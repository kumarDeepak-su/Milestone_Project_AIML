{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8__KJc9nmXZr"
   },
   "source": [
    "## Neural Networks - Part A ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8gowCO0mXZx"
   },
   "source": [
    "#### 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTyhQVXfLsTb",
    "outputId": "8ab4be79-1c10-405c-8ba1-065d4e87b25d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter 1</th>\n",
       "      <th>Parameter 2</th>\n",
       "      <th>Parameter 3</th>\n",
       "      <th>Parameter 4</th>\n",
       "      <th>Parameter 5</th>\n",
       "      <th>Parameter 6</th>\n",
       "      <th>Parameter 7</th>\n",
       "      <th>Parameter 8</th>\n",
       "      <th>Parameter 9</th>\n",
       "      <th>Parameter 10</th>\n",
       "      <th>Parameter 11</th>\n",
       "      <th>Signal_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parameter 1  Parameter 2  Parameter 3  Parameter 4  Parameter 5  \\\n",
       "0          7.4         0.70         0.00          1.9        0.076   \n",
       "1          7.8         0.88         0.00          2.6        0.098   \n",
       "2          7.8         0.76         0.04          2.3        0.092   \n",
       "3         11.2         0.28         0.56          1.9        0.075   \n",
       "4          7.4         0.70         0.00          1.9        0.076   \n",
       "\n",
       "   Parameter 6  Parameter 7  Parameter 8  Parameter 9  Parameter 10  \\\n",
       "0         11.0         34.0       0.9978         3.51          0.56   \n",
       "1         25.0         67.0       0.9968         3.20          0.68   \n",
       "2         15.0         54.0       0.9970         3.26          0.65   \n",
       "3         17.0         60.0       0.9980         3.16          0.58   \n",
       "4         11.0         34.0       0.9978         3.51          0.56   \n",
       "\n",
       "   Parameter 11  Signal_Strength  \n",
       "0           9.4                5  \n",
       "1           9.8                5  \n",
       "2           9.8                5  \n",
       "3           9.8                6  \n",
       "4           9.4                5  "
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np       # Library for number operations\n",
    "import pandas as pd      # Library for data operations\n",
    "\n",
    "# read csv file with \";\" as seprators\n",
    "DB=pd.read_csv(\"Signal.csv\",sep=\",\")  \n",
    "\n",
    "# Display top 5 rows of the dataset\n",
    "DB.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqJVdDjnmXZ1"
   },
   "source": [
    "#### 2. Data analysis & visualisation \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTFxoqo7mXZ2",
    "outputId": "ffa4ba38-ec5c-41c3-da34-992fef66966e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1599, 12)\n",
      "\n",
      "Columns: 1599\n",
      "\n",
      "Rows: 12\n",
      "\n",
      "Size: 19188\n"
     ]
    }
   ],
   "source": [
    "# Shape and size of Data\n",
    "\n",
    "print(\"Shape:\",DB.shape)\n",
    "print(\"\\nColumns:\",DB.shape[0])\n",
    "print(\"\\nRows:\",DB.shape[1])\n",
    "print(\"\\nSize:\",DB.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mSWlQARmXZ5",
    "outputId": "8ea2fbb5-7ee2-46c7-da26-96ebfae3e4ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter 1        0\n",
       "Parameter 2        0\n",
       "Parameter 3        0\n",
       "Parameter 4        0\n",
       "Parameter 5        0\n",
       "Parameter 6        0\n",
       "Parameter 7        0\n",
       "Parameter 8        0\n",
       "Parameter 9        0\n",
       "Parameter 10       0\n",
       "Parameter 11       0\n",
       "Signal_Strength    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null value detection\n",
    "\n",
    "DB.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYfeR8GYLsTk"
   },
   "outputs": [],
   "source": [
    "# Nothing to pre-process as the data is complete with numeric vallues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "goorPgrYmXZ8",
    "outputId": "104b36e3-af46-49a9-fb8f-b4b43f41336d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Parameter 1</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>8.319637</td>\n",
       "      <td>1.741096</td>\n",
       "      <td>4.60000</td>\n",
       "      <td>7.1000</td>\n",
       "      <td>7.90000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>15.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 2</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.52000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>1.58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 3</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 4</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>1.9000</td>\n",
       "      <td>2.20000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>15.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 5</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>0.01200</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.07900</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.61100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 6</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>72.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 7</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>38.00000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>289.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 8</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.99007</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>0.99675</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>1.00369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 9</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>2.74000</td>\n",
       "      <td>3.2100</td>\n",
       "      <td>3.31000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>4.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 10</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>0.33000</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.62000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 11</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>8.40000</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>10.20000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>14.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Signal_Strength</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>5.636023</td>\n",
       "      <td>0.807569</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count       mean        std      min      25%       50%  \\\n",
       "Parameter 1      1599.0   8.319637   1.741096  4.60000   7.1000   7.90000   \n",
       "Parameter 2      1599.0   0.527821   0.179060  0.12000   0.3900   0.52000   \n",
       "Parameter 3      1599.0   0.270976   0.194801  0.00000   0.0900   0.26000   \n",
       "Parameter 4      1599.0   2.538806   1.409928  0.90000   1.9000   2.20000   \n",
       "Parameter 5      1599.0   0.087467   0.047065  0.01200   0.0700   0.07900   \n",
       "Parameter 6      1599.0  15.874922  10.460157  1.00000   7.0000  14.00000   \n",
       "Parameter 7      1599.0  46.467792  32.895324  6.00000  22.0000  38.00000   \n",
       "Parameter 8      1599.0   0.996747   0.001887  0.99007   0.9956   0.99675   \n",
       "Parameter 9      1599.0   3.311113   0.154386  2.74000   3.2100   3.31000   \n",
       "Parameter 10     1599.0   0.658149   0.169507  0.33000   0.5500   0.62000   \n",
       "Parameter 11     1599.0  10.422983   1.065668  8.40000   9.5000  10.20000   \n",
       "Signal_Strength  1599.0   5.636023   0.807569  3.00000   5.0000   6.00000   \n",
       "\n",
       "                       75%        max  \n",
       "Parameter 1       9.200000   15.90000  \n",
       "Parameter 2       0.640000    1.58000  \n",
       "Parameter 3       0.420000    1.00000  \n",
       "Parameter 4       2.600000   15.50000  \n",
       "Parameter 5       0.090000    0.61100  \n",
       "Parameter 6      21.000000   72.00000  \n",
       "Parameter 7      62.000000  289.00000  \n",
       "Parameter 8       0.997835    1.00369  \n",
       "Parameter 9       3.400000    4.01000  \n",
       "Parameter 10      0.730000    2.00000  \n",
       "Parameter 11     11.100000   14.90000  \n",
       "Signal_Strength   6.000000    8.00000  "
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Further investigating with statistical analysis\n",
    "DB.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jEN6f01OmXZ9",
    "outputId": "15fc0d27-cb77-4356-8e51-d4b8ab83d816"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter 1</th>\n",
       "      <th>Parameter 2</th>\n",
       "      <th>Parameter 3</th>\n",
       "      <th>Parameter 4</th>\n",
       "      <th>Parameter 5</th>\n",
       "      <th>Parameter 6</th>\n",
       "      <th>Parameter 7</th>\n",
       "      <th>Parameter 8</th>\n",
       "      <th>Parameter 9</th>\n",
       "      <th>Parameter 10</th>\n",
       "      <th>Parameter 11</th>\n",
       "      <th>Signal_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Parameter 1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.256131</td>\n",
       "      <td>0.671703</td>\n",
       "      <td>0.114777</td>\n",
       "      <td>0.093705</td>\n",
       "      <td>-0.153794</td>\n",
       "      <td>-0.113181</td>\n",
       "      <td>0.668047</td>\n",
       "      <td>-0.682978</td>\n",
       "      <td>0.183006</td>\n",
       "      <td>-0.061668</td>\n",
       "      <td>0.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 2</th>\n",
       "      <td>-0.256131</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.552496</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>-0.010504</td>\n",
       "      <td>0.076470</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.234937</td>\n",
       "      <td>-0.260987</td>\n",
       "      <td>-0.202288</td>\n",
       "      <td>-0.390558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 3</th>\n",
       "      <td>0.671703</td>\n",
       "      <td>-0.552496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143577</td>\n",
       "      <td>0.203823</td>\n",
       "      <td>-0.060978</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.364947</td>\n",
       "      <td>-0.541904</td>\n",
       "      <td>0.312770</td>\n",
       "      <td>0.109903</td>\n",
       "      <td>0.226373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 4</th>\n",
       "      <td>0.114777</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.143577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055610</td>\n",
       "      <td>0.187049</td>\n",
       "      <td>0.203028</td>\n",
       "      <td>0.355283</td>\n",
       "      <td>-0.085652</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>0.042075</td>\n",
       "      <td>0.013732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 5</th>\n",
       "      <td>0.093705</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>0.203823</td>\n",
       "      <td>0.055610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.200632</td>\n",
       "      <td>-0.265026</td>\n",
       "      <td>0.371260</td>\n",
       "      <td>-0.221141</td>\n",
       "      <td>-0.128907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 6</th>\n",
       "      <td>-0.153794</td>\n",
       "      <td>-0.010504</td>\n",
       "      <td>-0.060978</td>\n",
       "      <td>0.187049</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.667666</td>\n",
       "      <td>-0.021946</td>\n",
       "      <td>0.070377</td>\n",
       "      <td>0.051658</td>\n",
       "      <td>-0.069408</td>\n",
       "      <td>-0.050656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 7</th>\n",
       "      <td>-0.113181</td>\n",
       "      <td>0.076470</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.203028</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.667666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071269</td>\n",
       "      <td>-0.066495</td>\n",
       "      <td>0.042947</td>\n",
       "      <td>-0.205654</td>\n",
       "      <td>-0.185100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 8</th>\n",
       "      <td>0.668047</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.364947</td>\n",
       "      <td>0.355283</td>\n",
       "      <td>0.200632</td>\n",
       "      <td>-0.021946</td>\n",
       "      <td>0.071269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.341699</td>\n",
       "      <td>0.148506</td>\n",
       "      <td>-0.496180</td>\n",
       "      <td>-0.174919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 9</th>\n",
       "      <td>-0.682978</td>\n",
       "      <td>0.234937</td>\n",
       "      <td>-0.541904</td>\n",
       "      <td>-0.085652</td>\n",
       "      <td>-0.265026</td>\n",
       "      <td>0.070377</td>\n",
       "      <td>-0.066495</td>\n",
       "      <td>-0.341699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.196648</td>\n",
       "      <td>0.205633</td>\n",
       "      <td>-0.057731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 10</th>\n",
       "      <td>0.183006</td>\n",
       "      <td>-0.260987</td>\n",
       "      <td>0.312770</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>0.371260</td>\n",
       "      <td>0.051658</td>\n",
       "      <td>0.042947</td>\n",
       "      <td>0.148506</td>\n",
       "      <td>-0.196648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093595</td>\n",
       "      <td>0.251397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 11</th>\n",
       "      <td>-0.061668</td>\n",
       "      <td>-0.202288</td>\n",
       "      <td>0.109903</td>\n",
       "      <td>0.042075</td>\n",
       "      <td>-0.221141</td>\n",
       "      <td>-0.069408</td>\n",
       "      <td>-0.205654</td>\n",
       "      <td>-0.496180</td>\n",
       "      <td>0.205633</td>\n",
       "      <td>0.093595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Signal_Strength</th>\n",
       "      <td>0.124052</td>\n",
       "      <td>-0.390558</td>\n",
       "      <td>0.226373</td>\n",
       "      <td>0.013732</td>\n",
       "      <td>-0.128907</td>\n",
       "      <td>-0.050656</td>\n",
       "      <td>-0.185100</td>\n",
       "      <td>-0.174919</td>\n",
       "      <td>-0.057731</td>\n",
       "      <td>0.251397</td>\n",
       "      <td>0.476166</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Parameter 1  Parameter 2  Parameter 3  Parameter 4  \\\n",
       "Parameter 1         1.000000    -0.256131     0.671703     0.114777   \n",
       "Parameter 2        -0.256131     1.000000    -0.552496     0.001918   \n",
       "Parameter 3         0.671703    -0.552496     1.000000     0.143577   \n",
       "Parameter 4         0.114777     0.001918     0.143577     1.000000   \n",
       "Parameter 5         0.093705     0.061298     0.203823     0.055610   \n",
       "Parameter 6        -0.153794    -0.010504    -0.060978     0.187049   \n",
       "Parameter 7        -0.113181     0.076470     0.035533     0.203028   \n",
       "Parameter 8         0.668047     0.022026     0.364947     0.355283   \n",
       "Parameter 9        -0.682978     0.234937    -0.541904    -0.085652   \n",
       "Parameter 10        0.183006    -0.260987     0.312770     0.005527   \n",
       "Parameter 11       -0.061668    -0.202288     0.109903     0.042075   \n",
       "Signal_Strength     0.124052    -0.390558     0.226373     0.013732   \n",
       "\n",
       "                 Parameter 5  Parameter 6  Parameter 7  Parameter 8  \\\n",
       "Parameter 1         0.093705    -0.153794    -0.113181     0.668047   \n",
       "Parameter 2         0.061298    -0.010504     0.076470     0.022026   \n",
       "Parameter 3         0.203823    -0.060978     0.035533     0.364947   \n",
       "Parameter 4         0.055610     0.187049     0.203028     0.355283   \n",
       "Parameter 5         1.000000     0.005562     0.047400     0.200632   \n",
       "Parameter 6         0.005562     1.000000     0.667666    -0.021946   \n",
       "Parameter 7         0.047400     0.667666     1.000000     0.071269   \n",
       "Parameter 8         0.200632    -0.021946     0.071269     1.000000   \n",
       "Parameter 9        -0.265026     0.070377    -0.066495    -0.341699   \n",
       "Parameter 10        0.371260     0.051658     0.042947     0.148506   \n",
       "Parameter 11       -0.221141    -0.069408    -0.205654    -0.496180   \n",
       "Signal_Strength    -0.128907    -0.050656    -0.185100    -0.174919   \n",
       "\n",
       "                 Parameter 9  Parameter 10  Parameter 11  Signal_Strength  \n",
       "Parameter 1        -0.682978      0.183006     -0.061668         0.124052  \n",
       "Parameter 2         0.234937     -0.260987     -0.202288        -0.390558  \n",
       "Parameter 3        -0.541904      0.312770      0.109903         0.226373  \n",
       "Parameter 4        -0.085652      0.005527      0.042075         0.013732  \n",
       "Parameter 5        -0.265026      0.371260     -0.221141        -0.128907  \n",
       "Parameter 6         0.070377      0.051658     -0.069408        -0.050656  \n",
       "Parameter 7        -0.066495      0.042947     -0.205654        -0.185100  \n",
       "Parameter 8        -0.341699      0.148506     -0.496180        -0.174919  \n",
       "Parameter 9         1.000000     -0.196648      0.205633        -0.057731  \n",
       "Parameter 10       -0.196648      1.000000      0.093595         0.251397  \n",
       "Parameter 11        0.205633      0.093595      1.000000         0.476166  \n",
       "Signal_Strength    -0.057731      0.251397      0.476166         1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORRELATION=DB.corr()\n",
    "CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Yh4UiiimXZ-",
    "outputId": "68f334d4-cf0a-4f59-ca88-df66a00d3d65"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplots(figsize=(20,8))\n",
    "sns.heatmap(CORRELATION)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeinP49YmXaB"
   },
   "source": [
    " - Performing univariate, bivariate and multivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fa8DPBTHmXaC",
    "outputId": "24526287-e112-4d0e-dd37-75b2ea27c108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07757361 0.097262   0.08087344 0.07842652 0.0752066  0.07591109\n",
      " 0.10185315 0.08594298 0.07418654 0.10419906 0.148565  ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Importance\n",
    "\n",
    "# Independent variables\n",
    "X=DB.drop('Signal_Strength',axis=1)      \n",
    "\n",
    "# Target variable\n",
    "Y=DB['Signal_Strength']                   \n",
    "\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,Y)\n",
    "\n",
    "#using inbuilt class \"feature_importances\" of tree based classifiers\n",
    "print(model.feature_importances_) \n",
    "\n",
    "#plotting graph of feature importances\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "#Observation: Most Effective - Parameter 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HEfdRCpmXaF"
   },
   "source": [
    "#### 3. Designing, training, tuning and testing a neural network regressor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvwFSUesmXaG"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Independent variables\n",
    "X=DB.drop('Signal_Strength',axis=1)  \n",
    "\n",
    "# Target variable\n",
    "Y=DB['Signal_Strength']               \n",
    "\n",
    "X_Train,X_Test,Y_Train,Y_Test=train_test_split(X, Y, train_size=0.7, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRVdZuo2mXaG"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling training data\n",
    "X_Train_S = StandardScaler().fit_transform(X_Train)   \n",
    "\n",
    "# Scaling testing data\n",
    "X_Test_S = StandardScaler().fit_transform(X_Test)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PnwQzvPLmXaH",
    "outputId": "4e6314a4-af89-4e71-e955-6e84752167e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1119, 11)\n",
      "(480, 11)\n",
      "(1119,)\n",
      "(480,)\n"
     ]
    }
   ],
   "source": [
    "# Confirming Matrix size\n",
    "print(X_Train_S.shape)\n",
    "print(X_Test_S.shape)\n",
    "print(Y_Train.shape)\n",
    "print(Y_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atv7SnUkmXaI",
    "outputId": "e06adeaf-0ac4-4d82-c20a-fc0cdb8e6cbe"
   },
   "outputs": [],
   "source": [
    " # Forward propogation\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LeakyReLU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULCNp_7DLsTx",
    "outputId": "5c18b776-8089-4e96-c167-59c8a20e8595"
   },
   "outputs": [],
   "source": [
    "NN_model_Regressor = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model_Regressor.add(Dense(128, kernel_initializer='normal',input_dim = X_Train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model_Regressor.add(Dense(64, kernel_initializer='normal',activation='relu'))  # sigmoid, tanh\n",
    "\n",
    "NN_model_Regressor.add(Dense(32, kernel_initializer='normal'))\n",
    "NN_model_Regressor.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "NN_model_Regressor.add(Dense(16, kernel_initializer='normal'))\n",
    "NN_model_Regressor.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model_Regressor.add(Dense(1, kernel_initializer='normal'))  # except softmax\n",
    "NN_model_Regressor.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model_Regressor.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "NN_model_Regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_K9EiVcmXaL",
    "outputId": "5db34e98-820f-474d-bf75-160578013861"
   },
   "outputs": [],
   "source": [
    "EPOCH=400\n",
    "Network_Regressor=NN_model_Regressor.fit(X_Train_S, Y_Train, validation_data=(X_Test_S,Y_Test), epochs=EPOCH, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLGWIj43mXaM",
    "outputId": "b1b8aca9-606a-46cf-eaf9-4b44b0969821"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = Network_Regressor.history['loss']\n",
    "loss_val = Network_Regressor.history['val_loss']\n",
    "epochs = range(1,EPOCH+1)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hcK-S8FAmXaN",
    "outputId": "109b3288-a4bb-4c97-d18f-f1d87318f2af"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3gU5fbA8e9JQhqd0HuV3qN4FQVEESuiUhQLNkRFxGsvKF6uPxui2PCiYsECKBZUOqJIUQEpSu8QekJLSM+e3x+zu9lUAmazwJ7P8+yTKe/MnJndzJn3nSaqijHGmOAVEugAjDHGBJYlAmOMCXKWCIwxJshZIjDGmCBnicAYY4KcJQJjjAlylghMHiIyXURuLe6ygSQi20TkYj/M92cRudPdPUBEZhWl7Eksp66IJIlI6MnGakxBLBGcIdw7Cc/HJSIpPv0DTmReqnqZqn5c3GVPRSLyhIjMz2d4ZRFJF5FWRZ2Xqn6mqj2KKa4ciUtVd6hqGVXNKo75G+PLEsEZwr2TKKOqZYAdwFU+wz7zlBORsMBFeUqaAJwnIg1yDe8P/KWqfwcgpqBhv8dTgyWCM5yIdBWROBF5TET2Ah+KSEUR+UFEDojIIXd3bZ9pfJs7BorIAhEZ5S67VUQuO8myDURkvogkisgcEXlbRD4tIO6ixDhSRBa65zdLRCr7jL9ZRLaLSIKIPFXQ9lHVOOAn4OZco24BPj5eHLliHigiC3z6LxGRdSJyRETeAsRnXCMR+ckdX7yIfCYiFdzjJgB1ge/dNbpHRaS+iKhnxykiNUVkqogcFJFNInKXz7xHiMhkEfnEvW1Wi0hsQdtARMaIyE4ROSoiy0TkAp9xoSLypIhsds9rmYjUcY9rKSKz3THsE5En3cM/EpH/+syjq4jE+fRvc/8eVwHHRCRMRB73WcYaEemdK8a7RGStz/gOIvKIiEzJVe5NEXm9oHU1+bNEEByqA5WAesAgnO/9Q3d/XSAFeKuQ6TsB64HKwMvAByIiJ1H2c+APIAYYQd6dr6+ixHgjcBtQFQgHHgYQkRbAWPf8a7qXl+/O2+1j31hEpCnQDviiiHHk4U5KU4CncbbFZuB83yLAC+74mgN1cLYJqnozOWt1L+eziC+AOPf01wP/JyLdfcZfDUwEKgBTjxPzEvf6VsL5jr4UkUj3uH8DNwCXA+WA24FkESkLzAFmuGNoDMwtbJvkcgNwBVBBVTNxts8FQHngOeBTEakBICJ9cLbNLe4YrgYSgE+Bnj4JNAzoh1PLMydCVe1zhn2AbcDF7u6uQDoQWUj5dsAhn/6fgTvd3QOBTT7jogEFqp9IWZydaCYQ7TP+U+DTIq5TfjE+7dN/LzDD3f0MMNFnXGn3Nri4gHlHA0eB89z9zwPfneS2WuDuvgX4zaec4Oy47yxgvtcAy/P7Dt399d3bMgwnaWQBZX3GvwB85O4eAczxGdcCSDmB388hoK27ez3QK58yN/jGm2vcR8B/ffq7AnG51u3248SwwrNcYCbwQAHlpgN3ubuvBNaUxP/YmfaxGkFwOKCqqZ4eEYkWkf+5m06OAvOBClLwFSl7PR2qmuzuLHOCZWsCB32GAewsKOAixrjXpzvZJ6aavvNW1WM4R5D5csf0JXCLu/YyAKeWcDLbyiN3DOrbLyJVRWSiiOxyz/dTnJpDUXi2ZaLPsO1ALZ/+3NsmUgpojxeRh9zNLkdE5DDOUbknljo4R+u5FTS8qHJ89yJyi4isEJHD7hhaFSEGcL6nm9zdN2G1gZNiiSA45H7E7ENAU6CTqpYDLnQPL6i5pzjsASqJSLTPsDqFlP8nMe7xnbd7mTHHmeZjoC9wCVAW+OEfxpE7BiHn+r6A8720cc/3plzzLOyxwLtxtmVZn2F1gV3HiSkP9/mAx3DWvaKqVgCO+MSyE2iUz6QFDQc4hlPL8qieTxnv+olIPeA9YAgQ447h7yLEAPAt0Eacq7uuBD4roJwphCWC4FQWp637sIhUAp719wJVdTuwFBghIuEi8i/gKj/F+BVwpYh0FpFw4D8c/7f+K3AYGIfTrJT+D+P4EWgpIte6j8SHknOHWBZIcs+3FvBIrun3AQ3zm7Gq7gQWAS+ISKSItAHu4OR2gmVxmuwOAGEi8gxOO7zH+8BIEWkijjYiEoOTKKuLyDARiRCRsiLSyT3NCuByEakkItWBYceJoTROYjgAICK34dQIfGN4WEQ6umNo7E4euGu6X+E+/6SqO05iGwQ9SwTB6XUgCogHfsM54VcSBgD/wmmm+S8wCUgroOxJx6iqq4H7cHYOe3DavOOOM40Cn+CcFP7kn8ahqvFAH+BFnPVtAiz0KfIc0AHn6PtH4Otcs3gBeNrdVPJwPou4Aee8wW7gG+BZVZ1dlNhymYnTzr4Bp3kplZzNNqOBycAsnPMoHwBR7mapS3CS+V5gI9DNPc0EYCXOuYBZON9zgVR1DfAqsBgnAbbGZ1up6pc4520+BxJxagGVfGbxsXsaaxY6SeI+yWJMiRORScA6VfV7jcScuUSkLrAO5wKGo4GO53RkNQJTYkTkbHGunw8RkZ5AL5yjO2NOioiE4FziOtGSwMmzu/pMSaqO0wQSg9NUc4+qLg9sSOZ0JSKlcZqStgM9AxzOac2ahowxJshZ05AxxgS5065pqHLlylq/fv1Ah2GMMaeVZcuWxatqlfzGnXaJoH79+ixdujTQYRhjzGlFRLYXNM6ahowxJshZIjDGmCBnicAYY4KcJQJjjAlylgiMMSbIWSIwxpggZ4nAGGOCnCUCY4w5BS3csZAVe1eUyLJOuxvKjDHmdOJSFyGS/zH3PT/cw98H/ubX2371lv3f0v9Rs2xNrpl0DYLgetbl9xitRmCMMSfotu9uY8qaKd7+9Kx0Fu5YmKfc3C1zKfN/ZVhzYA0ZWRkAPPfzczz909OkZqby7rJ3WbBjAR3HdWTp7qV8ufpL7p12L9dMugYARVkXv46k9CQemvkQP239yS/rYzUCY4wphKqSnJFM6fDSHEw5yLyt8/hoxUd8tOIjejbuSfmI8kxa7byEbcOQDTSJacK2w9vYnbibh2c/TEpmCpP+nsT4FeOJO5r9orwxv4/xdv+5509umHID6Vnp3mFtqrVh1b5VvLroVdbGr2XhzoVUjKrIRQ0uKvZ1PO0eQx0bG6v2rCFjTHFRVd7/831W7VvFS5e8RHSp6Bzjek/qzeK4xay7bx0NxjTgSNqRAucVERpB7+a9mfj3RO+w8NDwHDt4X7e3u53xK8Z7+8NCwmhYsSEbEjbw9AVOrWHU4lEAjL96PLe1v+2k11NElqlqbH7jrEZgjAk62w5vo8eEHjSv0pwVe1ew44jzzvsdR3fwUa+PiAiL4GjaUWZvns13678DoNfEXjmSwKTrJ3Hbd7eRnJHsPXpPy0pj4t8TiS4VTXJGMtXLVOem1jcxavEoYqJimNJ3Cq2qtqLyK5UB+KDXBzx03kOUDS/L77t+56yYs5i3dR7DZg6jY82OXHXWVbSs2pKE5AQGthvot+1hicAYc0ZKz0pn0PeDGNppKPO2zuPvA3/TNKYpnWp14uVFL7Px4EY2HtzoLf/fbv/l2Z+fZdAPg6gSXYXJqycTVSqKDjU6kJqZyq87fqVW2VrsStwFQJ8WfVi8czHrEtYxfcB05Dnxzuu9q96jW/1uRIZFEhkWSf0K9WlepTld6ncBYOJ1E2lVtRUALaq0AKBO+ToAVIysyIKdC+hWvxuhIaF+TQAe1jRkjAmIwq6mKYosVxahIaHsOLKDeq/XY/qA6Vza6FKW713OyPkj6VSrE0/MfYKI0AjSstLynUeohJKlWQDos8qjsx/l1cWv4tLsK3W+7vs1TWKa0O+rfjx+/uPM2zaPtKw0Prv2sxzz6v5Jd37a+hNZz2T9o/Xyl8KahvyaCNwvKB8DhALvq+qLucY/Agxw94YBzYEqqnqwoHlaIjDm9Dd68WiGzxvOH3f+QcuqLTmWfozS4aVzlNmQsIEy4WWoWbamd1hKRgpRpaL4Y9cfdHq/E//p+h/WxK/xtsnXLFsTl7rYm7Q3zzL/HPQn548/n5TMFAAeP/9xXrj4BZ6f/zz/qvMvLmpwERsTNnLWW2flmC7t6TTCQ8OPu07JGckkZyRTObryCW+PkhCQcwQiEgq8DVyC86LyJSIyVVXXeMqo6ivAK+7yVwEPFpYEjDGnj8S0RCLCIvLsROOT43lo1kMAzN06l0xXJu3+146J102kX6t+AGS6Mmn6VlMA1ty7huplqvPKold4ZdEr3BN7D7/ucK67f+bnZ3LMe3fibsqGl+Wdy99h08FNdK7bmQ0JG1CU9jXac16d85i7dS5T+0+lZ2PnffdPXfiUd/omMU2YdP0k3l7yNnXK1aFllZZFSgIA0aWic5xoPp348xzBOcAmVd0CICITgV7AmgLK3wB84cd4jDElYGPCRt764y3e+OMNrmt+HV/1/QpwrsCJOxrH4rjF3rIPzHjA291/Sn+2Ht7Ko+c/yq/bf/UO7/ZxN0TEe5T/5h9vFrjsJXctoXXV1kSEReQ7/ppm17DmwBoubXwppUJL5Vumb8u+9G3Zt+grfAbwW9OQiFwP9FTVO939NwOdVHVIPmWjcWoNjfOrEYjIIGAQQN26dTtu317gG9eMMX7yxV9fcGnjS6kUVYm0zDQ+/+tzbm57M2Eh2ceTcUfjeGDGA3y99mvvsJcufomp66dyccOLee6X5wDn6Llu+bqsi1/nLdeoYiM2H9pMbM1Ylu5eSnhoOOOuHMdd399FtTLV+OK6L2hZpSULdy5kXfw69iTuYfRvo73T/3HnH5xd6+xC10FVyXRlFpgEzmQBOUcgIn2AS3MlgnNU9f58yvYDblLVq443XztHYEzJUVVEhL/2/UWbd9vQs3FPLm5wMS8vepn9x/bz2bWfcWPrGwE4knqE+mPqczj1cKHzrFm2JleddRVRYVG8/vvrvHzxy/Rp2Yd65esx5vcxjPh5BD0b9+S65tfRp2UfkjOSCQ8Nz5FwPFIyUoj+v2hql6vNzgd3+mUbnCkCdR9BHFDHp782sLuAsv2xZiFjSsy+pH18/tfn3HP2PUSGReY5Unapi9u+u40v/vqCz6/73HtH7IxNM5ixaYZ3PmN+H0PV0lU5lHKIfl/1Q3EOLPu27MvwC4fTZmwbFOWCuhfQo1EPHjnvEW+zTVpmGsPOHUa9CvW88xt27jAe6PQAItmXYhbW7h5VKoppN06jeZXmxbdxgpA/awRhwAagO7ALWALcqKqrc5UrD2wF6qjqsePN12oExuR0NO0ooxaNYminoRxLP0bd8nVz7EhzS89Kp+GYhuxK3MWYnmMY2mkoz89/nv/M/w/TB0wnREKYun4qr/32GgANKjSgbvm6/LL9lwLnKTjLu/KsK9l2eBsfX/Mx7Wu0Z2/SXhbsWMB1za8rNCbjfwGpEahqpogMAWbiXD46XlVXi8hg9/h33UV7A7OKkgSMMY745HhiomIQEcb8NoaR80cycv5IAC5rfBlf9/uayLBINiZs5LXfXqNllZZc2vhSSpcqzed/fe69KeqFBS+QlpnG0/OeBpxr4T36tuzLoA6DuPTTS9l6eCvPXPgM/5n/H8B5ps7wecO9z9i54qwrmHy9cwOWr+plqnN9i+v9vj3MP2M3lBlzmvnv/P8yfN5wXuj+Ahc1uIgLPrzA+yybdtXbsWLvCkZ0GQHAiF9GeKerXqY6CckJZLicp2DOGDCDPl/2ITE9Mcf8R/cYzXUtrqNu+boAzN48m7Xxa7n/nPtZtmcZS3cvZXDsYA6lHGJDwgZaV2tNVFiUHfGf4gJ2Q5k/WCIwwcDzfykipGel8+TcJzm75tl0rd+V2q/VJtOVmaN872a9iQiL4JNrPuH6L69n6vqp3nGfXfsZCckJDJ0xNOcynlV2Hd3FvmP7aFixIRNWTuBgykGe7fqs/1fQlDh76JwxJSDTlUmLt1swsN1AnrzgSe9wVeW88edxcYOLGXnRSLYd3kbZ8LLERMd4y/yw4Qemb5zOm5e/SYiEMOj7QWw5vIWv+nzFgK8HMH3TdMJCwujdrDeZrkx+vPFHnvrpKY6lH2PWzbOoX6G+d15vXvYmrau2JrZmLL2a9kJEcKmLiLAILqx3IdsPb6dSVCUAapWrRa1ytQC4v1OeC/pMkLAagTHFZMXeFbT/X3sANg/dzJwtczivznlkujK9w/c/vJ+qo6oSFRbFskHLWLJ7CVFhUfT9yrmB6aF/PUTnup3pPal3jnmP7jGa1357jZ1Hd3LVWVcx9YapGHMirGnIBBWXukjNTC30ssO5W+bSuW7nAu9ABefZMVFhUWRpFlmuLCLCIthxZAcJyQm0r+Hs2JPSk7h+8vVc3uRy3l7yNhsSNgDQuFJjNh3cRPvq7alauiozN88sNOZ21dux9sBa78PR6pavy+COg3nqp6d48eIXefT8R5m7ZS5P/fQUk66flOOSS2OKwhKBOeOlZ6WTnJFMhcgKPDLrEUYtHkXqU6n57ujnbZ3HRZ9cxOPnP87lTS6ndrnaNKjYgPt+vI/UzFRqlK3BoI6DOOe9cygbUZb45HjqlKtDaEio92Xiz1z4DL9s/4W21dryxh9v5Jh/r6a9vM+w97i74900qdSEh2c/nCeeznU7M+fmOWw+tJk/dv3Byr0rvdfXH049TIXICsW4pUywskRgznh3fHcH41eMJ/nJZMq+UJYszWLWTbO4pNElgNMGv+ngJu7scCf3/HgPn6761Dtt+YjyHMs4luMErCDem6N8lQkvQ1J6UoFx3NDqBp7r+hxfrvmSQymHGLV4FG2qtWHl4JXOfN3PrN8+bDuTV0/m7o53Uzq89Cn52GJzZiksEdivz5wRPK/7m7J2ivcxwD9u/BFVJTEtkau/uJoHZz7Ik3OfzPHScYAjaUe8ScBz9K0olze5nKxnspgxIPtO2kOPHSLh0QReuvglGlVsRIiE0KlWJwCe6/ocn137GU1imvDkBU/SuW5nALrW6+qdftmgZUzpO4W65evy8HkPUzairCWB41CFtPxfJ+D1yy8wYgS4XIWXA8jMhKysYgntjGE1AnPK+mvfXzSu1DjPTUq5qSoxL8dwKPUQ59U5j0U7F+UYP7LbSIbPG05MVAwJKQkAvH352yzcuZDLG1/OTd/cRIiEsPWBrdQpV4edR3cyc9NMbml7CxFhERxJPUKFl9wJ4tns/5c1B9awLn4dqZmpDPh6AL8M/IUL613oHZ/lyuK9P9/jlra3nLaPJ/aYPh2qVYMOHUp+2Y89Bi+/DCkpEBcHixfDzTdnj4+Lgzruh9msXQvNmhU+v9atISwMli8v3jiXL4dt26B37+MWDYjCagSo6mn16dixo5oz3+GUw8oItO3Ytt5hR1OP6oLtC7z9i3Ys0s9WfaaPzHpEGYGGPBeijEAZgb62+DVvNyPQyP9G6uaDm7396ZnpqqqalJakbce21ekbpxcaz/Pzn9e5W+YWOH7roa3/bIXz4XKpTpmimppaeLkNG1TLllVdvlw1OdmZJiPj5Jf78ceqrVqpHjiQPaxqVdWePU98XrNnq1arprptm2qjRqqffFJwWZdLtXNn1UcfzTncqROoXn21aq1aTveWLdnj58/PLvPdd86wNWtUZ8zIu4zk5OyyLlf+cfzwg2pS0omtp8uVPd9TFbBUC9ivBnzHfqIfSwSnl8ysTE1Ky/lfNXu28w//99/Zw7JcWTnKzdw007vTvu+JHTpo6EFt9247ZQT6/PzndX38+hw7eh4rr7ePf8HbfzD5oMYfi9erPr9KGYFeMeYhPXxYdcvBLfrn7j/9tr7btqmef77qjh3/fF4//+z8h95/v9OfkeHs3P7+W3XdOmcb7t+v+uqrTrmOHVVbt3a6X3tNdevW/Oebnu7s1H/6Ke+4PXuyd2jPPae6cKGzLp5hnTurzprllE1MVF29Ouf0LpfqggXOR1W1cWNnuvvuy55HVlbe5SYmqn75ZXaZ3393hmdlOUnOM9zzeeGF7Gm//z57+MsvOwkxIsLp/7//U33sMSeJpKaqzpyZXXbvXqf8nXeqXnSR6nvvqS5b5oy7556CvxeXS7VPH9WvvsoeNnt29nw9iTsjw9nOM2eqDh+u+sQTBc+zJFgiMH6XkqJ68GDOYfv2qQ7+7j5lBJqZlamqzk7M8w/z8CNZ2uuLXtr3y77aZmwbrfdaPU3JSNFftv2SvYP/dw1v+dL3dtWOo67SiJER2nT4dUqbT5SnIpURaK3mcU65Z0J0+E/DvTFsTNioj337qoLqNdcUfX3ef1/17bdPfDv07evE2q6d6ptv5l8mIUH12LGCx914o7OTevNNZ1516jjjHnjA6a9QQfWyy5zud95xdnSebVSlimp0tNNdv76TDDZvdqZ3uVTfeEP18sud8ZGRzo7v8GFnfFKSMz9QrVkz787X93PFFU7Ci4hwpl+7VnXpUtXRo3OW8XSHhmZ333+/6q23Osnq1ltVv/giO2F4Pt26OTWD9eud/nHjVNu0yR5fq5bqt9+q3nGH6oQJ2cPvuMNZR3BqNb7zfPppZ7ynf/r0vOslkr38gqxdm11+zx7nO3v22exhCxc629q3nOdTUHLOLS7O2a6JiUUrXxSWCIzfeXYunur2sWPuH3+H/ykj0F1Hd+mexD3aqMM2LVcxTWs2OKw1z9qrXDFYuaWbd8cf/Xy0tzviykfy/COVCs9S7opVKm1QUB3y0gIdOHSbd/zPv6boo4+6dMUK1Uwn9+gzzzjjqlXLHub5m9v+/aqPPJK9PM/Ra2qqc0S3b5/Tv327c5Q3bpxzhOxyOUeADRtmT1uzZvZ8U1NVDx1yylWtqtqkiRODy6X63/+qTpqk+sorqk8+6Uz7n/+o3n573p1WpUo5t8e99zoJDpwj2927VVu2zLsDeuYZ1cmT89+px8Q4O8gmTZz+6GjV+HjnqNj3SL6gz5AhOft9k0iNGqqVKzvdZcqoXnJJ/vOoXdv5GxaWfTQP2eWXL1e94Qane+DA7B02ZMfYtKnzt0sX1ZCQ7O89PDx7G4WGqvbu7XT36JE9j8hI1cGDs/vPPddpIps2Lfs7zMhwvq8xY46/Tfr0Uf3007zDn346e36bN6s+/rjzm/P1+efZ265LF2eY5/f1T1giMCds99HdmpCckGf47787TRa5eXfEvznVguXLff4BLhipb09erTe+Mdrp7/Fv5aInvOMbNMzSxJRk7fZRN60xooO2GPimvjzzozz/RPfeq1qliksjq+70DouKylmmXbvs7t69ndg6dsxZ5sUXnX/8yZPzroenacXzWbrUGT5unNM/bJjq1KnO0bZvuX79cu7APJ/hw50E4DnivfTS7HHPPus0cfiW/9e/nL8PPaTatq2zM/CMK13aSUQxMXmX41vbuemmnOOuuy7njtL3U6tW/okjv+8WVK+91tl55S5fo4bTPu9pX/ckrEOHVD/4wOm+4AKnjf7HH53tBar9+ztNO4cOOeu2bVve2kGlSk7S3LJFtWtXp9wPPziJHbKTr6eJDJxkO2tW9vRTpmSP27Qp7zIuuMA5svf0h4Y6v63GjZ2dcEqKs7xXXlG96qq86w+q5cvnP9z7O2/gxO/h+V46dXL6Fy1yDjYaNco53SefqDZvrnreeU6z3smyRGByaNJE9fXXCy/D0+EqZfbpF19kD0tOT/b+OD1H/tdd59J2F63P/uF2f0z7Pv+RNrzriRw/5jpNDmvMpWOVkAy9Y9K/lUcq5xj/0Ueqc+Y4TRugWq9ezn+G0e/vVNWcO6Fu3fL/h6tePfvo1nM0mt9OumXLnCcMFy7MW+a//3XG9eqVc6cDTrtzYf/4no+niaJjR+dINjz8+NN4EoBvonjoISeWxYtV3303/3GqTpPCrFmqv/7q1FxSU7ObVfr0yZ6mbl2njT8rK+ey3303529h+3bV335zzk94TqKuXOl8R5dd5qxP7ma0LVuy2/lVnW7fZpHVq51kumZN3t9ely5OHJ7t1Lp1/r9Rlyv7+w0Pd4Z5fhMtWzrNKg0aOE1IycnOsHfeccq99ZZT7rnnVLt3d/o9ceZOdL61oipVVCtWzP8769kzu9u3Nrdjh3POZOhQp//rr51tGhKSXebBB53+kBAnAV1xhWpsbN5ljRiR/7YoCksExsvbZEPBZeKPxStDGyqolivn0sS0RF2/XrXdmAu80971n1914ZYlBe/M6v7i/L34ESX2HZWQTKXRdK1Wz6llvPjri8rgNjp+0j4991yn3Tsqyjlq9RyteZqbQPWPP5zYPM0boaHOVS116+Zd9tixTpXed9jNN+fs9zQzDB3qtPMOH+705/dPnvvosW5d1aNHnXg8TQWeRAE5my08n+bNnR3ur786R8CenV1BicyzM0tNdWpCNWrk316cluac5Ny1q/DvfeVKp0YxebKTJDzb08Oz7IULi/Y78qeLLnJi8XwnH39ccFnPb6RKFaf/llvUe5BQmNRU52DI8z36OnjQOUpv3Nhpqipsp3/HHaoffuh0e5qcwPld1Kzp1Hw8Jk7MOx9PQvL8JnPH89RTzrhnn3WaDRcvLsoWzJ8lAqOqzo5zy5a8iWDLwS365Jwn9Z0/3tEZG2fo9+u/V27r7JSTTJVHq2hIqTSl8Y85f8gx63L2lzqWoz+68n6nvb/fNd5hV16TrKqqLpdL9yU5De5LlmRP88EHzk5q+HBnx+f5R/S0zW/a5PS3aeP0p6dnn+Bcvjy7vTUpKec/3KpVOdv+ExOz24g9V6V07ZqzHd23zfill7KbM/KrTR06lHNZL7ygOmpU9pH4Bx/kLO85qQzOEW9amupZZzlNVmPGqJYq5ZzIdbbVP2sS8EhLK3jcPfc4sZzoZZP+0LmzE8v06cdf7/vvz07Wqtk7zuuu++dxZGTkPBhp2dI5SgfVFSuck9nx8dkXQIwdm530PdP71jiTkpwT+74HJYmJ2d35XSackKD673/nvRDjZFgiMPrLL863/e+H0r0/vKOpidrs1teV2HeUQR2UZ5zr8Ad+O1C5rl/2jrTClpw7/CY/KE2/yXN007LH7zn6L7o4XZ+a+5TWHP4v77D8qra+12Dnvuxy0SKnau75h3K5nKO/u+7KOX1cXAT/RrIAACAASURBVN757t7tHIHfeWf2Sd8vvshu7klPVx00yFnu2WdnL8PTjr9rl7NDWb/eGf7XX077e0FX/OROsKrOOYabb877T+5pz/7uu+wj/SNHnE9GhhN7ScrIcK5UOhU8+qizbdatO35Zz3Zs1Mjpf/ddp/9ErhArjOeE79Spznfzyy/O7yn3PQi7djnDDh0q+PfhsX+/M89LLnH6n37auVjA3ywRnKFcLpd2eq+TXj/5em36ZlPdfXS3Tlg5QY+kHtGUjBR9b9l7ujFho/66/Ve9/YFdeXbcnUffqEhG9rBy25WbLlGuukMb9n0n3yqxVNiuPBOiE2ev9Q4bOPxXrdRslf6y+EiOsp6bh27++haNrLJbwTlpl58PPlAdMKBo671+vXOkVByOHnVOFM6enT0sKSnnPQ5F9cQTqiNHFq1sVlbONnSTLT09uzZ0PJ6TwJUqOf3ffOP0X3ZZ8cTicv2z5piCrF5dPEf5J6KwRODXR0yISE9gDM47i99X1RfzKdMVeB0oBcSrapfC5mmPmMi2Pn49zd5qBlsvgnrzITQTtl3I4Gva8VfCMhYuEMJrr4bwY2R+8j2ujT1yzuDKQfDDOIY+uYf5u+bw1/ddyDrovJ6wZpP97N5YFYBu3ZQK1zxH27A+3HxtVSKi04kJr0WU+8kPCQlQyXnPCd9/D3//DR9+CKtXQ6lSzsHGsWRlxvQQeveG0NCS2kLmTLdsGcTGQkiI8/yg+fOhSxe46SaYMCHQ0Z1aAvKICZyd/2agIRAOrARa5CpTAVgD1HX3Vz3efIOxRpCZlamuXHXRI6lH9OUFLyt9eztH4D3vV+5t7nSf/aZyXzMF1Qbd5mrbt2M1JOqIlqm2L8cRe1Td1QpO88mR1CM6Y/7+HONr1nQul0tJyT8u3xNjxgRCfHzOJjmXy7kRr6SPtk8HFFIj8OdjD88BNqnqFlVNByYCvXKVuRH4WlV3uJPSfj/Gc9pq9EYj+nzZh/f/fJ9Ri0axev9qKr1UiUfnPArrnU3aOvIKxp//GwBRO3rRcLfzqsSQHRfxSPkluFLK8fbLVb3zPPdcFyk7WgDQtCmUiyjHpRdUISUFLrjAKdOkCTz8MERG5h9XvXrOX3tnuQkUT0308sudvyIwZAhUrBi4mE5H/nxncS1gp09/HNApV5mzgFIi8jNQFhijqp/knpGIDAIGAdStW9cvwZ6K1sWv4+z3ziYpPYntR7YzZa3z+OR52+aRpVk8034sL79yA6lAdEozdmwsB0B6fB3SlziPZ9y8Ge65B5o3d6rLt97qzPuyy0L4zckbVK6cvczISHjgAedJjwMGFB7fX38d//HAxviTCOzdC+XLBzqS05s/E0F+x4m5T0iEAR2B7kAUsFhEflPVDTkmUh0HjAPnHIEfYj3l3PrtrXyz9ps8L0GpVroa0zZOo175euz8djBkQc16KaTurcvffztlsrKcR/OOHeskgcREGDPGaUcdNsz553nwQdi4EWJi8h7RX3ed8zmesmWdjzGBVK1aoCM4/fkzEcQBdXz6awO78ykTr6rHgGMiMh9oC2wgSGW5sli5byWfrHQqRtVKV+O+s+/jmZ+fgWV3ELN/JPsureU8d/9d6NkT6teP4n//c3b43brBlVdCq1bQo4dz4mzzZrjEeVEXr72WvSw7mWaMAf++oWwJ0EREGohIONAfmJqrzHfABSISJiLROE1Ha/0Y0ynv/T/fp+O4jk6PQtXMs7mw8vWwcgB8/z5rfq9B3+pPc2vLu9m40XnJRrt2TlPOli1w443w7387SQCcJqErrwzc+hhjTn1+SwSqmgkMAWbi7Nwnq+pqERksIoPdZdYCM4BVwB84l5j+7a+YTgfL9izL7vnzTv564nuuPq8ZfPMpEuK8h69H+H8oe7ALLpdz5H/jjVCrlnOp5k03BShwY8xpy59NQ6jqNGBarmHv5up/BXjFn3GcLv7c8ye/xTlncEf3GM3PqwYzFTh6VDj/fJg1K4Q6deDOO7OnadXKSQAbNzpNQwVd4WOMMQXxayIwhVNVXljwAhlZGXy7/ltW7F0BwM1tbubBfz3Ibz7fzl13QXS0c8T/ySfOu2OzspxLPAGiovDe4GWMMSfCEkEAzd4ym6d+egq2nw/zXoXSB6DxDCp1cq6F27o1u2yrVs7fMWOcjzHGFBdLBAGy9sBaHnjxT9h9L6zrBdsuckas7ke9K3fxzDOwfr0zSMQ56WuMMf5giSAAZm6aSc/PesL7zi0R51y2nj+2ZI9/Ykgt741affpAy5ZOs5AxxviDJYIA+GHDDzn6w440BaBOHdi5E8qUyb5j94MP7KYtY4x/+fM+ApPL0t1LGfjtQCatnkT16Jre4YsWOUf+y5dD48YwfjysXOkkBUsCxhh/sxpBCRo+bzg/b/uZmmVrMrz929zmM65OHedxDxs3Biw8Y0yQshpBCTiadpS6r9VlxqYZDOs0jM1DN1MtqWeOMnXqFDCxMcb4mSWCEjBu2Th2HnUexHpb+9uYNSv7sbmepyY2bRqg4IwxQc+ahvwsOSOZ0YtH07V+V+bdOg+AwT7vaVu92nmMbocOAQrQGBP0rEbgRx/8+QG1Rtdiz5YK3Nv4JQA2bYJ586BFCzjrLKheHTp2tJe7GGMCxxKBn6zev5o7v7+TeuXrwztruLHrOaxeDZMmOeNnzHBuGLP39xpjAs2ahvzkx40/AvB6xxl0AzIzsx8T0bmznRw2xpw6rEbgJz9u/JE2VduyclHe1ye9+moAAjLGmAJYjcAP9iTu4dcNq4h4czfDcr5pkpUroU2bwMRljDH5sRpBMYs7GkePT3ugB84iNcl5LvTw4c64jh0tCRhjTj1WIyhmw6Y9zN/LytAy/U5W47xHYPhwqFoVevUKdHTGGJOXJYJitDJuHVM+LwPfL2a1e9ioUc4bxIYMCWhoxhhTIL82DYlITxFZLyKbROTxfMZ3FZEjIrLC/XnGn/H4W7s6zeD793MMK1cuQMEYY0wR+a1GICKhwNvAJUAcsEREpqrqmlxFf1XVK/0VR0nZvisFcM4JhIdDenpg4zHGmKLyZ43gHGCTqm5R1XRgInDGtpI/O3myt9vOBRhjTif+TAS1gJ0+/XHuYbn9S0RWish0EWmZ34xEZJCILBWRpQcOHPBHrP/YL0sSvN3R0fD557B4cQADMsaYIvLnyeL8np6jufr/BOqpapKIXA58CzTJM5HqOGAcQGxsbO55nBL2bK5EaHg6t98azvDhduewMeb04c8aQRzguzusDez2LaCqR1U1yd09DSglIpX9GJNfxCfHk7avPnWaxjNunCUBY8zpxZ+JYAnQREQaiEg40B+Y6ltARKqLOM/dFJFz3PEk5JnTKW59/Ho41IiGDV2BDsUYY06Y35qGVDVTRIYAM4FQYLyqrhaRwe7x7wLXA/eISCaQAvRX1VOy6Sc/u3eDywUr4tbB0X/RqtnhQIdkjDEnzK83lLmbe6blGvauT/dbwFv+jMGfLr4Y1q6FmsNmAHfQsUWFQIdkjDEnzJ419A+sXev83f2/sQA0aWKb0xhz+rFHTPwDlSvDMfaTlhyGitK4sb1mzBhz+rFD2JPgcsG0aRAfD+mt3uP2915n7lyhSpVAR2aMMSfOEsFJmDABrrjC6c6K3s1tF/SkW7fAxmSMMSfLEsFJ2Ls3u7tiTBbn1j43cMEYY8w/ZIngJPi+cP662AsIEduMxpjTl+3BToLv444Gd7k2cIEYY0wxsERwEvbvz+6uVysqcIEYY0wxsERwEvbty36URMWKAQzEGGOKQZESgYhMEZErRKwxHGDH7lRoNJPxSz7Pcb7AGGNOR0XdsY8FbgQ2isiLItLMjzGd8nbsSUXK7OOSsy4MdCjGGPOPFSkRqOocVR0AdAC2AbNFZJGI3CYipfwZ4KkmLTOdxINRNK1Xidrlagc6HGOM+ceK3NQjIjHAQOBOYDkwBicxzPZLZKeoWUu2QGYUnVpWD3QoxhhTLIr0rCER+RpoBkwArlLVPe5Rk0Rkqb+COxV98lkaADf1KRvgSIwxpngU9aFzb6nqT/mNUNXYYoznlPfzj1WRugvo0qZToEMxxphiUdSmoeYi4n3YvohUFJF7/RTTKWv1aojfVoMa//qVUqFBdWrEGHMGK2oiuEtVva/fUtVDwF3+CenUNfmrTBAXF11+MNChGGNMsSlq01CIiIjnNZIiEgqE+y+sU9PC5fuhXDr9zu0S6FCMMabYFLVGMBOYLCLdReQi4AtgxvEmEpGeIrJeRDaJyOOFlDtbRLJE5PoixlOisrLg7rth0S9lCCm3l+4Nugc6JGOMKTZFrRE8BtwN3AMIMAt4v7AJ3LWGt4FLgDhgiYhMVdU1+ZR7CSfZnJK2bIFx4wDKUaNpFlGl7PlCxpgzR5ESgaq6cO4uHnsC8z4H2KSqWwBEZCLQC1iTq9z9wBTg7BOYd4nyfdpoy4blAxeIMcb4QVGfNdRERL4SkTUissXzOc5ktYCdPv1x7mG+860F9AbePc7yB4nIUhFZesB3r1xCdu9Wb/f5LRuU+PKNMcafinqO4EOc2kAm0A34BOfmssLk9yZ3zdX/OvCYqmYVNiNVHaeqsaoaWyUALwZetTk7+TSpX7rEl2+MMf5U1EQQpapzAVHV7ao6ArjoONPEAXV8+msDu3OViQUmisg24HrgHRG5pogxlZiVm/Z5u+1po8aYM01RTxanuh9BvVFEhgC7gKrHmWYJ0EREGrjL98d5gqmXqnrbWUTkI+AHVf22iDH5XXw8vP8+bNx2DIB+/VxceaU9idsYc2YpaiIYBkQDQ4GROM1DtxY2gapmupPGTCAUGK+qq0VksHt8oecFTgX33QeTJ0NIeDvK1F/HxIlB/fRtY8wZ6riJwH15Z19VfQRIAm4r6sxVdRowLdewfBOAqg4s6nxLSkKC89eVHklM1fTABmOMMX5y3HYO94ncjiKS38nfM5rvGlevnvs8tzHGnBmK2jS0HPhORL4EjnkGqurXfonqFBHikybr1raHzBljzkxFTQSVgARyXimkwBmdCHw1rhsd6BCMMcYvinpncZHPC5xJjh7N7m7RsFLgAjHGGD8q6hvKPiTvzWCo6u3FHtEpxHOyGOCsevZGMmPMmamoTUM/+HRH4jwWIvfNYWecfQcyAOfcQM2aQXeu3BgTJIraNDTFt19EvgDm+CWiU0RWFiQecTaPiFKtmiUCY8yZ6WRvk20C1C3OQE41hw6BqrPzr1lTKGUXDRljzlBFffpooogc9XyA73HeUXDG2u1u+KrV92WmTSu8rDHGnM6K2jQUVGdKDxyAOe6Gr0Zt9tGmTWDjMcYYfypqjaC3iJT36a9wKj4ltLjccw889JDT3fysoHs1szEmyBT1HMGzqnrE06Oqh4Fn/RNSYKnCL79k9zetfbyHrBpjzOmtqIkgv3JFvfT0tLJxo/P4aY8ejXoELhhjjCkBRU0ES0VktIg0EpGGIvIasMyfgQXKb79ld4eEZtGyasvABWOMMSWgqIngfiAdmARMBlKA+/wVVCDFxbk7+l7HC19ND2gsxhhTEop61dAx4HE/x3JKSEiAiKhM0lp8Tfdzngx0OMYY43dFvWpotohU8OmvKCIz/RdW4MTHQ1Q550nbTWKaBDgaY4zxv6I2DVV2XykEgKoe4vjvLEZEeorIehHZJCJ5ahQi0ktEVonIChFZKiKdix66fyQkgEQfokaZGpSLKBfocIwxxu+KmghcIuJ9pISI1Cefp5H6cr/i8m3gMqAFcIOItMhVbC7QVlXbAbcD7xcxHr+Jj3eRGLaF7g27BzoUY4wpEUW9BPQpYIGIeK6wvxAYdJxpzgE2qeoWABGZCPQC1ngKqGqST/nSHCe5lIQde5PJLLuPAa0HBDoUY4wpEUWqEajqDCAWWI9z5dBDOFcOFaYWsNOnP849LAf3XcvrgB9xagV5iMggd9PR0gMHDhQl5JN26GAIRB+kW/1ufl2OMcacKop6svhOnGach9yfCcCI402Wz7D8Xm7zjao2A64BRuY3I1Udp6qxqhpbpUqVooR8UjIzITUxmvIVM4gIi/Dbcowx5lRS1HMEDwBnA9tVtRvQHjjeoXkcUMenvzaFvMxGVecDjUSkchFjKnaHDjl/q1U5I2+aNsaYfBU1EaSqaiqAiESo6jqg6XGmWQI0EZEGIhIO9Aem+hYQkcYiIu7uDkA4kJBnTiVk61bnb+1qkYEKwRhjSlxRD33j3PcRfAvMFpFDHOdVlaqaKSJDgJlAKDBeVVeLyGD3+HeB64BbRCQD55xDP1UN2AnjBx/KhMijnNclNVAhGGNMiZMT3e+KSBegPDBDVdP9ElUhYmNjdenSpcU+X1UIK+XCde4rfPt+M3o161XsyzDGmEARkWWqGpvfuBNuDFfVX45f6vRz5Ai4skIIL3eIixteHOhwjDGmxJzsO4vPOAnuMxMdGtWjdHjpwAZjjDElyBKB2/4DLgAa1LTHShhjgoslArede5MBqFY1NMCRGGNMybJE4LZzr3OjdPUqpQIciTHGlCxLBG579jkXQNWubvcQGGOCiyUCt737M0EyqVnFThQbY4KLJQK3AwkuiDpIxagKxy9sjDFnEEsEbgfjBaLjqRBpicAYE1wsEbgd2BsBZXdbIjDGBB1LBG4H4spBpS32ekpjTNCxRAAcPQrJR0oTWSWOELFNYowJLkG/11OFqe6HY5ep5t+3nxljzKko6BPBn3/CzTc73RVrHQxsMMYYEwBBnwj278/ubt/czg8YY4JP0CeCxER3xzW3clmr8wMaizHGBIIlAk8iqD+P7g26BzQWY4wJhKBPBJv27AXglnOupU75OgGOxhhjSp5fE4GI9BSR9SKySUQez2f8ABFZ5f4sEpG2/ownP/sOOo+fvuXs3iW9aGOMOSX4LRGISCjwNnAZ0AK4QURa5Cq2Feiiqm2AkcA4f8VTkMREICyF6Ijwkl60McacEvxZIzgH2KSqW9wvuZ8I5HgjvKouUtVD7t7fgNp+jCdfSYkC4UmEh1oiMMYEJ38mglrATp/+OPewgtwBTM9vhIgMEpGlIrL0wIHivekrKSkEwhOJCIso1vkaY8zpwp+JQPIZpvkWFOmGkwgey2+8qo5T1VhVja1SpUoxhgjJx0IgItFqBMaYoOXPRBAH+F6GUxvYnbuQiLQB3gd6qWqCH+PJV3JSqFMjCLUagTEmOPkzESwBmohIAxEJB/oDU30LiEhd4GvgZlXd4MdYCpR8LAwirGnIGBO8wvw1Y1XNFJEhwEwgFBivqqtFZLB7/LvAM0AM8I6IAGSqaqy/YspP6rEwKGNNQ8aY4OW3RACgqtOAabmGvevTfSdwpz9jOJ7U5FIQY01DxpjgFfR3Fqclh0O41QiMMcErqBOBKqSllILwY4SF+LVyZIwxp6ygTgRZWYCGEFoqE/c5CmOMCTpBnQjS052/YeGuwAZijDEBFNSJICPD+RsWlu99bsYYExSCOhF4awSlrEZgjAleQZ0IPDWCUuFWIzDGBK+gTgTeGoE1DRljglhQJwJPjSDcbiEwxgSxoE4EnhpBqVKBjcMYYwIpqBOB1QiMMSbIE4GnRhBeym4mM8YEL0sEWI3AGBPcgjoRZDcNWY3AGBO8gjoReGoEERGWCIwxwSuoE4GnRhBRKqg3gzEmyAX1HtBTI4iMCOrNYIwJckG9B/TWCMKDejMYY4KcX/eAItJTRNaLyCYReTyf8c1EZLGIpInIw/6MJT+eGkFUZGhJL9oYY04Zfnstl4iEAm8DlwBxwBIRmaqqa3yKHQSGAtf4K47CeGoEkXay2BgTxPz5fsZzgE2qugVARCYCvQBvIlDV/cB+EbnCj3EUKC1NASEy3F5TaU5PGRkZxMXFkZqaGuhQzCkiMjKS2rVrU+oEnp3jzz1gLWCnT38c0OlkZiQig4BBAHXr1v3nkbmlpGUCpSgdaQ8bMqenuLg4ypYtS/369e11qwZVJSEhgbi4OBo0aFDk6fx5jiC/X+VJPe9ZVcepaqyqxlapUuUfhpUtOTUTgGhLBOY0lZqaSkxMjCUBA4CIEBMTc8I1RH8mgjigjk9/bWC3H5d3wlK8icCahszpy5KA8XUyvwd/JoIlQBMRaSAi4UB/YKofl3fCUtKzACgdaQ8bMsYEL78lAlXNBIYAM4G1wGRVXS0ig0VkMICIVBeROODfwNMiEici5fwVU24paVkgWURHRJTUIo05oyQkJNCuXTvatWtH9erVqVWrlrc/3XN9dgGWLl3K0KFDj7uM8847r7jCNQXwa5uIqk4DpuUa9q5P916cJqOASE3LgpAMIkItERhzMmJiYlixYgUAI0aMoEyZMjz8cPYtQZmZmYSF5b+biY2NJTY29rjLWLRoUfEEW4KysrIIDT197k8K6sbx1DQXhKYTGRYZ6FCM+ceGzRjGir0rinWe7aq34/Wer5/QNAMHDqRSpUosX76cDh060K9fP4YNG0ZKSgpRUVF8+OGHNG3alJ9//plRo0bxww8/MGLECHbs2MGWLVvYsWMHw4YN89YWypQpQ1JSEj///DMjRoygcuXK/P3333Ts2JFPP/0UEWHatGn8+9//pnLlynTo0IEtW7bwww8/5Ihr27Zt3HzzzRw7dgyAt956y1vbePnll5kwYQIhISFcdtllvPjii2zatInBgwdz4MABQkND+fLLL9m5c6c3ZoAhQ4YQGxvLwIEDqV+/PrfffjuzZs1iyJAhJCYmMm7cONLT02ncuDETJkwgOjqaffv2MXjwYLZs2QLA2LFjmT59OpUrV+aBBx4A4KmnnqJatWpFqjEVh6BOBGnpLgjNsERgTDHbsGEDc+bMITQ0lKNHjzJ//nzCwsKYM2cOTz75JFOmTMkzzbp165g3bx6JiYk0bdqUe+65J8+18MuXL2f16tXUrFmT888/n4ULFxIbG8vdd9/N/PnzadCgATfccEO+MVWtWpXZs2cTGRnJxo0bueGGG1i6dCnTp0/n22+/5ffffyc6OpqDBw8CMGDAAB5//HF69+5NamoqLpeLnTt35jtvj8jISBYsWAA4zWZ33XUXAE8//TQffPAB999/P0OHDqVLly588803ZGVlkZSURM2aNbn22mt54IEHcLlcTJw4kT/++OOEt/vJCupE4KkRRIRZ05A5/Z3okbs/9enTx9s0cuTIEW699VY2btyIiJDhuaU/lyuuuIKIiAgiIiKoWrUq+/bto3btnC3H55xzjndYu3bt2LZtG2XKlKFhw4be6+ZvuOEGxo0bl2f+GRkZDBkyhBUrVhAaGsqGDRsAmDNnDrfddhvR0dEAVKpUicTERHbt2kXv3r0BZwdfFP369fN2//333zz99NMcPnyYpKQkLr30UgB++uknPvnkEwBCQ0MpX7485cuXJyYmhuXLl7Nv3z7at29PTExMkZZZHII6EaSnuyDEZTUCY4pZ6dKlvd3Dhw+nW7dufPPNN2zbto2uXbvmO02Ez0UboaGhZGZmFqmMatFuT3rttdeoVq0aK1euxOVyeXfuqprnksuC5hkWFobL5fL2575e33e9Bw4cyLfffkvbtm356KOP+PnnnwuN78477+Sjjz5i79693H777UVap+IS1I/dTEvHzhEY42dHjhyhVq1aAHz00UfFPv9mzZqxZcsWtm3bBsCkSZMKjKNGjRqEhIQwYcIEsrKcy8d79OjB+PHjSU5OBuDgwYOUK1eO2rVr8+233wKQlpZGcnIy9erVY82aNaSlpXHkyBHmzp1bYFyJiYnUqFGDjIwMPvvsM+/w7t27M3bsWMA5qXz06FEAevfuzYwZM1iyZIm39lBSgjoRpGeo0zRkVw0Z4zePPvooTzzxBOeff75351ucoqKieOedd+jZsyedO3emWrVqlC9fPk+5e++9l48//phzzz2XDRs2eI/ee/bsydVXX01sbCzt2rVj1KhRAEyYMIE33niDNm3acN5557F3717q1KlD3759adOmDQMGDKB9+/YFxjVy5Eg6derEJZdcQrNmzbzDx4wZw7x582jdujUdO3Zk9erVAISHh9OtWzf69u1b4lccSVGrVaeK2NhYXbp0abHMq33XbaxYd4Qd6ytRp3yd409gzClm7dq1NG/ePNBhBFxSUhJlypRBVbnvvvto0qQJDz74YKDDOiEul4sOHTrw5Zdf0qRJk380r/x+FyKyTFXzvV43qGsEGRlY05AxZ4D33nuPdu3a0bJlS44cOcLdd98d6JBOyJo1a2jcuDHdu3f/x0ngZAT5yWJxbiizq4aMOa09+OCDp10NwFeLFi289xUEgtUI7D4CY0yQC+pEkJIUDhFHKBVij6E2xgSv4E4EiZGERB+1x/gaY4JakCeCKEqVPhroMIwxJqCCNhFkZEBGSiSlSicFOhRjgkqZMmUA2L17N9dff32+Zbp27crxLhN//fXXvTeBAVx++eUcPny4+AINIkGbCA4dcv6WKmOJwJhAqFmzJl999dVJT587EUybNo0KFSoUR2glQlVzPK4ikII+EUSWSS68oDGniWHDoGvX4v0MG1b4Mh977DHeeecdb/+IESN49dVXSUpKonv37nTo0IHWrVvz3Xff5Zl227ZttGrVCoCUlBT69+9PmzZt6NevHykpKd5y99xzD7GxsbRs2ZJnn30WgDfeeIPdu3fTrVs3unXrBkD9+vWJj48HYPTo0bRq1YpWrVrx+uuve5fXvHlz7rrrLlq2bEmPHj1yLMfj+++/p1OnTrRv356LL76Yffv2Ac5Na7fddhutW7emTZs23ieozpgxgw4dOtC2bVu6d+/u3Q6eO5QBWrVqxbZt27wx3HvvvXTo0IGdO3fmu34AS5Ys4bzzzqNt27acc845JCYmcsEFF3jf/wBw/vnns2rVqsK/pCII2vsI3E+aJbJs3h+CMaZo+vfvz7Bhw7j33nsBmDx5MjNmzCAyMpJvvvmGcuXKnR3tswAADApJREFUER8fz7nnnsvVV19d4IUZY8eOJTo6mlWrVrFq1So6dOjgHff8889TqVIlsrKy6N69O6tWrWLo0KGMHj2aefPmUbly5RzzWrZsGR9++CG///47qkqnTp3o0qULFStWZOPGjXzxxRe899579O3blylTpnDTTTflmL5z58789ttviAjvv/8+L7/8Mq+++iojR46kfPny/PXXXwAcOnSIAwcOcNddd3kfge15hHVh1q9fz4cffuhNoPmtX7NmzejXrx+TJk3i7LPP5ujRo0RFRXkfTPf666+zYcMG0tLSaNOmTdG/sAIEbSLw1Aiiy6UWXtCY08TrAXgKdfv27dm/fz+7d+/mwIEDVKxYkbp165KRkcGTTz7J/PnzCQkJYdeuXezbt4/q1avnO5/58+d7X8LSpk2bHDu3yZMnM27cODIzM9mzZw9r1qwpdOe3YMECevfu7X2W0LXXXsuvv/7K1VdfTYMGDWjXrh0AHTt29D6ozldcXBz9+vVjz549pKenex9vPWfOHCZOnOgtV7FiRb7//nsuvPBCb5lKlSodd5vVq1ePc889t9D1ExFq1KjB2WefDUC5cs4bfPv06cPIkSN55ZVXGD9+PAMHDjzu8orCr01DItJTRNaLyCYReTyf8SIib7jHrxKRDvnNxx88iTu6XFpJLdKYM9L111/PV199xaRJk+jfvz8An332GQcOHGDZsmWsWLGCatWq5Xlkc2751Ra2bt3KqFGjmDt3LqtWreKKK6447nwKe35aUR51ff/99zNkyBD++usv/ve//3mXV9DjqvOLu7DHVfs+qrqg9StovtHR0VxyySV89913TJ48mRtvvLHAdT0RfksEIhIKvA1cBrQAbhCRFrmKXQY0cX8GAWP9FU9um3YnAHBhs1YltUhjzkj9+/dn4sSJfPXVV96rgI4cOULV/2/v/mOjru84jj9fdIUafiqoaVqxsEGMZdCW0eEQQszCAMdwZUaWbdXGprFBcVm2icNM9isZS8YWh3GpGwudOvhjgxEznco6FrNNwQpaFCcKZKwMkOmosjAm7/3x/fR6q3dH23H3Pfy+H0lz3/vct9973bu9fu77o5/PZZdRWlpKR0cHhw4dyrmNefPmpYZq7urqSh33PnnyJCNHjmTs2LEcPXqUxx57LPU9o0ePpqenJ+O2tm7dyqlTp3jnnXfYsmULc+fOHfDrSR82e+PGjan2BQsWsH79+tT9N998k2uuuYYdO3Zw4MABgNShoaqqKjo7OwHo7OxMPd5fttd31VVX0d3dzc6dO4FoSOveTqu5uZmVK1cya9asAe2BDEQ+Dw3VA/vN7HUASZuApcBLaessBdot6sL/LGmcpHIzO3K+w3znZ7v41tf6rig43RPtarVem3laO+fcwFRXV9PT00NFRQXl5eVANM3jkiVLUkM7pw/DnElraytNTU1Mnz6dmpoa6uvrAZgxYwa1tbVUV1czefJk5syZk/qelpYWFi1aRHl5OR0dHan2uro6brnlltQ2mpubqa2tzXgYKJM1a9Zw4403UlFRwezZs1N/xO+55x5WrFjBtGnTKCkp4d5776WhoYG2tjYaGho4e/ZsajrMZcuW0d7eTk1NDbNmzWLq1KkZnyvb6xs+fDibN2/mjjvuSM31/NRTTzFq1ChmzpzJmDFjaGpqGtDrGYi8DUMt6TPAQjNrDve/AHzUzG5PW+dR4Ltm9nS4vx24y8x29dtWC9EeAxMnTpx5rk8XmbRtfZFvru27VLREw5gz82Ie+VHmH5BzFwIfhjp5uru7mT9/Pvv27WPYsMwHdQY7DHU+9wgyXR7Qv9cZyDqYWRvQBtF8BEMJ03LDh2m5YSjf6ZxzxaG9vZ3Vq1ezbt26rJ3AUOSzIzgMpM/2Ugl0D2Ed55xzQGNjI42Njed9u/m8amgnMEXSJEnDgeXAtn7rbAMaw9VDs4F/5uP8gHPvZxfaLIMuv4by+5C3PQIz+4+k24HfAiXABjPbK+m28PiPgd8Ai4H9wCng/J39cC4BysrKOHHiBOPHj/dRdB1mxokTJygrG9wcK4mes9i5C92ZM2c4fPjwOa+td8lRVlZGZWUlpaX/O89KXCeLnXN5VlpamvqvVueGKrGDzjnnnIt4R+CccwnnHYFzziXcBXeyWNJxYPD/WhyZALxxHuOcL55rcDzX4BRrLijebO/HXFea2aWZHrjgOoL/h6Rd2c6ax8lzDY7nGpxizQXFmy1pufzQkHPOJZx3BM45l3BJ6wja4g6QhecaHM81OMWaC4o3W6JyJeocgXPOufdK2h6Bc865frwjcM65hEtERyBpoaRXJO2XtCrmLAclvShpt6Rdoe0SSU9KejXcXlyAHBskHZPUldaWNYeku0P9XpH0iRiyrZH0t1C33ZIWFzKbpCskdUh6WdJeSXeG9thrliNb3DUrk/SspD0h1zdCe6w1y5Er1nqlPVeJpOfDDI6FqZeZva+/iIbAfg2YDAwH9gBXx5jnIDChX9v3gFVheRWwtgA55gF1QNe5cgBXh7qNACaFepYUONsa4MsZ1i1INqAcqAvLo4G/hOeOvWY5ssVdMwGjwnIp8AwwO+6a5cgVa73Snu9LwCPAo+F+3uuVhD2CemC/mb1uZv8GNgFLY87U31JgY1jeCOR9Uk0z+wPwjwHmWApsMrPTZnaAaP6I+gJny6Yg2czsiJl1huUe4GWggiKoWY5s2RSqZmZmvROFl4YvI+aa5ciVTcF+lpIqgeuBn/R7/rzWKwkdQQXw17T7h8n9Jsk3A56Q9JykltB2uYWZ2cLtZTFly5ajWGp4u6QXwqGj3t3jgmeTVAXUEn2SLKqa9csGMdcsHObYDRwDnjSzoqhZllwQ/+/YD4GvAmfT2vJeryR0BJmmbYrzmtk5ZlYHLAJWSJoXY5aBKoYaPgB8EKgBjgDfD+0FzSZpFPBL4ItmdjLXqhna8lqzDNlir5mZvWtmNUTzkddLmpZj9bhzxVovSZ8EjpnZcwP9lgxtQ8qVhI7gMHBF2v1KoDumLJhZd7g9Bmwh2pU7KqkcINweiylethyx19DMjoY371ngQfp2gQuWTVIp0R/ah83sV6G5KGqWKVsx1KyXmb0F/B5YSJHUrH+uIqjXHOBTkg4SHcK+TtJDFKBeSegIdgJTJE2SNBxYDmyLI4ikkZJG9y4DC4CukOfmsNrNwK/jyJcjxzZguaQRkiYBU4BnCxms940QfJqobgXLJknAT4GXzWxd2kOx1yxbtiKo2aWSxoXli4CPA/uIuWbZcsVdLzO728wqzayK6O/U78zs8xSiXvk6811MX8BioispXgNWx5hjMtFZ/j3A3t4swHhgO/BquL2kAFl+QbT7e4bok8WtuXIAq0P9XgEWxZDt58CLwAvhDVBeyGzAtUS73S8Au8PX4mKoWY5scddsOvB8eP4u4Ovn+n2POVes9eqXcT59Vw3lvV4+xIRzziVcEg4NOeecy8E7AuecSzjvCJxzLuG8I3DOuYTzjsA55xLOOwLnAknvpo08uVvncaRaSVVKG03VuWLygbgDOFdE/mXRsAPOJYrvETh3DormkFgbxrB/VtKHQvuVkraHQcq2S5oY2i+XtCWMd79H0sfCpkokPRjGwH8i/FcrklZKeilsZ1NML9MlmHcEzvW5qN+hoZvSHjtpZvXAeqIRIgnL7WY2HXgYuC+03wfsMLMZRPMq7A3tU4D7zawaeAtYFtpXAbVhO7fl68U5l43/Z7FzgaS3zWxUhvaDwHVm9noY3O3vZjZe0htEwxCcCe1HzGyCpONApZmdTttGFdFwx1PC/buAUjP7tqTHgbeBrcBW6xsr37mC8D0C5wbGsixnWyeT02nL79J3ju564H5gJvCcJD935wrKOwLnBuamtNs/heU/Eo0SCfA54OmwvB1ohdQEKGOybVTSMOAKM+sgmpBkHPCevRLn8sk/eTjX56Iwa1Wvx82s9xLSEZKeIfrw9NnQthLYIOkrwHGgKbTfCbRJupXok38r0WiqmZQAD0kaSzTRyA8sGiPfuYLxcwTOnUM4R/ARM3sj7izO5YMfGnLOuYTzPQLnnEs43yNwzrmE847AOecSzjsC55xLOO8InHMu4bwjcM65hPsvKXkoe8gInMgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Acc_train = Network_Regressor.history['acc']\n",
    "Acc_val = Network_Regressor.history['val_acc']\n",
    "epochs = range(1,EPOCH+1)\n",
    "plt.plot(epochs, Acc_train, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, Acc_val, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtAfKRrxmXaO"
   },
   "source": [
    "#### 4. Pickle the model for future use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwe5KJFwmXaP",
    "outputId": "81a9f850-c205-4525-8a50-727530c3db15"
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "# Pickle model to JSON\n",
    "Regressor_model_json = NN_model_Regressor.to_json()\n",
    "with open(\"Regressor_model.json\", \"w\") as json_file:\n",
    "    json_file.write(Regressor_model_json)\n",
    "# Pickle weights to HDF5\n",
    "NN_model_Regressor.save_weights(\"Regressor_model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('Regressor_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"Regressor_model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# Evaluate\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_Test_S,Y_Test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TTyhQVXfLsTb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter 1</th>\n",
       "      <th>Parameter 2</th>\n",
       "      <th>Parameter 3</th>\n",
       "      <th>Parameter 4</th>\n",
       "      <th>Parameter 5</th>\n",
       "      <th>Parameter 6</th>\n",
       "      <th>Parameter 7</th>\n",
       "      <th>Parameter 8</th>\n",
       "      <th>Parameter 9</th>\n",
       "      <th>Parameter 10</th>\n",
       "      <th>Parameter 11</th>\n",
       "      <th>Signal_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parameter 1  Parameter 2  Parameter 3  Parameter 4  Parameter 5  \\\n",
       "0          7.4         0.70         0.00          1.9        0.076   \n",
       "1          7.8         0.88         0.00          2.6        0.098   \n",
       "2          7.8         0.76         0.04          2.3        0.092   \n",
       "3         11.2         0.28         0.56          1.9        0.075   \n",
       "4          7.4         0.70         0.00          1.9        0.076   \n",
       "\n",
       "   Parameter 6  Parameter 7  Parameter 8  Parameter 9  Parameter 10  \\\n",
       "0         11.0         34.0       0.9978         3.51          0.56   \n",
       "1         25.0         67.0       0.9968         3.20          0.68   \n",
       "2         15.0         54.0       0.9970         3.26          0.65   \n",
       "3         17.0         60.0       0.9980         3.16          0.58   \n",
       "4         11.0         34.0       0.9978         3.51          0.56   \n",
       "\n",
       "   Parameter 11  Signal_Strength  \n",
       "0           9.4                5  \n",
       "1           9.8                5  \n",
       "2           9.8                5  \n",
       "3           9.8                6  \n",
       "4           9.4                5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np       \n",
    "import pandas as pd      \n",
    "\n",
    "# read csv file with \";\" as seprators\n",
    "DB=pd.read_csv(\"Signal.csv\",sep=\",\")  \n",
    "\n",
    "# Display top 5 rows of the dataset\n",
    "DB.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data analysis & visualisation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1599, 12)\n",
      "\n",
      "Columns: 1599\n",
      "\n",
      "Rows: 12\n",
      "\n",
      "Size: 19188\n"
     ]
    }
   ],
   "source": [
    "# Shape and size of data\n",
    "\n",
    "print(\"Shape:\",DB.shape)\n",
    "print(\"\\nColumns:\",DB.shape[0])\n",
    "print(\"\\nRows:\",DB.shape[1])\n",
    "print(\"\\nSize:\",DB.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter 1        0\n",
       "Parameter 2        0\n",
       "Parameter 3        0\n",
       "Parameter 4        0\n",
       "Parameter 5        0\n",
       "Parameter 6        0\n",
       "Parameter 7        0\n",
       "Parameter 8        0\n",
       "Parameter 9        0\n",
       "Parameter 10       0\n",
       "Parameter 11       0\n",
       "Signal_Strength    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null value detection\n",
    "\n",
    "DB.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RYfeR8GYLsTk"
   },
   "outputs": [],
   "source": [
    "# Nothing to pre-process as the data is devoid of null vallues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Parameter 1</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>8.319637</td>\n",
       "      <td>1.741096</td>\n",
       "      <td>4.60000</td>\n",
       "      <td>7.1000</td>\n",
       "      <td>7.90000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>15.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 2</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.52000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>1.58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 3</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 4</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>1.9000</td>\n",
       "      <td>2.20000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>15.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 5</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>0.01200</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.07900</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.61100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 6</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>72.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 7</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>38.00000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>289.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 8</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.99007</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>0.99675</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>1.00369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 9</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>2.74000</td>\n",
       "      <td>3.2100</td>\n",
       "      <td>3.31000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>4.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 10</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>0.33000</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.62000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 11</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>8.40000</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>10.20000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>14.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Signal_Strength</th>\n",
       "      <td>1599.0</td>\n",
       "      <td>5.636023</td>\n",
       "      <td>0.807569</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count       mean        std      min      25%       50%  \\\n",
       "Parameter 1      1599.0   8.319637   1.741096  4.60000   7.1000   7.90000   \n",
       "Parameter 2      1599.0   0.527821   0.179060  0.12000   0.3900   0.52000   \n",
       "Parameter 3      1599.0   0.270976   0.194801  0.00000   0.0900   0.26000   \n",
       "Parameter 4      1599.0   2.538806   1.409928  0.90000   1.9000   2.20000   \n",
       "Parameter 5      1599.0   0.087467   0.047065  0.01200   0.0700   0.07900   \n",
       "Parameter 6      1599.0  15.874922  10.460157  1.00000   7.0000  14.00000   \n",
       "Parameter 7      1599.0  46.467792  32.895324  6.00000  22.0000  38.00000   \n",
       "Parameter 8      1599.0   0.996747   0.001887  0.99007   0.9956   0.99675   \n",
       "Parameter 9      1599.0   3.311113   0.154386  2.74000   3.2100   3.31000   \n",
       "Parameter 10     1599.0   0.658149   0.169507  0.33000   0.5500   0.62000   \n",
       "Parameter 11     1599.0  10.422983   1.065668  8.40000   9.5000  10.20000   \n",
       "Signal_Strength  1599.0   5.636023   0.807569  3.00000   5.0000   6.00000   \n",
       "\n",
       "                       75%        max  \n",
       "Parameter 1       9.200000   15.90000  \n",
       "Parameter 2       0.640000    1.58000  \n",
       "Parameter 3       0.420000    1.00000  \n",
       "Parameter 4       2.600000   15.50000  \n",
       "Parameter 5       0.090000    0.61100  \n",
       "Parameter 6      21.000000   72.00000  \n",
       "Parameter 7      62.000000  289.00000  \n",
       "Parameter 8       0.997835    1.00369  \n",
       "Parameter 9       3.400000    4.01000  \n",
       "Parameter 10      0.730000    2.00000  \n",
       "Parameter 11     11.100000   14.90000  \n",
       "Signal_Strength   6.000000    8.00000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter 1</th>\n",
       "      <th>Parameter 2</th>\n",
       "      <th>Parameter 3</th>\n",
       "      <th>Parameter 4</th>\n",
       "      <th>Parameter 5</th>\n",
       "      <th>Parameter 6</th>\n",
       "      <th>Parameter 7</th>\n",
       "      <th>Parameter 8</th>\n",
       "      <th>Parameter 9</th>\n",
       "      <th>Parameter 10</th>\n",
       "      <th>Parameter 11</th>\n",
       "      <th>Signal_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Parameter 1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.256131</td>\n",
       "      <td>0.671703</td>\n",
       "      <td>0.114777</td>\n",
       "      <td>0.093705</td>\n",
       "      <td>-0.153794</td>\n",
       "      <td>-0.113181</td>\n",
       "      <td>0.668047</td>\n",
       "      <td>-0.682978</td>\n",
       "      <td>0.183006</td>\n",
       "      <td>-0.061668</td>\n",
       "      <td>0.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 2</th>\n",
       "      <td>-0.256131</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.552496</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>-0.010504</td>\n",
       "      <td>0.076470</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.234937</td>\n",
       "      <td>-0.260987</td>\n",
       "      <td>-0.202288</td>\n",
       "      <td>-0.390558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 3</th>\n",
       "      <td>0.671703</td>\n",
       "      <td>-0.552496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143577</td>\n",
       "      <td>0.203823</td>\n",
       "      <td>-0.060978</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.364947</td>\n",
       "      <td>-0.541904</td>\n",
       "      <td>0.312770</td>\n",
       "      <td>0.109903</td>\n",
       "      <td>0.226373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 4</th>\n",
       "      <td>0.114777</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.143577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055610</td>\n",
       "      <td>0.187049</td>\n",
       "      <td>0.203028</td>\n",
       "      <td>0.355283</td>\n",
       "      <td>-0.085652</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>0.042075</td>\n",
       "      <td>0.013732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 5</th>\n",
       "      <td>0.093705</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>0.203823</td>\n",
       "      <td>0.055610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.200632</td>\n",
       "      <td>-0.265026</td>\n",
       "      <td>0.371260</td>\n",
       "      <td>-0.221141</td>\n",
       "      <td>-0.128907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 6</th>\n",
       "      <td>-0.153794</td>\n",
       "      <td>-0.010504</td>\n",
       "      <td>-0.060978</td>\n",
       "      <td>0.187049</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.667666</td>\n",
       "      <td>-0.021946</td>\n",
       "      <td>0.070377</td>\n",
       "      <td>0.051658</td>\n",
       "      <td>-0.069408</td>\n",
       "      <td>-0.050656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 7</th>\n",
       "      <td>-0.113181</td>\n",
       "      <td>0.076470</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.203028</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.667666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071269</td>\n",
       "      <td>-0.066495</td>\n",
       "      <td>0.042947</td>\n",
       "      <td>-0.205654</td>\n",
       "      <td>-0.185100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 8</th>\n",
       "      <td>0.668047</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.364947</td>\n",
       "      <td>0.355283</td>\n",
       "      <td>0.200632</td>\n",
       "      <td>-0.021946</td>\n",
       "      <td>0.071269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.341699</td>\n",
       "      <td>0.148506</td>\n",
       "      <td>-0.496180</td>\n",
       "      <td>-0.174919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 9</th>\n",
       "      <td>-0.682978</td>\n",
       "      <td>0.234937</td>\n",
       "      <td>-0.541904</td>\n",
       "      <td>-0.085652</td>\n",
       "      <td>-0.265026</td>\n",
       "      <td>0.070377</td>\n",
       "      <td>-0.066495</td>\n",
       "      <td>-0.341699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.196648</td>\n",
       "      <td>0.205633</td>\n",
       "      <td>-0.057731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 10</th>\n",
       "      <td>0.183006</td>\n",
       "      <td>-0.260987</td>\n",
       "      <td>0.312770</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>0.371260</td>\n",
       "      <td>0.051658</td>\n",
       "      <td>0.042947</td>\n",
       "      <td>0.148506</td>\n",
       "      <td>-0.196648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093595</td>\n",
       "      <td>0.251397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parameter 11</th>\n",
       "      <td>-0.061668</td>\n",
       "      <td>-0.202288</td>\n",
       "      <td>0.109903</td>\n",
       "      <td>0.042075</td>\n",
       "      <td>-0.221141</td>\n",
       "      <td>-0.069408</td>\n",
       "      <td>-0.205654</td>\n",
       "      <td>-0.496180</td>\n",
       "      <td>0.205633</td>\n",
       "      <td>0.093595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Signal_Strength</th>\n",
       "      <td>0.124052</td>\n",
       "      <td>-0.390558</td>\n",
       "      <td>0.226373</td>\n",
       "      <td>0.013732</td>\n",
       "      <td>-0.128907</td>\n",
       "      <td>-0.050656</td>\n",
       "      <td>-0.185100</td>\n",
       "      <td>-0.174919</td>\n",
       "      <td>-0.057731</td>\n",
       "      <td>0.251397</td>\n",
       "      <td>0.476166</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Parameter 1  Parameter 2  Parameter 3  Parameter 4  \\\n",
       "Parameter 1         1.000000    -0.256131     0.671703     0.114777   \n",
       "Parameter 2        -0.256131     1.000000    -0.552496     0.001918   \n",
       "Parameter 3         0.671703    -0.552496     1.000000     0.143577   \n",
       "Parameter 4         0.114777     0.001918     0.143577     1.000000   \n",
       "Parameter 5         0.093705     0.061298     0.203823     0.055610   \n",
       "Parameter 6        -0.153794    -0.010504    -0.060978     0.187049   \n",
       "Parameter 7        -0.113181     0.076470     0.035533     0.203028   \n",
       "Parameter 8         0.668047     0.022026     0.364947     0.355283   \n",
       "Parameter 9        -0.682978     0.234937    -0.541904    -0.085652   \n",
       "Parameter 10        0.183006    -0.260987     0.312770     0.005527   \n",
       "Parameter 11       -0.061668    -0.202288     0.109903     0.042075   \n",
       "Signal_Strength     0.124052    -0.390558     0.226373     0.013732   \n",
       "\n",
       "                 Parameter 5  Parameter 6  Parameter 7  Parameter 8  \\\n",
       "Parameter 1         0.093705    -0.153794    -0.113181     0.668047   \n",
       "Parameter 2         0.061298    -0.010504     0.076470     0.022026   \n",
       "Parameter 3         0.203823    -0.060978     0.035533     0.364947   \n",
       "Parameter 4         0.055610     0.187049     0.203028     0.355283   \n",
       "Parameter 5         1.000000     0.005562     0.047400     0.200632   \n",
       "Parameter 6         0.005562     1.000000     0.667666    -0.021946   \n",
       "Parameter 7         0.047400     0.667666     1.000000     0.071269   \n",
       "Parameter 8         0.200632    -0.021946     0.071269     1.000000   \n",
       "Parameter 9        -0.265026     0.070377    -0.066495    -0.341699   \n",
       "Parameter 10        0.371260     0.051658     0.042947     0.148506   \n",
       "Parameter 11       -0.221141    -0.069408    -0.205654    -0.496180   \n",
       "Signal_Strength    -0.128907    -0.050656    -0.185100    -0.174919   \n",
       "\n",
       "                 Parameter 9  Parameter 10  Parameter 11  Signal_Strength  \n",
       "Parameter 1        -0.682978      0.183006     -0.061668         0.124052  \n",
       "Parameter 2         0.234937     -0.260987     -0.202288        -0.390558  \n",
       "Parameter 3        -0.541904      0.312770      0.109903         0.226373  \n",
       "Parameter 4        -0.085652      0.005527      0.042075         0.013732  \n",
       "Parameter 5        -0.265026      0.371260     -0.221141        -0.128907  \n",
       "Parameter 6         0.070377      0.051658     -0.069408        -0.050656  \n",
       "Parameter 7        -0.066495      0.042947     -0.205654        -0.185100  \n",
       "Parameter 8        -0.341699      0.148506     -0.496180        -0.174919  \n",
       "Parameter 9         1.000000     -0.196648      0.205633        -0.057731  \n",
       "Parameter 10       -0.196648      1.000000      0.093595         0.251397  \n",
       "Parameter 11        0.205633      0.093595      1.000000         0.476166  \n",
       "Signal_Strength    -0.057731      0.251397      0.476166         1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORRELATION=DB.corr()\n",
    "CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplots(figsize=(20,8))\n",
    "sns.heatmap(CORRELATION)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Performing univariate, bivariate and multivariate analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07978419 0.0971146  0.08198794 0.07920675 0.07618029 0.07414144\n",
      " 0.09951916 0.08524015 0.07581775 0.10049406 0.15051366]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Importance\n",
    "\n",
    "# Independent variables\n",
    "X=DB.drop('Signal_Strength',axis=1) \n",
    "\n",
    "# Target variable\n",
    "Y=DB['Signal_Strength']                   \n",
    "\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,Y)\n",
    "\n",
    "#using inbuilt class \"feature_importances\" of tree based classifiers\n",
    "print(model.feature_importances_) \n",
    "\n",
    "#ploting graph of feature importances\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "#Observation: Most Effective - Parameter 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Designing, training, tuning and testing a neural network classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Independent variables\n",
    "X=DB.drop('Signal_Strength',axis=1)\n",
    "\n",
    "# Target variable\n",
    "Y=DB['Signal_Strength']               \n",
    "\n",
    "X_Train,X_Test,Y_Train,Y_Test=train_test_split(X, Y, train_size=0.7, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling train data\n",
    "X_Train_S = StandardScaler().fit_transform(X_Train) \n",
    "\n",
    "# Scaling test data\n",
    "X_Test_S = StandardScaler().fit_transform(X_Test)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y data into categorical (one-hot encoding)\n",
    "from keras.utils.np_utils import to_categorical\n",
    "Y_Train = to_categorical(Y_Train)\n",
    "Y_Test = to_categorical(Y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1119, 11)\n",
      "(480, 11)\n",
      "(1119, 9)\n",
      "(480, 9)\n"
     ]
    }
   ],
   "source": [
    "# Confirming Matrix size\n",
    "print(X_Train_S.shape)\n",
    "print(X_Test_S.shape)\n",
    "print(Y_Train.shape)\n",
    "print(Y_Test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential # Forward prop\n",
    "from keras.layers import Dense, Activation, LeakyReLU\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ULCNp_7DLsTx"
   },
   "outputs": [],
   "source": [
    "NN_model_Classifier = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model_Classifier.add(Dense(128, kernel_initializer='normal',input_dim = X_Train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model_Classifier.add(Dense(64, kernel_initializer='normal',activation='relu'))  # sigmoid, tanh\n",
    "\n",
    "NN_model_Classifier.add(Dense(32, kernel_initializer='normal'))\n",
    "NN_model_Classifier.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "NN_model_Classifier.add(Dense(16, kernel_initializer='normal'))\n",
    "NN_model_Classifier.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model_Classifier.add(Dense(9, kernel_initializer='normal',activation='softmax'))  # except softmax\n",
    "\n",
    "# Compile the network :\n",
    "NN_model_Classifier.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "NN_model_Classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH=400\n",
    "Network_Classifier=NN_model_Classifier.fit(X_Train_S, Y_Train, validation_data=(X_Test_S,Y_Test), epochs=EPOCH, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = Network_Classifier.history['loss']\n",
    "loss_val = Network_Classifier.history['val_loss']\n",
    "epochs = range(1,EPOCH+1)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Acc_train = Network_Classifier.history['acc']\n",
    "Acc_val = Network_Classifier.history['val_acc']\n",
    "epochs = range(1,EPOCH+1)\n",
    "plt.plot(epochs, Acc_train, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, Acc_val, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Pickle the model for future use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "# Pickle model to JSON\n",
    "Classifier_model_json = NN_model_Classifier.to_json()\n",
    "with open(\"Classifier_model.json\", \"w\") as json_file:\n",
    "    json_file.write(Classifier_model_json)\n",
    "# Pickle weights to HDF5\n",
    "NN_model_Classifier.save_weights(\"Classifier_model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('Classifier_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"Classifier_model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# Evaluate\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_Test_S,Y_Test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# App window\n",
    "win = tk.Tk()\n",
    "# Window Title\n",
    "win.title('Neural Networks GUI') \n",
    "\n",
    "# Importing data frame name\n",
    "\n",
    "Name=ttk.Label(win,text=\"    Step 1: File Name\")\n",
    "Name.grid(row=0,column=0,sticky=tk.W)\n",
    "\n",
    "Name_var=tk.StringVar()\n",
    "Name_entrybox=ttk.Entry(win,width=16,textvariable=Name_var)\n",
    "Name_entrybox.grid(row=0,column=1)\n",
    "\n",
    "def Import_Data():\n",
    "    global DB\n",
    "    DF_Name=Name_var.get()\n",
    "    DB_extension=re.findall(\"\\..*\", DF_Name) \n",
    "    if DB_extension==['.xlsx']:\n",
    "        DB=pd.read_excel(DF_Name)\n",
    "    elif DB_extension==['.csv']:\n",
    "        DB=pd.read_csv(DF_Name)\n",
    "    # Blank empty window to print confirmation\n",
    "    confirm=\"Done\"\n",
    "    Confirm_entrybox=ttk.Entry(win,width=16)\n",
    "    Confirm_entrybox.grid(row=0,column=3)\n",
    "    Confirm_entrybox.insert(1,str(confirm))   \n",
    "\n",
    "Import_Data_Button=ttk.Button(win,text=\"Import Data\",command=Import_Data)\n",
    "Import_Data_Button.grid(row=0,column=2)\n",
    "\n",
    "\n",
    "# Target data frame name\n",
    "\n",
    "Target=ttk.Label(win,text=\"    Step 2: Target Colummn\")\n",
    "Target.grid(row=1,column=0,sticky=tk.W)\n",
    "\n",
    "Target_var=tk.StringVar()\n",
    "Target_entrybox=ttk.Entry(win,width=16,textvariable=Target_var)\n",
    "Target_entrybox.grid(row=1,column=1)\n",
    "\n",
    "def Target_Data():\n",
    "    global DB,X,y, Target_Name, X_train, X_test, y_train, y_test\n",
    "    Target_Name=Target_var.get()\n",
    "    \n",
    "    Column_name=DB.columns\n",
    "    Column_name\n",
    "    found=0\n",
    "\n",
    "    for i in range(len(Column_name)):\n",
    "        if Column_name[i]==Target_Name:\n",
    "            confirm=\"Found\"\n",
    "        else:\n",
    "            confirm=\"Not Found\"\n",
    "    \n",
    "    Confirm_entrybox=ttk.Entry(win,width=16)\n",
    "    Confirm_entrybox.grid(row=1,column=3)\n",
    "    Confirm_entrybox.insert(1,str(confirm))\n",
    "\n",
    "\n",
    "Target_Button=ttk.Button(win,text=\"Import Target\",command=Target_Data)\n",
    "Target_Button.grid(row=1,column=2)\n",
    "\n",
    "\n",
    "# Regression\n",
    "\n",
    "Modelling=ttk.Label(win,text=\"    Step 3: Neural Network Regressor\")\n",
    "Modelling.grid(row=2,column=0,sticky=tk.W)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential # Forward prop\n",
    "from keras.layers import Dense, Activation, LeakyReLU\n",
    "from keras import optimizers\n",
    "\n",
    "Regression=ttk.Label(win,text=\"Regression\")\n",
    "Regression.grid(row=3,column=0,sticky=tk.E)\n",
    "\n",
    "\n",
    "def NNReg():\n",
    "    global DB,X,Y,NN_model_Regressor\n",
    "    \n",
    "    # Regression\n",
    "    \n",
    "    # Independent variables\n",
    "    X=DB.drop('Signal_Strength',axis=1)\n",
    "    \n",
    "    # Target variable\n",
    "    Y=DB['Signal_Strength']               \n",
    "\n",
    "    X_Train,X_Test,Y_Train,Y_Test=train_test_split(X, Y, train_size=0.7, random_state=12)\n",
    "    \n",
    "    X_Train_S = StandardScaler().fit_transform(X_Train)   # Scale train data\n",
    "    X_Test_S = StandardScaler().fit_transform(X_Test)     # Scale test data\n",
    "    \n",
    "    # Model \n",
    "    NN_model_Regressor = Sequential()\n",
    "    NN_model_Regressor.add(Dense(128, kernel_initializer='normal',input_dim = X_Train.shape[1], activation='relu'))\n",
    "    NN_model_Regressor.add(Dense(64, kernel_initializer='normal',activation='relu'))  # sigmoid, tanh\n",
    "    NN_model_Regressor.add(Dense(32, kernel_initializer='normal'))\n",
    "    NN_model_Regressor.add(LeakyReLU(alpha=0.1))\n",
    "    NN_model_Regressor.add(Dense(16, kernel_initializer='normal'))\n",
    "    NN_model_Regressor.add(LeakyReLU(alpha=0.1))\n",
    "    NN_model_Regressor.add(Dense(1, kernel_initializer='normal'))  # except softmax\n",
    "    NN_model_Regressor.add(LeakyReLU(alpha=0.1))\n",
    "    \n",
    "    # Compile the network :\n",
    "    NN_model_Regressor.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "    NN_model_Regressor.summary()\n",
    "    EPOCH=400\n",
    "    Network_Regressor=NN_model_Regressor.fit(X_Train_S, Y_Train, validation_data=(X_Test_S,Y_Test), epochs=EPOCH, batch_size=200)\n",
    "    \n",
    "    \n",
    "    Confirm_entrybox=ttk.Entry(win,width=16)\n",
    "    Confirm_entrybox.grid(row=3,column=2)\n",
    "    Confirm_entrybox.insert(1,str(\"Network Trained\"))\n",
    "\n",
    "Reg_Button=ttk.Button(win,text=\"Train\",command=NNReg)\n",
    "Reg_Button.grid(row=3,column=1)\n",
    "\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "Pickle=ttk.Label(win,text=\"Pickle\")\n",
    "Pickle.grid(row=4,column=0,sticky=tk.E)\n",
    "\n",
    "def Pickle():\n",
    "    # Pickle model to JSON\n",
    "    Regressor_model_json = NN_model_Regressor.to_json()\n",
    "    with open(\"Regressor_model.json\", \"w\") as json_file:\n",
    "        json_file.write(Regressor_model_json)\n",
    "    # Pickle weights to HDF5\n",
    "    NN_model_Regressor.save_weights(\"Regressor_model.h5\")\n",
    "    \n",
    "    Confirm_entrybox=ttk.Entry(win,width=16)\n",
    "    Confirm_entrybox.grid(row=4,column=2)\n",
    "    Confirm_entrybox.insert(1,str(\"Saved model to disk\"))\n",
    "\n",
    "Pickle_Button=ttk.Button(win,text=\"Run\",command=Pickle)\n",
    "Pickle_Button.grid(row=4,column=1)\n",
    "\n",
    "\n",
    "# Classifier\n",
    "\n",
    "Modelling=ttk.Label(win,text=\"    Step 4: Neural Network Classifier\")\n",
    "Modelling.grid(row=5,column=0,sticky=tk.W)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential # Forward prop\n",
    "from keras.layers import Dense, Activation, LeakyReLU\n",
    "from keras import optimizers\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "Classifier=ttk.Label(win,text=\"Classifier\")\n",
    "Classifier.grid(row=6,column=0,sticky=tk.E)\n",
    "\n",
    "def NNClassi():\n",
    "    global DB,X,Y,NN_model_Classifier\n",
    "    \n",
    "    # Regression\n",
    "    \n",
    "    # Independent variables\n",
    "    X=DB.drop('Signal_Strength',axis=1)\n",
    "    \n",
    "    # Target variable\n",
    "    Y=DB['Signal_Strength']               \n",
    "\n",
    "    X_Train,X_Test,Y_Train,Y_Test=train_test_split(X, Y, train_size=0.7, random_state=12)\n",
    "\n",
    "    X_Train,X_Test,Y_Train,Y_Test=train_test_split(X, Y, train_size=0.7, random_state=12)\n",
    "    \n",
    "    X_Train_S = StandardScaler().fit_transform(X_Train)   # Scale train data\n",
    "    X_Test_S = StandardScaler().fit_transform(X_Test)     # Scale test data\n",
    "    \n",
    "    Y_Train = to_categorical(Y_Train)\n",
    "    Y_Test = to_categorical(Y_Test)\n",
    "    \n",
    "    NN_model_Classifier = Sequential()\n",
    "\n",
    "    # The Input Layer :\n",
    "    NN_model_Classifier.add(Dense(128, kernel_initializer='normal',input_dim = X_Train.shape[1], activation='relu'))\n",
    "\n",
    "    # The Hidden Layers :\n",
    "    NN_model_Classifier.add(Dense(64, kernel_initializer='normal',activation='relu'))  # sigmoid, tanh\n",
    "\n",
    "    NN_model_Classifier.add(Dense(32, kernel_initializer='normal'))\n",
    "    NN_model_Classifier.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "    NN_model_Classifier.add(Dense(16, kernel_initializer='normal'))\n",
    "    NN_model_Classifier.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "    # The Output Layer :\n",
    "    NN_model_Classifier.add(Dense(9, kernel_initializer='normal',activation='softmax'))  # except softmax\n",
    "\n",
    "    # Compile the network :\n",
    "    NN_model_Classifier.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "    NN_model_Classifier.summary()\n",
    "    EPOCH=400\n",
    "    Network_Classifier=NN_model_Classifier.fit(X_Train_S, Y_Train, validation_data=(X_Test_S,Y_Test), epochs=EPOCH, batch_size=200)\n",
    "    \n",
    "    \n",
    "    Confirm_entrybox=ttk.Entry(win,width=16)\n",
    "    Confirm_entrybox.grid(row=6,column=2)\n",
    "    Confirm_entrybox.insert(1,str(\"Network Trained\"))\n",
    "\n",
    "Cla_Button=ttk.Button(win,text=\"Train\",command=NNClassi)\n",
    "Cla_Button.grid(row=6,column=1)\n",
    "\n",
    "Pickle=ttk.Label(win,text=\"Pickle\")\n",
    "Pickle.grid(row=4,column=0,sticky=tk.E)\n",
    "\n",
    "def Pickle2():\n",
    "    # Pickle model to JSON\n",
    "    Classifier_model_json = NN_model_Classifier.to_json()\n",
    "    with open(\"Classifier_model.json\", \"w\") as json_file:\n",
    "        json_file.write(Classifier_model_json)\n",
    "    # Pickle weights to HDF5\n",
    "    NN_model_Classifier.save_weights(\"Classifier_model.h5\")\n",
    "    \n",
    "    Confirm_entrybox=ttk.Entry(win,width=16)\n",
    "    Confirm_entrybox.grid(row=7,column=2)\n",
    "    Confirm_entrybox.insert(1,str(\"Saved model to disk\"))\n",
    "\n",
    "Pickle_Button2=ttk.Button(win,text=\"Run\",command=Pickle2)\n",
    "Pickle_Button2.grid(row=7,column=1)\n",
    "\n",
    "\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGJRmbOj1m6n"
   },
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z2Z7-OAs8QG"
   },
   "source": [
    "Mounting the drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REFUdThmpz_d",
    "outputId": "4b64537a-9706-4812-eee0-280f17df71b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucnevGLoyKf_"
   },
   "source": [
    "Checking the version of installed tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W5as47YxyJVk",
    "outputId": "77f8d501-2d09-4b2c-be41-539232ae31c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "# used to supress display of warnings\n",
    "import warnings\n",
    "\n",
    "# os is used to provide a way of using operating system dependent functionality\n",
    "# We use it for setting working folder\n",
    "import os\n",
    "\n",
    "# Pandas is used for data manipulation and analysis\n",
    "import pandas as pd \n",
    "\n",
    "# Numpy is used for large, multi-dimensional arrays and matrices, along with mathematical operators on these arrays\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib is a data visualization library for 2D plots of arrays, built on NumPy arrays \n",
    "# and designed to work with the broader SciPy stack\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Seaborn is based on matplotlib, which aids in drawing attractive and informative statistical graphics.\n",
    "import seaborn as sns\n",
    "import tensorflow \n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qCKU7-YkHDq3"
   },
   "outputs": [],
   "source": [
    "# suppress display of warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# display all dataframe columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# to set the limit to 3 decimals\n",
    "pd.options.display.float_format = '{:.7f}'.format\n",
    "\n",
    "# display all dataframe rows\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lsux2ZwyTTR"
   },
   "source": [
    "Let us now, load the dataset that is available as a .h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BApX9qgNsqV0",
    "outputId": "13e451b1-2432-48fd-aed7-7863a689812e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the file as readonly\n",
    "h5f = h5py.File('/content/drive/My Drive/Data/Autonomous_Vehicles_SVHN_single_grey1.h5', 'r')\n",
    "\n",
    "h5f.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDORGE7AHWtV"
   },
   "source": [
    "## 2. Data pre-processing & visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aKEpYZ4w2yjg"
   },
   "outputs": [],
   "source": [
    "# Load the training, test and validation set\n",
    "X_train = h5f['X_train'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "X_test = h5f['X_test'][:]\n",
    "y_test = h5f['y_test'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJHUOjjM3aUH"
   },
   "source": [
    "Checking few contents of features and labels of one example from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J4rkRt553Ipq",
    "outputId": "ab8849d8-1754-4039-e425-87842a8c0213"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 33.0704,  30.2601,  26.852 , ...,  71.4471,  58.2204,\n",
       "          42.9939],\n",
       "        [ 25.2283,  25.5533,  29.9765, ..., 113.0209, 103.3639,\n",
       "          84.2949],\n",
       "        [ 26.2775,  22.6137,  40.4763, ..., 113.3028, 121.775 ,\n",
       "         115.4228],\n",
       "        ...,\n",
       "        [ 28.5502,  36.212 ,  45.0801, ...,  24.1359,  25.0927,\n",
       "          26.0603],\n",
       "        [ 38.4352,  26.4733,  23.2717, ...,  28.1094,  29.4683,\n",
       "          30.0661],\n",
       "        [ 50.2984,  26.0773,  24.0389, ...,  49.6682,  50.853 ,\n",
       "          53.0377]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prCBSrZg3SFQ",
    "outputId": "d8c65b5c-fe69-4623-dfe9-85360f111012"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHhJ7jTd3mKk",
    "outputId": "a343ed29-1285-4cda-f795-b6f897a73286"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 40.558 ,  46.7917,  48.9764, ..., 112.1153, 112.9904,\n",
       "         112.1646],\n",
       "        [ 39.4379,  44.2911,  47.1768, ..., 111.0122, 110.9475,\n",
       "         109.9368],\n",
       "        [ 38.4488,  43.6394,  48.7098, ..., 109.8921, 109.9414,\n",
       "         109.1048],\n",
       "        ...,\n",
       "        [ 34.9869,  35.4707,  39.6676, ..., 109.211 , 109.9074,\n",
       "         112.7346],\n",
       "        [ 35.6602,  35.5462,  40.3193, ..., 110.9998, 112.049 ,\n",
       "         114.3431],\n",
       "        [ 36.1871,  35.4214,  40.6998, ..., 110.0169, 111.2017,\n",
       "         114.1906]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qr4Nz_v03nm-",
    "outputId": "56c6e1cf-c269-46b0-d3ca-cc97b73b37d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxODV6HKykuc"
   },
   "source": [
    "Visualising the first 10 images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "id": "Bvsc8ytHsqWD",
    "outputId": "a8fa3e6a-7274-468b-c5a2-187bab5a3bc4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image: [2 6 7 4 4 0 3 0 7 3]\n"
     ]
    }
   ],
   "source": [
    "# visualizing the first 10 images in the dataset and their labels\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X_train[i], cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('label for each of the above image: %s' % (y_train[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1ZC0x0I3-jo"
   },
   "source": [
    "Checking the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ju4-rQ9y39RW",
    "outputId": "306cbade-be11-4f4b-c13c-47673177d91e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_3SxY7O4DJB",
    "outputId": "5d42b6bd-4ff3-4593-9a85-787cb02dbd26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzoyeXHOy80N"
   },
   "source": [
    "Need to reshape the X_train and X_test so that the same can be fed for model building. Currently we have a 3D tensor and we need to feed a 2D tensor into the model.\n",
    "\n",
    "- We will normalize the data. We divide by 255 as this is a grayscale image and can take values from 0-255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9YPwf9ysqWU",
    "outputId": "709f501e-9ac9-4f4e-9d97-c3fdbfdc9870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized Training set (42000, 1024, 1) (42000,)\n",
      "Resized Test set (18000, 1024, 1) (18000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 1024, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1024, 1)\n",
    "\n",
    "# # normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print('Resized Training set', X_train.shape, y_train.shape)\n",
    "print('Resized Test set', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bogxx3cezol1"
   },
   "source": [
    "Encoding the target variables. We need to one hot encode the labels for the model to understand the labels better. We will be using categorical cross entropy as our loss function and for this purpose we need our labels to be in one hot encoded format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zL0lYER4sqWw",
    "outputId": "8b4db398-2146-4e6d-f8c5-2618d17d30a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes in this dataset are: 10\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# no.of classes\n",
    "num_classes = y_test.shape[1] \n",
    "print(\"The number of classes in this dataset are:\",num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xztigzzfITt-"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## 3. Designing, training, tuning and testing a neural network image classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJDUoaEj1d6e"
   },
   "source": [
    "#### Building the neural network model, fitting the training data, testing it and providing model summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Cmi81Gr5sqW-"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "def nn_model():\n",
    "    # create model\n",
    "    model = Sequential()  \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu')) ###Multiple Dense units with Relu activation\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbGCdivk6gM7"
   },
   "source": [
    "Creating an object of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "geazN4wi6Y84"
   },
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = nn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Mfh8tFcB7oj4"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "sgd = optimizers.Adam(lr=1e-3)\n",
    "\n",
    "### Loss function = Categorical cross entropy\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5t90ufg46jLl"
   },
   "source": [
    "Fitting the model on the training dataset along with it's equivalent one hot encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "It28yqDu6dLW",
    "outputId": "c61aa242-2935-4528-8fcd-a37d513753bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 - 4s - loss: 2.3015 - accuracy: 0.1086 - val_loss: 2.2705 - val_accuracy: 0.1313\n",
      "Epoch 2/100\n",
      "140/140 - 0s - loss: 2.1670 - accuracy: 0.1952 - val_loss: 1.9661 - val_accuracy: 0.2987\n",
      "Epoch 3/100\n",
      "140/140 - 0s - loss: 1.7231 - accuracy: 0.4030 - val_loss: 1.5149 - val_accuracy: 0.4902\n",
      "Epoch 4/100\n",
      "140/140 - 0s - loss: 1.4136 - accuracy: 0.5320 - val_loss: 1.2990 - val_accuracy: 0.5783\n",
      "Epoch 5/100\n",
      "140/140 - 0s - loss: 1.2865 - accuracy: 0.5821 - val_loss: 1.2255 - val_accuracy: 0.6043\n",
      "Epoch 6/100\n",
      "140/140 - 0s - loss: 1.1954 - accuracy: 0.6179 - val_loss: 1.1652 - val_accuracy: 0.6282\n",
      "Epoch 7/100\n",
      "140/140 - 0s - loss: 1.1394 - accuracy: 0.6398 - val_loss: 1.1142 - val_accuracy: 0.6457\n",
      "Epoch 8/100\n",
      "140/140 - 0s - loss: 1.0855 - accuracy: 0.6588 - val_loss: 1.0712 - val_accuracy: 0.6641\n",
      "Epoch 9/100\n",
      "140/140 - 0s - loss: 1.0450 - accuracy: 0.6740 - val_loss: 1.0296 - val_accuracy: 0.6799\n",
      "Epoch 10/100\n",
      "140/140 - 0s - loss: 1.0166 - accuracy: 0.6837 - val_loss: 1.0040 - val_accuracy: 0.6886\n",
      "Epoch 11/100\n",
      "140/140 - 0s - loss: 0.9920 - accuracy: 0.6928 - val_loss: 1.0023 - val_accuracy: 0.6874\n",
      "Epoch 12/100\n",
      "140/140 - 0s - loss: 0.9569 - accuracy: 0.7018 - val_loss: 0.9442 - val_accuracy: 0.7102\n",
      "Epoch 13/100\n",
      "140/140 - 0s - loss: 0.9249 - accuracy: 0.7141 - val_loss: 0.9841 - val_accuracy: 0.7033\n",
      "Epoch 14/100\n",
      "140/140 - 0s - loss: 0.8970 - accuracy: 0.7236 - val_loss: 0.9345 - val_accuracy: 0.7205\n",
      "Epoch 15/100\n",
      "140/140 - 0s - loss: 0.8653 - accuracy: 0.7332 - val_loss: 0.8972 - val_accuracy: 0.7290\n",
      "Epoch 16/100\n",
      "140/140 - 0s - loss: 0.8551 - accuracy: 0.7384 - val_loss: 0.8640 - val_accuracy: 0.7410\n",
      "Epoch 17/100\n",
      "140/140 - 0s - loss: 0.8347 - accuracy: 0.7436 - val_loss: 0.8796 - val_accuracy: 0.7329\n",
      "Epoch 18/100\n",
      "140/140 - 0s - loss: 0.8083 - accuracy: 0.7522 - val_loss: 0.8605 - val_accuracy: 0.7362\n",
      "Epoch 19/100\n",
      "140/140 - 0s - loss: 0.8060 - accuracy: 0.7509 - val_loss: 0.8300 - val_accuracy: 0.7524\n",
      "Epoch 20/100\n",
      "140/140 - 0s - loss: 0.7896 - accuracy: 0.7598 - val_loss: 0.8422 - val_accuracy: 0.7439\n",
      "Epoch 21/100\n",
      "140/140 - 0s - loss: 0.7728 - accuracy: 0.7633 - val_loss: 0.8135 - val_accuracy: 0.7543\n",
      "Epoch 22/100\n",
      "140/140 - 0s - loss: 0.7601 - accuracy: 0.7660 - val_loss: 0.9244 - val_accuracy: 0.7186\n",
      "Epoch 23/100\n",
      "140/140 - 0s - loss: 0.7451 - accuracy: 0.7722 - val_loss: 0.7928 - val_accuracy: 0.7604\n",
      "Epoch 24/100\n",
      "140/140 - 0s - loss: 0.7400 - accuracy: 0.7723 - val_loss: 0.7858 - val_accuracy: 0.7649\n",
      "Epoch 25/100\n",
      "140/140 - 0s - loss: 0.7308 - accuracy: 0.7755 - val_loss: 0.8194 - val_accuracy: 0.7537\n",
      "Epoch 26/100\n",
      "140/140 - 0s - loss: 0.7140 - accuracy: 0.7823 - val_loss: 0.7694 - val_accuracy: 0.7690\n",
      "Epoch 27/100\n",
      "140/140 - 0s - loss: 0.7107 - accuracy: 0.7829 - val_loss: 0.7653 - val_accuracy: 0.7693\n",
      "Epoch 28/100\n",
      "140/140 - 0s - loss: 0.6927 - accuracy: 0.7870 - val_loss: 0.7643 - val_accuracy: 0.7755\n",
      "Epoch 29/100\n",
      "140/140 - 0s - loss: 0.6894 - accuracy: 0.7883 - val_loss: 0.7793 - val_accuracy: 0.7686\n",
      "Epoch 30/100\n",
      "140/140 - 0s - loss: 0.6820 - accuracy: 0.7903 - val_loss: 0.7752 - val_accuracy: 0.7654\n",
      "Epoch 31/100\n",
      "140/140 - 0s - loss: 0.6716 - accuracy: 0.7939 - val_loss: 0.7480 - val_accuracy: 0.7780\n",
      "Epoch 32/100\n",
      "140/140 - 0s - loss: 0.6710 - accuracy: 0.7934 - val_loss: 0.7713 - val_accuracy: 0.7671\n",
      "Epoch 33/100\n",
      "140/140 - 0s - loss: 0.6657 - accuracy: 0.7950 - val_loss: 0.7853 - val_accuracy: 0.7636\n",
      "Epoch 34/100\n",
      "140/140 - 0s - loss: 0.6536 - accuracy: 0.7987 - val_loss: 0.7267 - val_accuracy: 0.7835\n",
      "Epoch 35/100\n",
      "140/140 - 0s - loss: 0.6445 - accuracy: 0.8022 - val_loss: 0.7437 - val_accuracy: 0.7781\n",
      "Epoch 36/100\n",
      "140/140 - 0s - loss: 0.6352 - accuracy: 0.8030 - val_loss: 0.7415 - val_accuracy: 0.7797\n",
      "Epoch 37/100\n",
      "140/140 - 0s - loss: 0.6264 - accuracy: 0.8065 - val_loss: 0.7553 - val_accuracy: 0.7730\n",
      "Epoch 38/100\n",
      "140/140 - 0s - loss: 0.6298 - accuracy: 0.8059 - val_loss: 0.7151 - val_accuracy: 0.7878\n",
      "Epoch 39/100\n",
      "140/140 - 0s - loss: 0.6161 - accuracy: 0.8106 - val_loss: 0.7388 - val_accuracy: 0.7778\n",
      "Epoch 40/100\n",
      "140/140 - 0s - loss: 0.6201 - accuracy: 0.8064 - val_loss: 0.7134 - val_accuracy: 0.7905\n",
      "Epoch 41/100\n",
      "140/140 - 0s - loss: 0.6101 - accuracy: 0.8087 - val_loss: 0.7235 - val_accuracy: 0.7878\n",
      "Epoch 42/100\n",
      "140/140 - 0s - loss: 0.6045 - accuracy: 0.8134 - val_loss: 0.7402 - val_accuracy: 0.7767\n",
      "Epoch 43/100\n",
      "140/140 - 0s - loss: 0.5955 - accuracy: 0.8167 - val_loss: 0.7525 - val_accuracy: 0.7759\n",
      "Epoch 44/100\n",
      "140/140 - 0s - loss: 0.5917 - accuracy: 0.8151 - val_loss: 0.7111 - val_accuracy: 0.7916\n",
      "Epoch 45/100\n",
      "140/140 - 0s - loss: 0.5911 - accuracy: 0.8161 - val_loss: 0.7111 - val_accuracy: 0.7891\n",
      "Epoch 46/100\n",
      "140/140 - 0s - loss: 0.5802 - accuracy: 0.8184 - val_loss: 0.7054 - val_accuracy: 0.7933\n",
      "Epoch 47/100\n",
      "140/140 - 0s - loss: 0.5733 - accuracy: 0.8204 - val_loss: 0.6950 - val_accuracy: 0.7962\n",
      "Epoch 48/100\n",
      "140/140 - 0s - loss: 0.5768 - accuracy: 0.8201 - val_loss: 0.7098 - val_accuracy: 0.7934\n",
      "Epoch 49/100\n",
      "140/140 - 0s - loss: 0.5789 - accuracy: 0.8191 - val_loss: 0.6953 - val_accuracy: 0.7932\n",
      "Epoch 50/100\n",
      "140/140 - 0s - loss: 0.5621 - accuracy: 0.8240 - val_loss: 0.6989 - val_accuracy: 0.7939\n",
      "Epoch 51/100\n",
      "140/140 - 0s - loss: 0.5614 - accuracy: 0.8255 - val_loss: 0.7188 - val_accuracy: 0.7858\n",
      "Epoch 52/100\n",
      "140/140 - 1s - loss: 0.5501 - accuracy: 0.8282 - val_loss: 0.6776 - val_accuracy: 0.7994\n",
      "Epoch 53/100\n",
      "140/140 - 0s - loss: 0.5435 - accuracy: 0.8305 - val_loss: 0.7012 - val_accuracy: 0.7957\n",
      "Epoch 54/100\n",
      "140/140 - 0s - loss: 0.5449 - accuracy: 0.8289 - val_loss: 0.6969 - val_accuracy: 0.7927\n",
      "Epoch 55/100\n",
      "140/140 - 0s - loss: 0.5409 - accuracy: 0.8317 - val_loss: 0.6722 - val_accuracy: 0.8028\n",
      "Epoch 56/100\n",
      "140/140 - 0s - loss: 0.5318 - accuracy: 0.8329 - val_loss: 0.6920 - val_accuracy: 0.7953\n",
      "Epoch 57/100\n",
      "140/140 - 0s - loss: 0.5413 - accuracy: 0.8302 - val_loss: 0.6954 - val_accuracy: 0.7973\n",
      "Epoch 58/100\n",
      "140/140 - 0s - loss: 0.5384 - accuracy: 0.8327 - val_loss: 0.6782 - val_accuracy: 0.8009\n",
      "Epoch 59/100\n",
      "140/140 - 0s - loss: 0.5254 - accuracy: 0.8362 - val_loss: 0.6981 - val_accuracy: 0.7960\n",
      "Epoch 60/100\n",
      "140/140 - 0s - loss: 0.5261 - accuracy: 0.8342 - val_loss: 0.6936 - val_accuracy: 0.8017\n",
      "Epoch 61/100\n",
      "140/140 - 0s - loss: 0.5224 - accuracy: 0.8368 - val_loss: 0.6873 - val_accuracy: 0.7998\n",
      "Epoch 62/100\n",
      "140/140 - 0s - loss: 0.5206 - accuracy: 0.8372 - val_loss: 0.6757 - val_accuracy: 0.8049\n",
      "Epoch 63/100\n",
      "140/140 - 0s - loss: 0.5160 - accuracy: 0.8398 - val_loss: 0.7031 - val_accuracy: 0.7926\n",
      "Epoch 64/100\n",
      "140/140 - 0s - loss: 0.5121 - accuracy: 0.8393 - val_loss: 0.7022 - val_accuracy: 0.7955\n",
      "Epoch 65/100\n",
      "140/140 - 0s - loss: 0.5027 - accuracy: 0.8430 - val_loss: 0.6925 - val_accuracy: 0.7989\n",
      "Epoch 66/100\n",
      "140/140 - 0s - loss: 0.5094 - accuracy: 0.8410 - val_loss: 0.6942 - val_accuracy: 0.7999\n",
      "Epoch 67/100\n",
      "140/140 - 0s - loss: 0.4932 - accuracy: 0.8469 - val_loss: 0.6645 - val_accuracy: 0.8054\n",
      "Epoch 68/100\n",
      "140/140 - 0s - loss: 0.5003 - accuracy: 0.8440 - val_loss: 0.6771 - val_accuracy: 0.8026\n",
      "Epoch 69/100\n",
      "140/140 - 0s - loss: 0.4958 - accuracy: 0.8447 - val_loss: 0.6667 - val_accuracy: 0.8055\n",
      "Epoch 70/100\n",
      "140/140 - 0s - loss: 0.4924 - accuracy: 0.8460 - val_loss: 0.6647 - val_accuracy: 0.8076\n",
      "Epoch 71/100\n",
      "140/140 - 0s - loss: 0.4912 - accuracy: 0.8455 - val_loss: 0.6812 - val_accuracy: 0.8035\n",
      "Epoch 72/100\n",
      "140/140 - 0s - loss: 0.4945 - accuracy: 0.8443 - val_loss: 0.6735 - val_accuracy: 0.8076\n",
      "Epoch 73/100\n",
      "140/140 - 0s - loss: 0.4728 - accuracy: 0.8503 - val_loss: 0.6660 - val_accuracy: 0.8058\n",
      "Epoch 74/100\n",
      "140/140 - 0s - loss: 0.4803 - accuracy: 0.8480 - val_loss: 0.6694 - val_accuracy: 0.8052\n",
      "Epoch 75/100\n",
      "140/140 - 0s - loss: 0.4780 - accuracy: 0.8497 - val_loss: 0.6766 - val_accuracy: 0.8088\n",
      "Epoch 76/100\n",
      "140/140 - 0s - loss: 0.4782 - accuracy: 0.8496 - val_loss: 0.6958 - val_accuracy: 0.8012\n",
      "Epoch 77/100\n",
      "140/140 - 0s - loss: 0.4645 - accuracy: 0.8540 - val_loss: 0.6661 - val_accuracy: 0.8087\n",
      "Epoch 78/100\n",
      "140/140 - 0s - loss: 0.4632 - accuracy: 0.8542 - val_loss: 0.6461 - val_accuracy: 0.8157\n",
      "Epoch 79/100\n",
      "140/140 - 0s - loss: 0.4686 - accuracy: 0.8534 - val_loss: 0.6672 - val_accuracy: 0.8073\n",
      "Epoch 80/100\n",
      "140/140 - 0s - loss: 0.4727 - accuracy: 0.8510 - val_loss: 0.7112 - val_accuracy: 0.7961\n",
      "Epoch 81/100\n",
      "140/140 - 0s - loss: 0.4617 - accuracy: 0.8568 - val_loss: 0.6721 - val_accuracy: 0.8064\n",
      "Epoch 82/100\n",
      "140/140 - 0s - loss: 0.4654 - accuracy: 0.8542 - val_loss: 0.7021 - val_accuracy: 0.8011\n",
      "Epoch 83/100\n",
      "140/140 - 0s - loss: 0.4481 - accuracy: 0.8597 - val_loss: 0.6898 - val_accuracy: 0.8023\n",
      "Epoch 84/100\n",
      "140/140 - 0s - loss: 0.4550 - accuracy: 0.8573 - val_loss: 0.6900 - val_accuracy: 0.8026\n",
      "Epoch 85/100\n",
      "140/140 - 0s - loss: 0.4466 - accuracy: 0.8603 - val_loss: 0.6558 - val_accuracy: 0.8136\n",
      "Epoch 86/100\n",
      "140/140 - 0s - loss: 0.4511 - accuracy: 0.8581 - val_loss: 0.6573 - val_accuracy: 0.8121\n",
      "Epoch 87/100\n",
      "140/140 - 0s - loss: 0.4414 - accuracy: 0.8608 - val_loss: 0.6683 - val_accuracy: 0.8103\n",
      "Epoch 88/100\n",
      "140/140 - 0s - loss: 0.4511 - accuracy: 0.8586 - val_loss: 0.6762 - val_accuracy: 0.8072\n",
      "Epoch 89/100\n",
      "140/140 - 0s - loss: 0.4368 - accuracy: 0.8628 - val_loss: 0.6834 - val_accuracy: 0.8067\n",
      "Epoch 90/100\n",
      "140/140 - 0s - loss: 0.4559 - accuracy: 0.8571 - val_loss: 0.6634 - val_accuracy: 0.8097\n",
      "Epoch 91/100\n",
      "140/140 - 0s - loss: 0.4465 - accuracy: 0.8602 - val_loss: 0.6845 - val_accuracy: 0.8028\n",
      "Epoch 92/100\n",
      "140/140 - 0s - loss: 0.4448 - accuracy: 0.8605 - val_loss: 0.6693 - val_accuracy: 0.8064\n",
      "Epoch 93/100\n",
      "140/140 - 0s - loss: 0.4378 - accuracy: 0.8609 - val_loss: 0.6737 - val_accuracy: 0.8086\n",
      "Epoch 94/100\n",
      "140/140 - 0s - loss: 0.4373 - accuracy: 0.8623 - val_loss: 0.6686 - val_accuracy: 0.8116\n",
      "Epoch 95/100\n",
      "140/140 - 0s - loss: 0.4398 - accuracy: 0.8611 - val_loss: 0.6471 - val_accuracy: 0.8154\n",
      "Epoch 96/100\n",
      "140/140 - 0s - loss: 0.4230 - accuracy: 0.8660 - val_loss: 0.6706 - val_accuracy: 0.8081\n",
      "Epoch 97/100\n",
      "140/140 - 0s - loss: 0.4216 - accuracy: 0.8679 - val_loss: 0.6584 - val_accuracy: 0.8143\n",
      "Epoch 98/100\n",
      "140/140 - 0s - loss: 0.4219 - accuracy: 0.8656 - val_loss: 0.6835 - val_accuracy: 0.8049\n",
      "Epoch 99/100\n",
      "140/140 - 0s - loss: 0.4191 - accuracy: 0.8684 - val_loss: 0.6739 - val_accuracy: 0.8094\n",
      "Epoch 100/100\n",
      "140/140 - 0s - loss: 0.4129 - accuracy: 0.8687 - val_loss: 0.6921 - val_accuracy: 0.8047\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "training_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=300, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "algw3-VGIj-N"
   },
   "source": [
    "## 4. Plotting the training loss, validation loss vs number of epochs and training accuracy, \n",
    "## validation accuracy vs number of epochs plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FnJ1ivri6raW",
    "outputId": "2fec1e0a-1203-4e6d-90c6-c49f049feed5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6920722126960754\n",
      "Accuracy: 0.804722249507904\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Loss:\", scores[0])\n",
    "print(\"Accuracy:\", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "KTkKIdERtyIp",
    "outputId": "8f4080ff-a5c2-47db-bbf5-7bc25d781c6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and validation loss')"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy      = training_history.history['accuracy']\n",
    "val_accuracy  = training_history.history['val_accuracy']\n",
    "loss     = training_history.history['loss']\n",
    "val_loss = training_history.history['val_loss']\n",
    "\n",
    "epochs   = range(len(accuracy)) # Get number of epochs\n",
    "\n",
    "plt.plot  ( epochs, accuracy, label = 'training accuracy' )\n",
    "plt.plot  ( epochs, val_accuracy, label = 'validation accuracy' )\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.figure()\n",
    "\n",
    "plt.plot  ( epochs, loss, label = 'training loss' )\n",
    "plt.plot  ( epochs, val_loss, label = 'validation loss' )\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title ('Training and validation loss'   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS27zSiqIzZ8"
   },
   "source": [
    "There are around 10 classes in the dataset which represent digits from 0-9.\n",
    "\n",
    "We tried training a Neural Network with dense hidden layers of different number of units and are able to achieve a final test accuracy of 80.74 %. \n",
    "\n",
    "Also we notice that after a certain point the model begins to overfit on our dataset as is clear from the plots above where the validation loss begins to increase after certain point and validation accuracy begins to decrease.\n",
    "\n",
    "Thus, with this amount of accuracy we are able to distinguish between the different digits in this dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pT3rJzPszHgm"
   },
   "source": [
    "## Neural Networks - Part A ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "lz9bffGcyhn8",
    "outputId": "88e7166a-d693-4798-ca57-4e9eca027f89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Mounting Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X8PZN4ee1mJI"
   },
   "outputs": [],
   "source": [
    "# Setting the current working directory\n",
    "import os; os.chdir('drive/My Drive/Great Learning/Neural Network')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6DsvU1eB2dJ9"
   },
   "source": [
    "<a id='import'></a>\n",
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "colab_type": "code",
    "id": "YdPPqfcR17r5",
    "outputId": "6de7e6c5-07ef-4596-e8f9-08b2861ce82f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns, h5py\n",
    "import matplotlib.style as style; style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "# Metrics and preprocessing\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# TF and Keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Checking if GPU is found\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uWLj6hFH3e36",
    "outputId": "329d6d2a-40ce-4b37-c3aa-4c2937112177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'07_Neural Network.ipynb'   SVHN_single_grey1.h5\n"
     ]
    }
   ],
   "source": [
    "!ls '/content/drive/My Drive/Great Learning/Neural Network'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X4jslkxXdFB1"
   },
   "source": [
    "<a id='load'></a>\n",
    "### Load train, val and test datasets from h5py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "kdolI00z7KOf",
    "outputId": "7d3fd2b8-da8b-4c72-f55c-c0868eedb822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (42000, 32, 32) (42000,)\n",
      "Validation set (60000, 32, 32) (60000,)\n",
      "Test set (18000, 32, 32) (18000,)\n",
      "\n",
      "\n",
      "Unique labels in y_train: [0 1 2 3 4 5 6 7 8 9]\n",
      "Unique labels in y_val: [0 1 2 3 4 5 6 7 8 9]\n",
      "Unique labels in y_test: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Read the h5 file\n",
    "h5_SVH = h5py.File('SVHN_single_grey1.h5', 'r')\n",
    "\n",
    "# Load the training, validation and test sets\n",
    "X_train = h5_SVH['X_train'][:]\n",
    "y_train_o = h5_SVH['y_train'][:]\n",
    "X_val = h5_SVH['X_val'][:]\n",
    "y_val_o = h5_SVH['y_val'][:]\n",
    "X_test = h5_SVH['X_test'][:]\n",
    "y_test_o = h5_SVH['y_test'][:]\n",
    "\n",
    "# Close this file\n",
    "\n",
    "h5_SVH.close()\n",
    "\n",
    "print('Training set', X_train.shape, y_train_o.shape)\n",
    "print('Validation set', X_val.shape, y_val_o.shape)\n",
    "print('Test set', X_test.shape, y_test_o.shape)\n",
    "\n",
    "print('\\n')\n",
    "print('Unique labels in y_train:', np.unique(y_train_o))\n",
    "print('Unique labels in y_val:', np.unique(y_val_o))\n",
    "print('Unique labels in y_test:', np.unique(y_test_o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwanQxdD9mBC"
   },
   "source": [
    "<a id='o1'></a>\n",
    "#### Observation 1 - Sets Shape\n",
    "* Length of training sets: 42k, validation sets: 60k, test sets: 18k\n",
    "* Size of the images: 32*32\n",
    "* Number of class: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g8Zur6Qxs92_"
   },
   "source": [
    "<a id='visualize'></a>\n",
    "### Visualizing first 10 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152
    },
    "colab_type": "code",
    "id": "wuXKfSv58lbK",
    "outputId": "4d2bf75c-6b25-4c59-ecd7-0c06aade559e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7kAAAB1CAYAAACLZSaSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x324 with 10 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label for each of the above image: [2 6 7 4 4 0 3 0 7 3]\n"
     ]
    }
   ],
   "source": [
    "# Visualizing first 10 images in the dataset and their labels\n",
    "plt.figure(figsize = (15, 4.5))\n",
    "for i in range(10):  \n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X_train[i].reshape((32, 32)),cmap = plt.cm.binary)\n",
    "    plt.axis('off')\n",
    "plt.subplots_adjust(wspace = -0.1, hspace = -0.1)\n",
    "plt.show()\n",
    "\n",
    "print('Label for each of the above image: %s' % (y_train_o[0 : 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "Td7LigoTynL2",
    "outputId": "dea62917-3429-40ac-c813-31b36f8a5f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking first image and label in training set\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD1CAYAAAB9TzjVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYmjghETM/wIo2e2Bn1dKLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n"
     ]
    }
   ],
   "source": [
    "print('Checking first image and label in training set'); print('--'*40)\n",
    "plt.imshow(X_train[0], cmap = plt.cm.binary)    \n",
    "plt.show()\n",
    "print('Label:', y_train_o[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "Bcpa-MFxy0Zt",
    "outputId": "f4593ef0-8dfb-46d5-d06d-3d4c2c88907f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking first image and label in validation set\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD1CAYAAAB9TzjVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYeTgQlQYObgQFebfAfmL0QQbDJBwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "print('Checking first image and label in validation set'); print('--'*40)\n",
    "plt.imshow(X_val[0], cmap = plt.cm.binary)    \n",
    "plt.show()\n",
    "print('Label:', y_val_o[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "r1OIeig-zHap",
    "outputId": "469be395-b214-4ccb-fdb3-5058f7a2f3f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking first image and label in test set\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD1CAYAAAB9TzjVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "print('Checking first image and label in test set'); print('--'*40)\n",
    "plt.imshow(X_test[0], cmap = plt.cm.binary)    \n",
    "plt.show()\n",
    "print('Label:', y_test_o[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fEQ-CNcVdr-c"
   },
   "source": [
    "<a id='flatten'></a>\n",
    "### Flatten and normalize the images for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "t4cfwZ9ldlO0",
    "outputId": "4c4d0e87-bb47-47d7-f016-7bf6347f7ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping X data: (n, 32, 32) => (n, 1024)\n",
      "--------------------------------------------------------------------------------\n",
      "Making sure that the values are float so that we can get decimal points after division\n",
      "--------------------------------------------------------------------------------\n",
      "Normalizing the RGB codes by dividing it to the max RGB value\n",
      "--------------------------------------------------------------------------------\n",
      "Converting y data into categorical (one-hot encoding)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Reshaping X data: (n, 32, 32) => (n, 1024)'); print('--'*40)\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_val = X_val.reshape((X_val.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "print('Making sure that the values are float so that we can get decimal points after division'); print('--'*40)\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print('Normalizing the RGB codes by dividing it to the max RGB value'); print('--'*40)\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('Converting y data into categorical (one-hot encoding)'); print('--'*40)\n",
    "y_train = to_categorical(y_train_o)\n",
    "y_val = to_categorical(y_val_o)\n",
    "y_test = to_categorical(y_test_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "evUXte-cnfRN",
    "outputId": "9f9be675-0b9e-4a14-dd97-1f4bd4d4efa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (42000, 1024)\n",
      "X_val shape: (60000, 1024)\n",
      "X_test shape: (18000, 1024)\n",
      "\n",
      "\n",
      "y_train shape: (42000, 10)\n",
      "y_val shape: (60000, 10)\n",
      "y_test shape: (18000, 10)\n",
      "\n",
      "\n",
      "Number of images in X_train 42000\n",
      "Number of images in X_val 60000\n",
      "Number of images in X_test 18000\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_val shape:', X_val.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('\\n')\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_val shape:', y_val.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "print('\\n')\n",
    "print('Number of images in X_train', X_train.shape[0])\n",
    "print('Number of images in X_val', X_val.shape[0])\n",
    "print('Number of images in X_test', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGKy-ZD1YAWv"
   },
   "source": [
    "<a id='Baby'></a>\n",
    "### Modelling - Baby sitting the learning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JX35qWq_AyLZ"
   },
   "source": [
    "#### Fully connected linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyQvFvwMX_pI"
   },
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.W = np.random.randn(in_size, out_size) * 0.01\n",
    "        self.b = np.zeros((1, out_size))\n",
    "        self.params = [self.W, self.b]\n",
    "        self.gradW = None\n",
    "        self.gradB = None\n",
    "        self.gradInput = None        \n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.output = np.dot(X, self.W) + self.b\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradW = np.dot(self.X.T, nextgrad)\n",
    "        self.gradB = np.sum(nextgrad, axis=0)\n",
    "        self.gradInput = np.dot(nextgrad, self.W.T)\n",
    "        return self.gradInput, [self.gradW, self.gradB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CQegqIQXA1Wi"
   },
   "source": [
    "#### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A0HxN2PnaaaM"
   },
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.gradInput = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.output = np.maximum(X, 0)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradInput = nextgrad.copy()\n",
    "        self.gradInput[self.output <=0] = 0\n",
    "        return self.gradInput, []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5CwuYJdhA7sz"
   },
   "source": [
    "#### Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5AxCBE9fagiP"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6X9_AZeA-61"
   },
   "source": [
    "#### Cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tbjl_6qYaq80"
   },
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    def forward(self, X, y):\n",
    "        self.m = y.shape[0]\n",
    "        self.p = softmax(X)\n",
    "        cross_entropy = -np.log(self.p[range(self.m), y]+1e-16)\n",
    "        loss = np.sum(cross_entropy) / self.m\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        y_idx = y.argmax()        \n",
    "        grad = softmax(X)\n",
    "        grad[range(self.m), y] -= 1\n",
    "        grad /= self.m\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-dLPKqbBCuT"
   },
   "source": [
    "#### NN class that enables the forward prop and backward propagation of the entire network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOUQbEfIawH0"
   },
   "outputs": [],
   "source": [
    "class NN():\n",
    "    def __init__(self, lossfunc = CrossEntropy(), mode = 'train'):\n",
    "        self.params = []\n",
    "        self.layers = []\n",
    "        self.loss_func = lossfunc\n",
    "        self.grads = []\n",
    "        self.mode = mode\n",
    "        \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        self.params.append(layer.params)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, nextgrad):\n",
    "        self.clear_grad_param()\n",
    "        for layer in reversed(self.layers):\n",
    "            nextgrad, grad = layer.backward(nextgrad)\n",
    "            self.grads.append(grad)\n",
    "        return self.grads\n",
    "    \n",
    "    def train_step(self, X, y):\n",
    "        out = self.forward(X)\n",
    "        loss = self.loss_func.forward(out,y)\n",
    "        nextgrad = self.loss_func.backward(out,y)\n",
    "        grads = self.backward(nextgrad)\n",
    "        return loss, grads\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self.forward(X)\n",
    "        p = softmax(X)\n",
    "        return np.argmax(p, axis=1)\n",
    "    \n",
    "    def predict_scores(self, X):\n",
    "        X = self.forward(X)\n",
    "        p = softmax(X)\n",
    "        return p\n",
    "    \n",
    "    def clear_grad_param(self):\n",
    "        self.grads = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHLu_qtoBGYg"
   },
   "source": [
    "#### Update function SGD with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XpEjX7qqbN9q"
   },
   "outputs": [],
   "source": [
    "def update(velocity, params, grads, learning_rate=0.01, mu=0.9):\n",
    "    for v, p, g, in zip(velocity, params, reversed(grads)):\n",
    "        for i in range(len(g)):\n",
    "            v[i] = (mu * v[i]) - (learning_rate * g[i])\n",
    "            p[i] += v[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQnT5wBFBJUH"
   },
   "source": [
    "#### Get minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xYxPXK7Fbfgk"
   },
   "outputs": [],
   "source": [
    "def minibatch(X, y, minibatch_size):\n",
    "    n = X.shape[0]\n",
    "    minibatches = []\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    X = X[permutation]\n",
    "    y = y[permutation]\n",
    "    \n",
    "    for i in range(0, n , minibatch_size):\n",
    "        X_batch = X[i:i + minibatch_size, :]\n",
    "        y_batch = y[i:i + minibatch_size, ]\n",
    "        minibatches.append((X_batch, y_batch))\n",
    "        \n",
    "    return minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ScfG6m51BQfz"
   },
   "source": [
    "#### The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y6F3W-wfbpqC"
   },
   "outputs": [],
   "source": [
    "def train(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu = 0.9, X_val = None, y_val = None, Lambda = 0, verb = True):\n",
    "    val_loss_epoch = []\n",
    "    minibatches = minibatch(X_train, y_train, minibatch_size)\n",
    "    minibatches_val = minibatch(X_val, y_val, minibatch_size)\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        loss_batch = []\n",
    "        val_loss_batch = []\n",
    "        velocity = []\n",
    "        for param_layer in net.params:\n",
    "            p = [np.zeros_like(param) for param in list(param_layer)]\n",
    "            velocity.append(p)\n",
    "            \n",
    "        # iterate over mini batches\n",
    "        for X_mini, y_mini in minibatches:\n",
    "            loss, grads = net.train_step(X_mini, y_mini)\n",
    "            loss_batch.append(loss)\n",
    "            update(velocity, net.params, grads, learning_rate=learning_rate, mu=mu)\n",
    "\n",
    "        for X_mini_val, y_mini_val in minibatches_val:\n",
    "            val_loss, _ = net.train_step(X_mini, y_mini)\n",
    "            val_loss_batch.append(val_loss)\n",
    "        \n",
    "        # accuracy of model at end of epoch after all mini batch updates\n",
    "        m_train = X_train.shape[0]\n",
    "        m_val = X_val.shape[0]\n",
    "        y_train_pred = []\n",
    "        y_val_pred = []\n",
    "        y_train1 = []\n",
    "        y_vall = []\n",
    "        for ii in range(0, m_train, minibatch_size):\n",
    "            X_tr = X_train[ii:ii + minibatch_size, : ]\n",
    "            y_tr = y_train[ii:ii + minibatch_size,]\n",
    "            y_train1 = np.append(y_train1, y_tr)\n",
    "            y_train_pred = np.append(y_train_pred, net.predict(X_tr))\n",
    "\n",
    "        for ii in range(0, m_val, minibatch_size):\n",
    "            X_va = X_val[ii:ii + minibatch_size, : ]\n",
    "            y_va = y_val[ii:ii + minibatch_size,]\n",
    "            y_vall = np.append(y_vall, y_va)\n",
    "            y_val_pred = np.append(y_val_pred, net.predict(X_va))\n",
    "            \n",
    "        train_acc = check_accuracy(y_train1, y_train_pred)\n",
    "        val_acc = check_accuracy(y_vall, y_val_pred)\n",
    "        \n",
    "        ## weights\n",
    "        w = np.array(net.params[0][0])\n",
    "        \n",
    "        ## adding regularization to cost\n",
    "        mean_train_loss = (sum(loss_batch) / float(len(loss_batch)))\n",
    "        mean_val_loss = sum(val_loss_batch) / float(len(val_loss_batch))\n",
    "        \n",
    "        val_loss_epoch.append(mean_val_loss)\n",
    "        if verb:\n",
    "            if i%50==0:\n",
    "                print(\"Epoch {3}/{4}: Loss = {0} | Training Accuracy = {1}\".format(mean_train_loss, train_acc, val_acc, i, epoch))\n",
    "    return net, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFKQ9JIPBU2L"
   },
   "source": [
    "#### Checking the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gAAOfhBebz8d"
   },
   "outputs": [],
   "source": [
    "def check_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iagKp2kvBaZD"
   },
   "source": [
    "#### Invoking all that we have created until now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vA1-5ojib7XH"
   },
   "outputs": [],
   "source": [
    "# Invoking the model\n",
    "## input size\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "def train_and_test_loop(iterations, lr, Lambda, verb = True):\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes1 = 10\n",
    "    output_nodes = 10\n",
    "\n",
    "    ## define neural net\n",
    "    nn = NN()\n",
    "    nn.add_layer(Linear(input_dim, hidden_nodes1))\n",
    "\n",
    "    nn, val_acc = train(nn, X_train, y_train_o, minibatch_size = 200, epoch = iterations, learning_rate = learning_rate,\\\n",
    "                      X_val = X_test, y_val = y_test_o, Lambda = Lambda, verb = verb)\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_JhBJRfvBfiC"
   },
   "source": [
    "#### Double Check that the loss is reasonable : Disable the regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "fjbjgrHl6LBv",
    "outputId": "8dd2b91f-4761-480b-c68e-bdfe4c4a54a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1: Loss = 2.3117883972138844 | Training Accuracy = 0.09335714285714286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09438888888888888"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "Lambda = 0\n",
    "train_and_test_loop(1, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wFbKNxLpBl7i"
   },
   "source": [
    "#### Now, lets crank up the Lambda(Regularization) and check what it does to our loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "_OtyvtW39bmm",
    "outputId": "ce84f1ba-9d21-4a36-c881-579f3fa3ba4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1: Loss = 2.3082000425724667 | Training Accuracy = 0.08478571428571428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08188888888888889"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "Lambda = 1e3\n",
    "train_and_test_loop(1, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Zq7TGKfBped"
   },
   "source": [
    "#### Now, lets overfit to a small subset of our dataset, in this case 20 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "882INFrA9wSF",
    "outputId": "8f0d13f9-0dc9-40eb-a335-30f87bb8b746"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 1024), (20,))"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_subset = X_train[0:20]\n",
    "y_train_subset = y_train_o[0:20]\n",
    "\n",
    "X_train = X_train_subset\n",
    "y_train_o = y_train_subset\n",
    "\n",
    "X_train.shape, y_train_o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fmS0Eicu-T00"
   },
   "source": [
    "#### Make sure that you can overfit very small portion of the training data\n",
    "So, set a small learning rate and turn regularization off\n",
    "In the code below:\n",
    "* Take the first 20 examples\n",
    "* turn off regularization(reg=0.0)\n",
    "* use simple vanilla 'sgd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "adxWZ2NO-OrY",
    "outputId": "1a35adc0-91a8-4603-f953-b6430d9030e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 8 s, total: 8 s\n",
      "Wall time: 8.11 s\n",
      "Epoch 0/5000: Loss = 2.343525441008851 | Training Accuracy = 0.0\n",
      "Epoch 50/5000: Loss = 1.9368840865311359 | Training Accuracy = 0.3\n",
      "Epoch 100/5000: Loss = 1.8502138907049706 | Training Accuracy = 0.3\n",
      "Epoch 150/5000: Loss = 1.795704759770493 | Training Accuracy = 0.35\n",
      "Epoch 200/5000: Loss = 1.7505141963680764 | Training Accuracy = 0.4\n",
      "Epoch 250/5000: Loss = 1.7098591715226046 | Training Accuracy = 0.45\n",
      "Epoch 300/5000: Loss = 1.6720807405140872 | Training Accuracy = 0.45\n",
      "Epoch 350/5000: Loss = 1.6364256819871694 | Training Accuracy = 0.5\n",
      "Epoch 400/5000: Loss = 1.602489808977548 | Training Accuracy = 0.55\n",
      "Epoch 450/5000: Loss = 1.5700278004175436 | Training Accuracy = 0.55\n",
      "Epoch 500/5000: Loss = 1.5388749934942745 | Training Accuracy = 0.6\n",
      "Epoch 550/5000: Loss = 1.5089113416081257 | Training Accuracy = 0.6\n",
      "Epoch 600/5000: Loss = 1.480043412413456 | Training Accuracy = 0.6\n",
      "Epoch 650/5000: Loss = 1.4521947854019437 | Training Accuracy = 0.65\n",
      "Epoch 700/5000: Loss = 1.425300621663516 | Training Accuracy = 0.65\n",
      "Epoch 750/5000: Loss = 1.3993044229509757 | Training Accuracy = 0.65\n",
      "Epoch 800/5000: Loss = 1.3741559975684867 | Training Accuracy = 0.65\n",
      "Epoch 850/5000: Loss = 1.3498101223720105 | Training Accuracy = 0.65\n",
      "Epoch 900/5000: Loss = 1.3262256235641494 | Training Accuracy = 0.65\n",
      "Epoch 950/5000: Loss = 1.303364719491542 | Training Accuracy = 0.65\n",
      "Epoch 1000/5000: Loss = 1.2811925334058236 | Training Accuracy = 0.65\n",
      "Epoch 1050/5000: Loss = 1.2596767202488166 | Training Accuracy = 0.65\n",
      "Epoch 1100/5000: Loss = 1.2387871723562258 | Training Accuracy = 0.65\n",
      "Epoch 1150/5000: Loss = 1.218495781389982 | Training Accuracy = 0.65\n",
      "Epoch 1200/5000: Loss = 1.1987762414312768 | Training Accuracy = 0.7\n",
      "Epoch 1250/5000: Loss = 1.1796038829744615 | Training Accuracy = 0.7\n",
      "Epoch 1300/5000: Loss = 1.1609555306717911 | Training Accuracy = 0.7\n",
      "Epoch 1350/5000: Loss = 1.1428093797371377 | Training Accuracy = 0.7\n",
      "Epoch 1400/5000: Loss = 1.1251448873080339 | Training Accuracy = 0.7\n",
      "Epoch 1450/5000: Loss = 1.1079426760244366 | Training Accuracy = 0.8\n",
      "Epoch 1500/5000: Loss = 1.0911844477557584 | Training Accuracy = 0.85\n",
      "Epoch 1550/5000: Loss = 1.0748529058881875 | Training Accuracy = 0.85\n",
      "Epoch 1600/5000: Loss = 1.058931684932634 | Training Accuracy = 0.85\n",
      "Epoch 1650/5000: Loss = 1.0434052864697851 | Training Accuracy = 0.85\n",
      "Epoch 1700/5000: Loss = 1.0282590206397022 | Training Accuracy = 0.85\n",
      "Epoch 1750/5000: Loss = 1.013478952527564 | Training Accuracy = 0.85\n",
      "Epoch 1800/5000: Loss = 0.9990518529073633 | Training Accuracy = 0.85\n",
      "Epoch 1850/5000: Loss = 0.9849651528906417 | Training Accuracy = 0.85\n",
      "Epoch 1900/5000: Loss = 0.9712069020941513 | Training Accuracy = 0.85\n",
      "Epoch 1950/5000: Loss = 0.9577657299933456 | Training Accuracy = 0.85\n",
      "Epoch 2000/5000: Loss = 0.9446308101711862 | Training Accuracy = 0.85\n",
      "Epoch 2050/5000: Loss = 0.9317918272064819 | Training Accuracy = 0.85\n",
      "Epoch 2100/5000: Loss = 0.9192389459746264 | Training Accuracy = 0.85\n",
      "Epoch 2150/5000: Loss = 0.9069627831576392 | Training Accuracy = 0.85\n",
      "Epoch 2200/5000: Loss = 0.8949543807808057 | Training Accuracy = 0.85\n",
      "Epoch 2250/5000: Loss = 0.8832051816107626 | Training Accuracy = 0.9\n",
      "Epoch 2300/5000: Loss = 0.8717070062651777 | Training Accuracy = 0.95\n",
      "Epoch 2350/5000: Loss = 0.8604520318976363 | Training Accuracy = 0.95\n",
      "Epoch 2400/5000: Loss = 0.849432772333326 | Training Accuracy = 0.95\n",
      "Epoch 2450/5000: Loss = 0.8386420595418531 | Training Accuracy = 0.95\n",
      "Epoch 2500/5000: Loss = 0.828073026343203 | Training Accuracy = 0.95\n",
      "Epoch 2550/5000: Loss = 0.8177190902516587 | Training Accuracy = 0.95\n",
      "Epoch 2600/5000: Loss = 0.8075739383704768 | Training Accuracy = 0.95\n",
      "Epoch 2650/5000: Loss = 0.7976315132574238 | Training Accuracy = 0.95\n",
      "Epoch 2700/5000: Loss = 0.7878859996879619 | Training Accuracy = 0.95\n",
      "Epoch 2750/5000: Loss = 0.778331812248966 | Training Accuracy = 0.95\n",
      "Epoch 2800/5000: Loss = 0.7689635837014647 | Training Accuracy = 1.0\n",
      "Epoch 2850/5000: Loss = 0.7597761540560017 | Training Accuracy = 1.0\n",
      "Epoch 2900/5000: Loss = 0.7507645603089181 | Training Accuracy = 1.0\n",
      "Epoch 2950/5000: Loss = 0.7419240267921232 | Training Accuracy = 1.0\n",
      "Epoch 3000/5000: Loss = 0.7332499560928596 | Training Accuracy = 1.0\n",
      "Epoch 3050/5000: Loss = 0.7247379205035223 | Training Accuracy = 1.0\n",
      "Epoch 3100/5000: Loss = 0.716383653964874 | Training Accuracy = 1.0\n",
      "Epoch 3150/5000: Loss = 0.7081830444689625 | Training Accuracy = 1.0\n",
      "Epoch 3200/5000: Loss = 0.700132126890769 | Training Accuracy = 1.0\n",
      "Epoch 3250/5000: Loss = 0.6922270762200713 | Training Accuracy = 1.0\n",
      "Epoch 3300/5000: Loss = 0.6844642011672761 | Training Accuracy = 1.0\n",
      "Epoch 3350/5000: Loss = 0.6768399381190008 | Training Accuracy = 1.0\n",
      "Epoch 3400/5000: Loss = 0.6693508454210667 | Training Accuracy = 1.0\n",
      "Epoch 3450/5000: Loss = 0.6619935979682519 | Training Accuracy = 1.0\n",
      "Epoch 3500/5000: Loss = 0.6547649820817112 | Training Accuracy = 1.0\n",
      "Epoch 3550/5000: Loss = 0.6476618906563633 | Training Accuracy = 1.0\n",
      "Epoch 3600/5000: Loss = 0.6406813185618502 | Training Accuracy = 1.0\n",
      "Epoch 3650/5000: Loss = 0.6338203582818351 | Training Accuracy = 1.0\n",
      "Epoch 3700/5000: Loss = 0.62707619577748 | Training Accuracy = 1.0\n",
      "Epoch 3750/5000: Loss = 0.6204461065619331 | Training Accuracy = 1.0\n",
      "Epoch 3800/5000: Loss = 0.613927451973544 | Training Accuracy = 1.0\n",
      "Epoch 3850/5000: Loss = 0.6075176756363615 | Training Accuracy = 1.0\n",
      "Epoch 3900/5000: Loss = 0.6012143000972181 | Training Accuracy = 1.0\n",
      "Epoch 3950/5000: Loss = 0.5950149236294051 | Training Accuracy = 1.0\n",
      "Epoch 4000/5000: Loss = 0.5889172171935882 | Training Accuracy = 1.0\n",
      "Epoch 4050/5000: Loss = 0.5829189215472004 | Training Accuracy = 1.0\n",
      "Epoch 4100/5000: Loss = 0.5770178444941011 | Training Accuracy = 1.0\n",
      "Epoch 4150/5000: Loss = 0.5712118582668013 | Training Accuracy = 1.0\n",
      "Epoch 4200/5000: Loss = 0.5654988970340131 | Training Accuracy = 1.0\n",
      "Epoch 4250/5000: Loss = 0.5598769545267331 | Training Accuracy = 1.0\n",
      "Epoch 4300/5000: Loss = 0.5543440817764675 | Training Accuracy = 1.0\n",
      "Epoch 4350/5000: Loss = 0.5488983849595841 | Training Accuracy = 1.0\n",
      "Epoch 4400/5000: Loss = 0.5435380233421363 | Training Accuracy = 1.0\n",
      "Epoch 4450/5000: Loss = 0.538261207319821 | Training Accuracy = 1.0\n",
      "Epoch 4500/5000: Loss = 0.5330661965480605 | Training Accuracy = 1.0\n",
      "Epoch 4550/5000: Loss = 0.5279512981574574 | Training Accuracy = 1.0\n",
      "Epoch 4600/5000: Loss = 0.5229148650501726 | Training Accuracy = 1.0\n",
      "Epoch 4650/5000: Loss = 0.5179552942730058 | Training Accuracy = 1.0\n",
      "Epoch 4700/5000: Loss = 0.513071025463205 | Training Accuracy = 1.0\n",
      "Epoch 4750/5000: Loss = 0.5082605393632545 | Training Accuracy = 1.0\n",
      "Epoch 4800/5000: Loss = 0.5035223564010968 | Training Accuracy = 1.0\n",
      "Epoch 4850/5000: Loss = 0.49885503533244346 | Training Accuracy = 1.0\n",
      "Epoch 4900/5000: Loss = 0.4942571719420129 | Training Accuracy = 1.0\n",
      "Epoch 4950/5000: Loss = 0.4897273978007071 | Training Accuracy = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1381111111111111"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "lr = 0.001\n",
    "Lambda = 0\n",
    "train_and_test_loop(5000, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BleQhuF6ByTQ"
   },
   "source": [
    "#### Loading the original dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "C1iZh7go--Tx",
    "outputId": "688eb4bb-3310-47e0-a01c-39b97ca301f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping X data: (n, 32, 32) => (n, 1024)\n",
      "--------------------------------------------------------------------------------\n",
      "Making sure that the values are float so that we can get decimal points after division\n",
      "--------------------------------------------------------------------------------\n",
      "Normalizing the RGB codes by dividing it to the max RGB value\n",
      "--------------------------------------------------------------------------------\n",
      "Converting y data into categorical (one-hot encoding)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "h5_SVH = h5py.File('SVHN_single_grey1.h5', 'r')\n",
    "# Load the training, validation and test sets\n",
    "X_train = h5_SVH['X_train'][:]\n",
    "y_train_o = h5_SVH['y_train'][:]\n",
    "X_val = h5_SVH['X_val'][:]\n",
    "y_val_o = h5_SVH['y_val'][:]\n",
    "X_test = h5_SVH['X_test'][:]\n",
    "y_test_o = h5_SVH['y_test'][:]\n",
    "\n",
    "print('Reshaping X data: (n, 32, 32) => (n, 1024)'); print('--'*40)\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_val = X_val.reshape((X_val.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "print('Making sure that the values are float so that we can get decimal points after division'); print('--'*40)\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print('Normalizing the RGB codes by dividing it to the max RGB value'); print('--'*40)\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('Converting y data into categorical (one-hot encoding)'); print('--'*40)\n",
    "y_train = to_categorical(y_train_o)\n",
    "y_val = to_categorical(y_val_o)\n",
    "y_test = to_categorical(y_test_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8qZ1E-lE_vD9"
   },
   "source": [
    "#### Start with small regularization and find learning rate that makes the loss go down.\n",
    "* we start with Lambda(small regularization) = 1e-7\n",
    "* we start with a small learning rate = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "V7q3hsLT_oDn",
    "outputId": "842b874b-99ea-4eee-efc3-369b5b83f4aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/500: Loss = 2.317728157047642 | Training Accuracy = 0.104\n",
      "Epoch 50/500: Loss = 2.3127425227478797 | Training Accuracy = 0.10471428571428572\n",
      "Epoch 100/500: Loss = 2.3094828415428403 | Training Accuracy = 0.1055\n",
      "Epoch 150/500: Loss = 2.307345836509397 | Training Accuracy = 0.10542857142857143\n",
      "Epoch 200/500: Loss = 2.305942805671862 | Training Accuracy = 0.10428571428571429\n",
      "Epoch 250/500: Loss = 2.3050204802732313 | Training Accuracy = 0.10395238095238095\n",
      "Epoch 300/500: Loss = 2.3044129184583078 | Training Accuracy = 0.10254761904761905\n",
      "Epoch 350/500: Loss = 2.3040111864235984 | Training Accuracy = 0.101\n",
      "Epoch 400/500: Loss = 2.303743794017468 | Training Accuracy = 0.10019047619047619\n",
      "Epoch 450/500: Loss = 2.3035638954300524 | Training Accuracy = 0.09911904761904762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09555555555555556"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-7\n",
    "Lambda = 1e-7\n",
    "train_and_test_loop(500, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OtPHH89wB8YE"
   },
   "source": [
    "#### Lets try to train now with a value of learning rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "7hvRY3b__90J",
    "outputId": "47584191-1536-49b4-ccff-db2e2a597ec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/500: Loss = 2.3045206865294667 | Training Accuracy = 0.11473809523809524\n",
      "Epoch 50/500: Loss = 2.259865884155515 | Training Accuracy = 0.20614285714285716\n",
      "Epoch 100/500: Loss = 2.251416078728257 | Training Accuracy = 0.21633333333333332\n",
      "Epoch 150/500: Loss = 2.2471058220607465 | Training Accuracy = 0.22138095238095237\n",
      "Epoch 200/500: Loss = 2.2442164094973287 | Training Accuracy = 0.22454761904761905\n",
      "Epoch 250/500: Loss = 2.2420426056295346 | Training Accuracy = 0.22678571428571428\n",
      "Epoch 300/500: Loss = 2.240300552374621 | Training Accuracy = 0.22766666666666666\n",
      "Epoch 350/500: Loss = 2.2388468080995563 | Training Accuracy = 0.22914285714285715\n",
      "Epoch 400/500: Loss = 2.237598607772921 | Training Accuracy = 0.2300952380952381\n",
      "Epoch 450/500: Loss = 2.2365039099696107 | Training Accuracy = 0.23076190476190475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21433333333333332"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "Lambda = 1e-7\n",
    "train_and_test_loop(500, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gU8B62CzAdTA"
   },
   "source": [
    "#### Hyperparameter Optimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qp_2H1IwCUIY"
   },
   "source": [
    "#### Running a finer search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "GZN36etSCUsA",
    "outputId": "9b5791f7-94d4-4134-b18c-f2bb284e340c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try 1/10: Best_val_acc: 0.18288888888888888, lr: 0.005248163657617819, Lambda: 64.48340786832672\n",
      "\n",
      "Try 2/10: Best_val_acc: 0.2053888888888889, lr: 0.006679712019881258, Lambda: 0.3646857771377305\n",
      "\n",
      "Try 3/10: Best_val_acc: 0.18827777777777777, lr: 0.0046008725625766725, Lambda: 0.03253300599381195\n",
      "\n",
      "Try 4/10: Best_val_acc: 0.19616666666666666, lr: 0.004120077105146745, Lambda: 13.396751846027179\n",
      "\n",
      "Try 5/10: Best_val_acc: 0.18988888888888888, lr: 0.0015322728061813945, Lambda: 0.05780821685783054\n",
      "\n",
      "Try 6/10: Best_val_acc: 0.2031111111111111, lr: 0.003223010681924104, Lambda: 19.57233858291238\n",
      "\n",
      "Try 7/10: Best_val_acc: 0.18738888888888888, lr: 0.007976192792141505, Lambda: 0.0004221599617830911\n",
      "\n",
      "Try 8/10: Best_val_acc: 0.19411111111111112, lr: 0.009793789314692974, Lambda: 1.7025515288536694\n",
      "\n",
      "Try 9/10: Best_val_acc: 0.19827777777777778, lr: 0.0023285365617220083, Lambda: 5.1261156557902146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for k in range(1, 10):\n",
    "    lr = math.pow(10, np.random.uniform(-3.0, -2.0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-5, 2))\n",
    "    best_acc = train_and_test_loop(100, lr, Lambda, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 10, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lzm9IwhkvrIm"
   },
   "source": [
    "##### Observation 2 - Baby sitting the neural network for SVHN\n",
    "* Best accuracy achieved using this method after hyperparameter optimization: 21%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uwYNz4zM-gob"
   },
   "source": [
    "<a id='BasicNN'></a>\n",
    "### Modelling - Neural Network API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vrFnLj4hP787"
   },
   "source": [
    "#### NN model, sigmoid activations, SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "clFSpvEc-fkg",
    "outputId": "4ce26658-e9be-40c6-d6c6-331144bd2345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN model with sigmoid activations\n",
      "--------------------------------------------------------------------------------\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "print('NN model with sigmoid activations'); print('--'*40)\n",
    "# Initialize the neural network classifier\n",
    "model1 = Sequential()\n",
    "\n",
    "# Input Layer - adding input layer and activation functions sigmoid\n",
    "model1.add(Dense(128, input_shape = (1024, )))\n",
    "# Adding activation function\n",
    "model1.add(Activation('sigmoid'))\n",
    "\n",
    "#Hidden Layer 1 - adding first hidden layer\n",
    "model1.add(Dense(64))\n",
    "# Adding activation function\n",
    "model1.add(Activation('sigmoid'))\n",
    "\n",
    "# Output Layer - adding output layer which is of 10 nodes (digits)\n",
    "model1.add(Dense(10))\n",
    "# Adding activation function - softmax for multiclass classification\n",
    "model1.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "vYDJ37MPlLiL",
    "outputId": "f3c7951d-68c1-4a5a-a18a-b1e0b246c517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 140,106\n",
      "Trainable params: 140,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RkURmgxTQYhx",
    "outputId": "5a9d0c3d-f955-4493-d0e4-d42618d9401b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 2.3172 - acc: 0.1011 - val_loss: 2.3029 - val_acc: 0.1029\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3030 - acc: 0.1024 - val_loss: 2.3030 - val_acc: 0.1024\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3031 - acc: 0.0996 - val_loss: 2.3028 - val_acc: 0.0991\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3030 - acc: 0.0988 - val_loss: 2.3028 - val_acc: 0.1019\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3029 - acc: 0.0998 - val_loss: 2.3027 - val_acc: 0.1009\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3028 - acc: 0.0989 - val_loss: 2.3029 - val_acc: 0.0998\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3028 - acc: 0.1022 - val_loss: 2.3026 - val_acc: 0.1011\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.3027 - acc: 0.1015 - val_loss: 2.3027 - val_acc: 0.0998\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.3027 - acc: 0.1011 - val_loss: 2.3028 - val_acc: 0.1001\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3027 - acc: 0.1016 - val_loss: 2.3026 - val_acc: 0.1012\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3027 - acc: 0.1014 - val_loss: 2.3024 - val_acc: 0.1020\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3026 - acc: 0.0993 - val_loss: 2.3024 - val_acc: 0.0998\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3026 - acc: 0.1008 - val_loss: 2.3023 - val_acc: 0.1032\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3025 - acc: 0.1026 - val_loss: 2.3023 - val_acc: 0.1045\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3024 - acc: 0.1019 - val_loss: 2.3022 - val_acc: 0.1067\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3024 - acc: 0.1028 - val_loss: 2.3022 - val_acc: 0.0962\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3024 - acc: 0.1019 - val_loss: 2.3022 - val_acc: 0.1077\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3023 - acc: 0.1036 - val_loss: 2.3021 - val_acc: 0.1125\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3022 - acc: 0.1033 - val_loss: 2.3022 - val_acc: 0.1000\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3023 - acc: 0.1028 - val_loss: 2.3021 - val_acc: 0.1013\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3022 - acc: 0.1040 - val_loss: 2.3021 - val_acc: 0.1061\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3021 - acc: 0.1048 - val_loss: 2.3020 - val_acc: 0.1111\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3021 - acc: 0.1043 - val_loss: 2.3020 - val_acc: 0.1078\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.3020 - acc: 0.1039 - val_loss: 2.3021 - val_acc: 0.1015\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3021 - acc: 0.1037 - val_loss: 2.3019 - val_acc: 0.1015\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3020 - acc: 0.1052 - val_loss: 2.3018 - val_acc: 0.1037\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.3020 - acc: 0.1053 - val_loss: 2.3018 - val_acc: 0.1041\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3019 - acc: 0.1047 - val_loss: 2.3018 - val_acc: 0.1081\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3019 - acc: 0.1064 - val_loss: 2.3018 - val_acc: 0.1072\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3019 - acc: 0.1028 - val_loss: 2.3018 - val_acc: 0.1039\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.3018 - acc: 0.1055 - val_loss: 2.3017 - val_acc: 0.1143\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3017 - acc: 0.1055 - val_loss: 2.3018 - val_acc: 0.1142\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3016 - acc: 0.1061 - val_loss: 2.3018 - val_acc: 0.1019\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.3018 - acc: 0.1057 - val_loss: 2.3015 - val_acc: 0.1066\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3017 - acc: 0.1079 - val_loss: 2.3015 - val_acc: 0.1040\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3017 - acc: 0.1078 - val_loss: 2.3015 - val_acc: 0.1039\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3014 - acc: 0.1084 - val_loss: 2.3018 - val_acc: 0.1082\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.3015 - acc: 0.1052 - val_loss: 2.3017 - val_acc: 0.0992\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3014 - acc: 0.1075 - val_loss: 2.3017 - val_acc: 0.1029\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3015 - acc: 0.1057 - val_loss: 2.3013 - val_acc: 0.1061\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3014 - acc: 0.1077 - val_loss: 2.3015 - val_acc: 0.1013\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3014 - acc: 0.1063 - val_loss: 2.3013 - val_acc: 0.1096\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3014 - acc: 0.1086 - val_loss: 2.3013 - val_acc: 0.1166\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3014 - acc: 0.1085 - val_loss: 2.3012 - val_acc: 0.1049\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3013 - acc: 0.1101 - val_loss: 2.3013 - val_acc: 0.1107\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3013 - acc: 0.1059 - val_loss: 2.3012 - val_acc: 0.1158\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.3012 - acc: 0.1110 - val_loss: 2.3012 - val_acc: 0.1061\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3012 - acc: 0.1094 - val_loss: 2.3011 - val_acc: 0.1081\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3012 - acc: 0.1083 - val_loss: 2.3013 - val_acc: 0.1005\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3011 - acc: 0.1099 - val_loss: 2.3011 - val_acc: 0.1132\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3010 - acc: 0.1121 - val_loss: 2.3013 - val_acc: 0.1023\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3011 - acc: 0.1110 - val_loss: 2.3010 - val_acc: 0.1064\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3011 - acc: 0.1106 - val_loss: 2.3009 - val_acc: 0.1101\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3010 - acc: 0.1100 - val_loss: 2.3009 - val_acc: 0.1094\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3009 - acc: 0.1097 - val_loss: 2.3009 - val_acc: 0.1133\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3009 - acc: 0.1113 - val_loss: 2.3009 - val_acc: 0.1195\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3009 - acc: 0.1130 - val_loss: 2.3008 - val_acc: 0.1099\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3009 - acc: 0.1145 - val_loss: 2.3008 - val_acc: 0.1093\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3009 - acc: 0.1117 - val_loss: 2.3008 - val_acc: 0.1138\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3008 - acc: 0.1125 - val_loss: 2.3006 - val_acc: 0.1204\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3008 - acc: 0.1122 - val_loss: 2.3007 - val_acc: 0.1053\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3007 - acc: 0.1095 - val_loss: 2.3008 - val_acc: 0.1187\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3007 - acc: 0.1140 - val_loss: 2.3007 - val_acc: 0.1177\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.3007 - acc: 0.1117 - val_loss: 2.3005 - val_acc: 0.1193\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3006 - acc: 0.1120 - val_loss: 2.3005 - val_acc: 0.1189\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3006 - acc: 0.1135 - val_loss: 2.3005 - val_acc: 0.1089\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3006 - acc: 0.1143 - val_loss: 2.3005 - val_acc: 0.1201\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3004 - acc: 0.1117 - val_loss: 2.3005 - val_acc: 0.1099\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3005 - acc: 0.1138 - val_loss: 2.3004 - val_acc: 0.1221\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3004 - acc: 0.1152 - val_loss: 2.3004 - val_acc: 0.1177\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3004 - acc: 0.1198 - val_loss: 2.3005 - val_acc: 0.1110\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3004 - acc: 0.1152 - val_loss: 2.3003 - val_acc: 0.1209\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3004 - acc: 0.1161 - val_loss: 2.3002 - val_acc: 0.1174\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3003 - acc: 0.1162 - val_loss: 2.3002 - val_acc: 0.1155\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3002 - acc: 0.1153 - val_loss: 2.3002 - val_acc: 0.1095\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3002 - acc: 0.1156 - val_loss: 2.3001 - val_acc: 0.1209\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3002 - acc: 0.1168 - val_loss: 2.3001 - val_acc: 0.1187\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3001 - acc: 0.1217 - val_loss: 2.3003 - val_acc: 0.1151\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3001 - acc: 0.1150 - val_loss: 2.3000 - val_acc: 0.1183\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3001 - acc: 0.1196 - val_loss: 2.3001 - val_acc: 0.1110\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3001 - acc: 0.1145 - val_loss: 2.3000 - val_acc: 0.1260\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.3000 - acc: 0.1196 - val_loss: 2.3001 - val_acc: 0.1094\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.3000 - acc: 0.1144 - val_loss: 2.2999 - val_acc: 0.1208\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2999 - acc: 0.1197 - val_loss: 2.2998 - val_acc: 0.1211\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2999 - acc: 0.1178 - val_loss: 2.2998 - val_acc: 0.1247\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.2998 - acc: 0.1186 - val_loss: 2.2997 - val_acc: 0.1234\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2998 - acc: 0.1185 - val_loss: 2.2998 - val_acc: 0.1148\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2998 - acc: 0.1168 - val_loss: 2.2997 - val_acc: 0.1222\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.2998 - acc: 0.1189 - val_loss: 2.2997 - val_acc: 0.1289\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2997 - acc: 0.1195 - val_loss: 2.2998 - val_acc: 0.1131\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2997 - acc: 0.1196 - val_loss: 2.2997 - val_acc: 0.1146\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2996 - acc: 0.1196 - val_loss: 2.2995 - val_acc: 0.1250\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2996 - acc: 0.1202 - val_loss: 2.2995 - val_acc: 0.1207\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2995 - acc: 0.1209 - val_loss: 2.2995 - val_acc: 0.1238\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2995 - acc: 0.1215 - val_loss: 2.2995 - val_acc: 0.1158\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2994 - acc: 0.1203 - val_loss: 2.2996 - val_acc: 0.1181\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2994 - acc: 0.1227 - val_loss: 2.2995 - val_acc: 0.1090\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2994 - acc: 0.1210 - val_loss: 2.2994 - val_acc: 0.1194\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2994 - acc: 0.1224 - val_loss: 2.2993 - val_acc: 0.1255\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2993 - acc: 0.1243 - val_loss: 2.2994 - val_acc: 0.1126\n"
     ]
    }
   ],
   "source": [
    "# compiling the neural network classifier, sgd optimizer\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model1.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the neural network for training\n",
    "history = model1.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "airVUr8-FQJ8",
    "outputId": "6ca2bcf8-d177-43c5-894f-c610cb411f3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate NN model with sigmoid activations\n",
      "--------------------------------------------------------------------------------\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 2.2994 - acc: 0.1126\n",
      "Validation accuracy: 11.26\n"
     ]
    }
   ],
   "source": [
    "print('Evaluate NN model with sigmoid activations'); print('--'*40)\n",
    "results1 = model1.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: {}'.format(round(results1[1]*100, 2), '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2rIo2V1Q10H"
   },
   "source": [
    "#### NN model, sigmoid activations, SGD optimizer, changing learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YTbX96-vGjFj",
    "outputId": "275c3e7d-35df-4a15-c2f1-e26a47eba163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN model with sigmoid activations - changing learning rate\n",
      "--------------------------------------------------------------------------------\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.2991 - acc: 0.1169 - val_loss: 2.2993 - val_acc: 0.1169\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1221 - val_loss: 2.2992 - val_acc: 0.1207\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2990 - acc: 0.1222 - val_loss: 2.2992 - val_acc: 0.1231\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1248 - val_loss: 2.2992 - val_acc: 0.1244\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1266 - val_loss: 2.2992 - val_acc: 0.1257\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1285 - val_loss: 2.2992 - val_acc: 0.1260\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1264 - val_loss: 2.2991 - val_acc: 0.1277\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1262 - val_loss: 2.2991 - val_acc: 0.1290\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1290 - val_loss: 2.2991 - val_acc: 0.1291\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1296 - val_loss: 2.2991 - val_acc: 0.1291\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2990 - acc: 0.1286 - val_loss: 2.2991 - val_acc: 0.1295\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1320 - val_loss: 2.2991 - val_acc: 0.1291\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2989 - acc: 0.1301 - val_loss: 2.2991 - val_acc: 0.1289\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1279 - val_loss: 2.2991 - val_acc: 0.1287\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1305 - val_loss: 2.2991 - val_acc: 0.1286\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.2989 - acc: 0.1282 - val_loss: 2.2991 - val_acc: 0.1289\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1305 - val_loss: 2.2991 - val_acc: 0.1286\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1276 - val_loss: 2.2991 - val_acc: 0.1293\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1284 - val_loss: 2.2991 - val_acc: 0.1300\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2989 - acc: 0.1305 - val_loss: 2.2991 - val_acc: 0.1300\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1314 - val_loss: 2.2991 - val_acc: 0.1294\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1301 - val_loss: 2.2991 - val_acc: 0.1296\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2989 - acc: 0.1304 - val_loss: 2.2991 - val_acc: 0.1293\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2989 - acc: 0.1315 - val_loss: 2.2991 - val_acc: 0.1279\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2989 - acc: 0.1285 - val_loss: 2.2991 - val_acc: 0.1289\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2989 - acc: 0.1281 - val_loss: 2.2991 - val_acc: 0.1292\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2989 - acc: 0.1303 - val_loss: 2.2991 - val_acc: 0.1293\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2989 - acc: 0.1315 - val_loss: 2.2991 - val_acc: 0.1281\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2989 - acc: 0.1288 - val_loss: 2.2991 - val_acc: 0.1285\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.2989 - acc: 0.1285 - val_loss: 2.2990 - val_acc: 0.1287\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.2989 - acc: 0.1293 - val_loss: 2.2990 - val_acc: 0.1290\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1287 - val_loss: 2.2990 - val_acc: 0.1294\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1316 - val_loss: 2.2990 - val_acc: 0.1288\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1297 - val_loss: 2.2990 - val_acc: 0.1289\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2989 - acc: 0.1300 - val_loss: 2.2990 - val_acc: 0.1294\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2989 - acc: 0.1313 - val_loss: 2.2990 - val_acc: 0.1283\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2988 - acc: 0.1293 - val_loss: 2.2990 - val_acc: 0.1284\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2988 - acc: 0.1300 - val_loss: 2.2990 - val_acc: 0.1288\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1285 - val_loss: 2.2990 - val_acc: 0.1293\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1292 - val_loss: 2.2990 - val_acc: 0.1298\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 2.2988 - acc: 0.1310 - val_loss: 2.2990 - val_acc: 0.1293\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1317 - val_loss: 2.2990 - val_acc: 0.1290\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1301 - val_loss: 2.2990 - val_acc: 0.1291\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1301 - val_loss: 2.2990 - val_acc: 0.1285\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1310 - val_loss: 2.2990 - val_acc: 0.1288\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1300 - val_loss: 2.2990 - val_acc: 0.1286\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1310 - val_loss: 2.2990 - val_acc: 0.1283\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1312 - val_loss: 2.2990 - val_acc: 0.1279\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1260 - val_loss: 2.2990 - val_acc: 0.1295\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1295 - val_loss: 2.2990 - val_acc: 0.1300\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1297 - val_loss: 2.2990 - val_acc: 0.1302\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2988 - acc: 0.1319 - val_loss: 2.2990 - val_acc: 0.1297\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.2988 - acc: 0.1313 - val_loss: 2.2990 - val_acc: 0.1287\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1287 - val_loss: 2.2989 - val_acc: 0.1296\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1314 - val_loss: 2.2989 - val_acc: 0.1295\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1299 - val_loss: 2.2989 - val_acc: 0.1292\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2988 - acc: 0.1321 - val_loss: 2.2989 - val_acc: 0.1289\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1298 - val_loss: 2.2989 - val_acc: 0.1293\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2988 - acc: 0.1293 - val_loss: 2.2989 - val_acc: 0.1301\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2988 - acc: 0.1285 - val_loss: 2.2989 - val_acc: 0.1304\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1317 - val_loss: 2.2989 - val_acc: 0.1305\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2987 - acc: 0.1312 - val_loss: 2.2989 - val_acc: 0.1306\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1307 - val_loss: 2.2989 - val_acc: 0.1302\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1331 - val_loss: 2.2989 - val_acc: 0.1294\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1318 - val_loss: 2.2989 - val_acc: 0.1296\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1304 - val_loss: 2.2989 - val_acc: 0.1296\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1306 - val_loss: 2.2989 - val_acc: 0.1300\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1323 - val_loss: 2.2989 - val_acc: 0.1293\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2987 - acc: 0.1300 - val_loss: 2.2989 - val_acc: 0.1298\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.2987 - acc: 0.1308 - val_loss: 2.2989 - val_acc: 0.1302\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2987 - acc: 0.1307 - val_loss: 2.2989 - val_acc: 0.1304\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2987 - acc: 0.1316 - val_loss: 2.2989 - val_acc: 0.1309\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2987 - acc: 0.1319 - val_loss: 2.2989 - val_acc: 0.1301\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2987 - acc: 0.1331 - val_loss: 2.2989 - val_acc: 0.1287\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1304 - val_loss: 2.2989 - val_acc: 0.1290\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2987 - acc: 0.1294 - val_loss: 2.2989 - val_acc: 0.1298\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2987 - acc: 0.1307 - val_loss: 2.2989 - val_acc: 0.1300\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1292 - val_loss: 2.2989 - val_acc: 0.1303\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1312 - val_loss: 2.2988 - val_acc: 0.1303\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2987 - acc: 0.1324 - val_loss: 2.2988 - val_acc: 0.1301\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1315 - val_loss: 2.2988 - val_acc: 0.1308\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2987 - acc: 0.1318 - val_loss: 2.2988 - val_acc: 0.1305\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2987 - acc: 0.1308 - val_loss: 2.2988 - val_acc: 0.1310\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2987 - acc: 0.1311 - val_loss: 2.2988 - val_acc: 0.1316\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1324 - val_loss: 2.2988 - val_acc: 0.1314\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1318 - val_loss: 2.2988 - val_acc: 0.1308\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1334 - val_loss: 2.2988 - val_acc: 0.1299\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1312 - val_loss: 2.2988 - val_acc: 0.1305\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1306 - val_loss: 2.2988 - val_acc: 0.1307\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1332 - val_loss: 2.2988 - val_acc: 0.1297\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1320 - val_loss: 2.2988 - val_acc: 0.1299\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 2.2986 - acc: 0.1315 - val_loss: 2.2988 - val_acc: 0.1297\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2986 - acc: 0.1313 - val_loss: 2.2988 - val_acc: 0.1295\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1301 - val_loss: 2.2988 - val_acc: 0.1297\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.2986 - acc: 0.1307 - val_loss: 2.2988 - val_acc: 0.1302\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1309 - val_loss: 2.2988 - val_acc: 0.1303\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2986 - acc: 0.1324 - val_loss: 2.2988 - val_acc: 0.1299\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1320 - val_loss: 2.2988 - val_acc: 0.1295\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2986 - acc: 0.1299 - val_loss: 2.2988 - val_acc: 0.1310\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2986 - acc: 0.1308 - val_loss: 2.2988 - val_acc: 0.1307\n"
     ]
    }
   ],
   "source": [
    "print('NN model with sigmoid activations - changing learning rate'); print('--'*40)\n",
    "# compiling the neural network classifier, sgd optimizer\n",
    "sgd = optimizers.SGD(lr = 0.001)\n",
    "model1.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the neural network for training\n",
    "history = model1.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "scbm_YOeJkap",
    "outputId": "a96146ce-4b68-43da-f4b7-7005e0e5e1c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate NN model with sigmoid activations - changing learning rate\n",
      "--------------------------------------------------------------------------------\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 2.2988 - acc: 0.1307\n",
      "Validation accuracy: 13.07\n"
     ]
    }
   ],
   "source": [
    "print('Evaluate NN model with sigmoid activations - changing learning rate'); print('--'*40)\n",
    "results1 = model1.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: {}'.format(round(results1[1]*100, 2), '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SUgKHYEmt1X"
   },
   "source": [
    "<a id='o3'></a>\n",
    "##### Observation 3 - NN model with sigmoid activations\n",
    "* Validation score is very low, changing learning rate further reduces it.\n",
    "* Optimizing the network in order to better learn the patterns in the dataset.\n",
    "* Best model out of the above is the one with lower learning rate using SGD optimizer and sigmoid activations.\n",
    "* Next, let's use relu activations and see if the score improves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3qkfHovRFig"
   },
   "source": [
    "#### NN model, relu activations, SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "BRsNW7ss_iL9",
    "outputId": "0ba86d89-5f13-4e0e-c9bc-2a96bcbee867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 s, sys: 1 s, total: 3 s\n",
      "Wall time: 6.68 s\n",
      "NN model with relu activations and sgd optimizers\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "print('NN model with relu activations and sgd optimizers'); print('--'*40)\n",
    "# Initialize the neural network classifier\n",
    "model2 = Sequential()\n",
    "\n",
    "# Input Layer - adding input layer and activation functions relu\n",
    "model2.add(Dense(128, input_shape = (1024, )))\n",
    "# Adding activation function\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "#Hidden Layer 1 - adding first hidden layer\n",
    "model2.add(Dense(64))\n",
    "# Adding activation function\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "# Output Layer - adding output layer which is of 10 nodes (digits)\n",
    "model2.add(Dense(10))\n",
    "# Adding activation function - softmax for multiclass classification\n",
    "model2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "x4uIPsDZqi8n",
    "outputId": "b633d453-b0bf-4b57-e252-8e313eb8cf12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 140,106\n",
      "Trainable params: 140,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OJzn5I1ORL8q",
    "outputId": "674afc1b-75b8-4cfa-f82e-c27339777082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.3001 - acc: 0.1166 - val_loss: 2.2903 - val_acc: 0.1328\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2854 - acc: 0.1465 - val_loss: 2.2786 - val_acc: 0.1673\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2722 - acc: 0.1781 - val_loss: 2.2643 - val_acc: 0.1904\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2561 - acc: 0.2140 - val_loss: 2.2467 - val_acc: 0.2199\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.2369 - acc: 0.2507 - val_loss: 2.2263 - val_acc: 0.2579\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.2128 - acc: 0.2883 - val_loss: 2.1973 - val_acc: 0.3150\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.1828 - acc: 0.3158 - val_loss: 2.1645 - val_acc: 0.3450\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.1463 - acc: 0.3465 - val_loss: 2.1254 - val_acc: 0.3584\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.1025 - acc: 0.3752 - val_loss: 2.0772 - val_acc: 0.3822\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 2.0490 - acc: 0.4008 - val_loss: 2.0188 - val_acc: 0.4164\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.9873 - acc: 0.4255 - val_loss: 1.9517 - val_acc: 0.4352\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.9183 - acc: 0.4470 - val_loss: 1.8801 - val_acc: 0.4531\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.8455 - acc: 0.4674 - val_loss: 1.8076 - val_acc: 0.4808\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.7732 - acc: 0.4886 - val_loss: 1.7343 - val_acc: 0.4963\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.7041 - acc: 0.5085 - val_loss: 1.6676 - val_acc: 0.5157\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.6407 - acc: 0.5236 - val_loss: 1.6103 - val_acc: 0.5370\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.5833 - acc: 0.5417 - val_loss: 1.5525 - val_acc: 0.5501\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.5326 - acc: 0.5534 - val_loss: 1.5026 - val_acc: 0.5629\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.4851 - acc: 0.5659 - val_loss: 1.4584 - val_acc: 0.5728\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.4431 - acc: 0.5756 - val_loss: 1.4193 - val_acc: 0.5908\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.4061 - acc: 0.5859 - val_loss: 1.3822 - val_acc: 0.5966\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.3737 - acc: 0.5931 - val_loss: 1.3552 - val_acc: 0.5914\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.3442 - acc: 0.6000 - val_loss: 1.3209 - val_acc: 0.6088\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.3146 - acc: 0.6076 - val_loss: 1.2990 - val_acc: 0.6103\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.2933 - acc: 0.6137 - val_loss: 1.2714 - val_acc: 0.6263\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.2681 - acc: 0.6206 - val_loss: 1.2635 - val_acc: 0.6183\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.2485 - acc: 0.6246 - val_loss: 1.2253 - val_acc: 0.6389\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.2259 - acc: 0.6333 - val_loss: 1.2039 - val_acc: 0.6449\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.2094 - acc: 0.6355 - val_loss: 1.1899 - val_acc: 0.6465\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.1919 - acc: 0.6437 - val_loss: 1.1801 - val_acc: 0.6503\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.1786 - acc: 0.6477 - val_loss: 1.1587 - val_acc: 0.6580\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.1616 - acc: 0.6523 - val_loss: 1.1568 - val_acc: 0.6514\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.1512 - acc: 0.6531 - val_loss: 1.1345 - val_acc: 0.6618\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.1352 - acc: 0.6613 - val_loss: 1.1188 - val_acc: 0.6700\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.1242 - acc: 0.6632 - val_loss: 1.1040 - val_acc: 0.6727\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.1088 - acc: 0.6689 - val_loss: 1.0946 - val_acc: 0.6725\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0974 - acc: 0.6719 - val_loss: 1.0941 - val_acc: 0.6751\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0869 - acc: 0.6758 - val_loss: 1.0704 - val_acc: 0.6830\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0775 - acc: 0.6783 - val_loss: 1.0789 - val_acc: 0.6772\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0685 - acc: 0.6812 - val_loss: 1.0560 - val_acc: 0.6874\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0565 - acc: 0.6835 - val_loss: 1.0430 - val_acc: 0.6918\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0457 - acc: 0.6873 - val_loss: 1.0934 - val_acc: 0.6640\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.0348 - acc: 0.6916 - val_loss: 1.0173 - val_acc: 0.6985\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.0230 - acc: 0.6930 - val_loss: 1.0077 - val_acc: 0.7038\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.0125 - acc: 0.6962 - val_loss: 0.9966 - val_acc: 0.7057\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0083 - acc: 0.6993 - val_loss: 1.0228 - val_acc: 0.6914\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.9951 - acc: 0.7034 - val_loss: 1.0381 - val_acc: 0.6836\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9866 - acc: 0.7040 - val_loss: 0.9950 - val_acc: 0.7046\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9829 - acc: 0.7075 - val_loss: 0.9727 - val_acc: 0.7103\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9720 - acc: 0.7098 - val_loss: 0.9611 - val_acc: 0.7149\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9621 - acc: 0.7136 - val_loss: 0.9521 - val_acc: 0.7190\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9557 - acc: 0.7144 - val_loss: 0.9603 - val_acc: 0.7140\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9464 - acc: 0.7175 - val_loss: 0.9550 - val_acc: 0.7157\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9408 - acc: 0.7178 - val_loss: 0.9284 - val_acc: 0.7271\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9319 - acc: 0.7215 - val_loss: 0.9394 - val_acc: 0.7183\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9281 - acc: 0.7238 - val_loss: 0.9207 - val_acc: 0.7272\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9127 - acc: 0.7280 - val_loss: 0.9036 - val_acc: 0.7338\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9087 - acc: 0.7296 - val_loss: 0.9100 - val_acc: 0.7281\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9039 - acc: 0.7315 - val_loss: 0.9017 - val_acc: 0.7313\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.8953 - acc: 0.7330 - val_loss: 0.8901 - val_acc: 0.7363\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8903 - acc: 0.7342 - val_loss: 0.9211 - val_acc: 0.7243\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8842 - acc: 0.7363 - val_loss: 0.8956 - val_acc: 0.7299\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8779 - acc: 0.7378 - val_loss: 0.8624 - val_acc: 0.7475\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8720 - acc: 0.7404 - val_loss: 0.8584 - val_acc: 0.7469\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8632 - acc: 0.7435 - val_loss: 0.8876 - val_acc: 0.7364\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8595 - acc: 0.7448 - val_loss: 0.8548 - val_acc: 0.7465\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8490 - acc: 0.7484 - val_loss: 0.8642 - val_acc: 0.7442\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8486 - acc: 0.7457 - val_loss: 0.8481 - val_acc: 0.7492\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8393 - acc: 0.7504 - val_loss: 0.8327 - val_acc: 0.7544\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8353 - acc: 0.7501 - val_loss: 0.8289 - val_acc: 0.7560\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8261 - acc: 0.7539 - val_loss: 0.8208 - val_acc: 0.7594\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8244 - acc: 0.7542 - val_loss: 0.8829 - val_acc: 0.7296\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8219 - acc: 0.7559 - val_loss: 0.8300 - val_acc: 0.7531\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8139 - acc: 0.7574 - val_loss: 0.8140 - val_acc: 0.7588\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8078 - acc: 0.7588 - val_loss: 0.8330 - val_acc: 0.7498\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8063 - acc: 0.7593 - val_loss: 0.7989 - val_acc: 0.7649\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.8026 - acc: 0.7609 - val_loss: 0.8428 - val_acc: 0.7449\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7969 - acc: 0.7625 - val_loss: 0.8424 - val_acc: 0.7461\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7871 - acc: 0.7662 - val_loss: 0.8011 - val_acc: 0.7637\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7874 - acc: 0.7667 - val_loss: 0.7827 - val_acc: 0.7681\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7836 - acc: 0.7662 - val_loss: 0.7725 - val_acc: 0.7734\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7790 - acc: 0.7682 - val_loss: 0.7892 - val_acc: 0.7655\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7736 - acc: 0.7713 - val_loss: 0.7670 - val_acc: 0.7764\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7643 - acc: 0.7731 - val_loss: 0.7617 - val_acc: 0.7786\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7653 - acc: 0.7727 - val_loss: 0.7642 - val_acc: 0.7736\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7625 - acc: 0.7740 - val_loss: 0.7830 - val_acc: 0.7649\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7564 - acc: 0.7759 - val_loss: 0.7579 - val_acc: 0.7788\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7540 - acc: 0.7751 - val_loss: 0.7516 - val_acc: 0.7801\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7418 - acc: 0.7804 - val_loss: 0.7488 - val_acc: 0.7813\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7452 - acc: 0.7795 - val_loss: 0.7650 - val_acc: 0.7742\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7419 - acc: 0.7801 - val_loss: 0.7780 - val_acc: 0.7645\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.7399 - acc: 0.7804 - val_loss: 0.7546 - val_acc: 0.7770\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7336 - acc: 0.7807 - val_loss: 0.7553 - val_acc: 0.7751\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.7345 - acc: 0.7808 - val_loss: 0.7326 - val_acc: 0.7833\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7269 - acc: 0.7834 - val_loss: 0.7250 - val_acc: 0.7897\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7175 - acc: 0.7872 - val_loss: 0.7265 - val_acc: 0.7863\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7217 - acc: 0.7840 - val_loss: 0.7476 - val_acc: 0.7760\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.7156 - acc: 0.7873 - val_loss: 0.7110 - val_acc: 0.7939\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.7118 - acc: 0.7906 - val_loss: 0.7762 - val_acc: 0.7646\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7070 - acc: 0.7895 - val_loss: 0.7015 - val_acc: 0.7965\n"
     ]
    }
   ],
   "source": [
    "# compiling the neural network classifier, sgd optimizer\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model2.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the neural network for training\n",
    "history = model2.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "RGwKAGtRDEm8",
    "outputId": "071ffd46-eaf6-4cd6-ad9f-d03e610e4ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate NN model with relu activations\n",
      "--------------------------------------------------------------------------------\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.7015 - acc: 0.7965\n",
      "Validation accuracy: 79.65\n"
     ]
    }
   ],
   "source": [
    "print('Evaluate NN model with relu activations'); print('--'*40)\n",
    "results2 = model2.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: {}'.format(round(results2[1]*100, 2), '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4p0ZX0GTRRyG"
   },
   "source": [
    "#### NN model, relu activations, SGD optimizer, changing learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DWIBrdDdGnDY",
    "outputId": "9bf968c3-4375-4a81-daf3-aa8f6f228898"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 s, sys: 1e+03 ns, total: 3 s\n",
      "Wall time: 15.5 s\n",
      "NN model with relu activations and sgd optimizers - changing learning rate\n",
      "--------------------------------------------------------------------------------\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6704 - acc: 0.8051 - val_loss: 0.6922 - val_acc: 0.8003\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6680 - acc: 0.8054 - val_loss: 0.6917 - val_acc: 0.7996\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6679 - acc: 0.8055 - val_loss: 0.6901 - val_acc: 0.8005\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6671 - acc: 0.8058 - val_loss: 0.6899 - val_acc: 0.7997\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6665 - acc: 0.8065 - val_loss: 0.6900 - val_acc: 0.8002\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6665 - acc: 0.8061 - val_loss: 0.6891 - val_acc: 0.8007\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6659 - acc: 0.8061 - val_loss: 0.6901 - val_acc: 0.8005\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6655 - acc: 0.8067 - val_loss: 0.6885 - val_acc: 0.8010\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6651 - acc: 0.8063 - val_loss: 0.6880 - val_acc: 0.8008\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6648 - acc: 0.8069 - val_loss: 0.6878 - val_acc: 0.8016\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6643 - acc: 0.8066 - val_loss: 0.6878 - val_acc: 0.8010\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6637 - acc: 0.8069 - val_loss: 0.6871 - val_acc: 0.8013\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6638 - acc: 0.8066 - val_loss: 0.6866 - val_acc: 0.8017\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6632 - acc: 0.8067 - val_loss: 0.6865 - val_acc: 0.8019\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6627 - acc: 0.8073 - val_loss: 0.6869 - val_acc: 0.8012\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6625 - acc: 0.8076 - val_loss: 0.6858 - val_acc: 0.8022\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6623 - acc: 0.8075 - val_loss: 0.6851 - val_acc: 0.8023\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6619 - acc: 0.8079 - val_loss: 0.6852 - val_acc: 0.8011\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6611 - acc: 0.8081 - val_loss: 0.6861 - val_acc: 0.8014\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6610 - acc: 0.8076 - val_loss: 0.6847 - val_acc: 0.8024\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6606 - acc: 0.8094 - val_loss: 0.6845 - val_acc: 0.8022\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6603 - acc: 0.8082 - val_loss: 0.6841 - val_acc: 0.8021\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6602 - acc: 0.8080 - val_loss: 0.6833 - val_acc: 0.8022\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6594 - acc: 0.8084 - val_loss: 0.6835 - val_acc: 0.8027\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6592 - acc: 0.8084 - val_loss: 0.6834 - val_acc: 0.8022\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6587 - acc: 0.8086 - val_loss: 0.6830 - val_acc: 0.8022\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6585 - acc: 0.8086 - val_loss: 0.6827 - val_acc: 0.8020\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6582 - acc: 0.8083 - val_loss: 0.6815 - val_acc: 0.8029\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6578 - acc: 0.8085 - val_loss: 0.6820 - val_acc: 0.8035\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6573 - acc: 0.8087 - val_loss: 0.6811 - val_acc: 0.8037\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6568 - acc: 0.8087 - val_loss: 0.6810 - val_acc: 0.8034\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6568 - acc: 0.8094 - val_loss: 0.6814 - val_acc: 0.8037\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6561 - acc: 0.8095 - val_loss: 0.6820 - val_acc: 0.8025\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6561 - acc: 0.8091 - val_loss: 0.6800 - val_acc: 0.8039\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6556 - acc: 0.8095 - val_loss: 0.6815 - val_acc: 0.8023\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6553 - acc: 0.8102 - val_loss: 0.6793 - val_acc: 0.8039\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6552 - acc: 0.8091 - val_loss: 0.6786 - val_acc: 0.8048\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6545 - acc: 0.8091 - val_loss: 0.6787 - val_acc: 0.8039\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6544 - acc: 0.8102 - val_loss: 0.6791 - val_acc: 0.8040\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6538 - acc: 0.8104 - val_loss: 0.6795 - val_acc: 0.8035\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6536 - acc: 0.8103 - val_loss: 0.6788 - val_acc: 0.8041\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6531 - acc: 0.8098 - val_loss: 0.6793 - val_acc: 0.8042\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6528 - acc: 0.8108 - val_loss: 0.6783 - val_acc: 0.8041\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6525 - acc: 0.8099 - val_loss: 0.6770 - val_acc: 0.8048\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6522 - acc: 0.8120 - val_loss: 0.6772 - val_acc: 0.8040\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6518 - acc: 0.8104 - val_loss: 0.6773 - val_acc: 0.8048\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6514 - acc: 0.8103 - val_loss: 0.6762 - val_acc: 0.8050\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6512 - acc: 0.8111 - val_loss: 0.6762 - val_acc: 0.8047\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6509 - acc: 0.8113 - val_loss: 0.6750 - val_acc: 0.8047\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6503 - acc: 0.8108 - val_loss: 0.6763 - val_acc: 0.8041\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6502 - acc: 0.8111 - val_loss: 0.6752 - val_acc: 0.8049\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6497 - acc: 0.8110 - val_loss: 0.6747 - val_acc: 0.8061\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6495 - acc: 0.8118 - val_loss: 0.6739 - val_acc: 0.8058\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6493 - acc: 0.8111 - val_loss: 0.6742 - val_acc: 0.8049\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6491 - acc: 0.8117 - val_loss: 0.6735 - val_acc: 0.8054\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6483 - acc: 0.8115 - val_loss: 0.6735 - val_acc: 0.8059\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6482 - acc: 0.8117 - val_loss: 0.6736 - val_acc: 0.8061\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6479 - acc: 0.8123 - val_loss: 0.6735 - val_acc: 0.8053\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6475 - acc: 0.8125 - val_loss: 0.6731 - val_acc: 0.8060\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6472 - acc: 0.8123 - val_loss: 0.6724 - val_acc: 0.8061\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6469 - acc: 0.8119 - val_loss: 0.6721 - val_acc: 0.8064\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6465 - acc: 0.8119 - val_loss: 0.6723 - val_acc: 0.8060\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6463 - acc: 0.8126 - val_loss: 0.6713 - val_acc: 0.8056\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6460 - acc: 0.8130 - val_loss: 0.6707 - val_acc: 0.8064\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6454 - acc: 0.8123 - val_loss: 0.6711 - val_acc: 0.8061\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6453 - acc: 0.8136 - val_loss: 0.6703 - val_acc: 0.8069\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6449 - acc: 0.8130 - val_loss: 0.6699 - val_acc: 0.8062\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6446 - acc: 0.8127 - val_loss: 0.6698 - val_acc: 0.8075\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6442 - acc: 0.8132 - val_loss: 0.6693 - val_acc: 0.8071\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6437 - acc: 0.8129 - val_loss: 0.6696 - val_acc: 0.8058\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6437 - acc: 0.8131 - val_loss: 0.6694 - val_acc: 0.8057\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6433 - acc: 0.8131 - val_loss: 0.6692 - val_acc: 0.8067\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6430 - acc: 0.8137 - val_loss: 0.6687 - val_acc: 0.8073\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6428 - acc: 0.8131 - val_loss: 0.6690 - val_acc: 0.8073\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6425 - acc: 0.8139 - val_loss: 0.6676 - val_acc: 0.8073\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6419 - acc: 0.8140 - val_loss: 0.6672 - val_acc: 0.8077\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6418 - acc: 0.8141 - val_loss: 0.6672 - val_acc: 0.8074\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6415 - acc: 0.8141 - val_loss: 0.6676 - val_acc: 0.8061\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6411 - acc: 0.8145 - val_loss: 0.6669 - val_acc: 0.8072\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6409 - acc: 0.8139 - val_loss: 0.6685 - val_acc: 0.8061\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6408 - acc: 0.8138 - val_loss: 0.6668 - val_acc: 0.8075\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6404 - acc: 0.8141 - val_loss: 0.6655 - val_acc: 0.8078\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6398 - acc: 0.8137 - val_loss: 0.6651 - val_acc: 0.8077\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6394 - acc: 0.8151 - val_loss: 0.6666 - val_acc: 0.8076\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6395 - acc: 0.8140 - val_loss: 0.6655 - val_acc: 0.8083\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6392 - acc: 0.8147 - val_loss: 0.6653 - val_acc: 0.8075\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6387 - acc: 0.8147 - val_loss: 0.6643 - val_acc: 0.8076\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6384 - acc: 0.8151 - val_loss: 0.6646 - val_acc: 0.8078\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6380 - acc: 0.8145 - val_loss: 0.6636 - val_acc: 0.8078\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6375 - acc: 0.8148 - val_loss: 0.6638 - val_acc: 0.8083\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6376 - acc: 0.8157 - val_loss: 0.6637 - val_acc: 0.8088\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6370 - acc: 0.8152 - val_loss: 0.6632 - val_acc: 0.8087\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6367 - acc: 0.8152 - val_loss: 0.6636 - val_acc: 0.8081\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6367 - acc: 0.8140 - val_loss: 0.6623 - val_acc: 0.8089\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6362 - acc: 0.8158 - val_loss: 0.6631 - val_acc: 0.8092\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6358 - acc: 0.8150 - val_loss: 0.6630 - val_acc: 0.8080\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6358 - acc: 0.8151 - val_loss: 0.6615 - val_acc: 0.8091\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6353 - acc: 0.8160 - val_loss: 0.6622 - val_acc: 0.8086\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6350 - acc: 0.8152 - val_loss: 0.6614 - val_acc: 0.8087\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6348 - acc: 0.8156 - val_loss: 0.6611 - val_acc: 0.8088\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "print('NN model with relu activations and sgd optimizers - changing learning rate'); print('--'*40)\n",
    "# compiling the neural network classifier, sgd optimizer\n",
    "sgd = optimizers.SGD(lr = 0.001)\n",
    "model2.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the neural network for training\n",
    "history = model2.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "9O9KhqH5HMWW",
    "outputId": "03347a3f-e86f-45b9-dce0-8d47001f6b07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate NN model with relu activations\n",
      "--------------------------------------------------------------------------------\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.6611 - acc: 0.8088\n",
      "Validation accuracy: 80.88\n"
     ]
    }
   ],
   "source": [
    "print('Evaluate NN model with relu activations'); print('--'*40)\n",
    "results2 = model2.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: {}'.format(round(results2[1]*100, 2), '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CKJFAr9JRfJJ"
   },
   "source": [
    "#### NN model, relu activations, adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9Q8PtyA-Jw74",
    "outputId": "15020f47-a35d-45bf-9090-cd6556442388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 s, sys: 0 ns, total: 2 s\n",
      "Wall time: 5.01 s\n",
      "NN model with relu activations and adam optimizer\n",
      "--------------------------------------------------------------------------------\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 3.3943 - acc: 0.1031 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 2.3013 - acc: 0.1004 - val_loss: 2.3027 - val_acc: 0.1014\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 2.2895 - acc: 0.1191 - val_loss: 2.2743 - val_acc: 0.1331\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.2683 - acc: 0.1293 - val_loss: 2.2518 - val_acc: 0.1432\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.1576 - acc: 0.1853 - val_loss: 2.0355 - val_acc: 0.2498\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.8345 - acc: 0.3417 - val_loss: 1.6677 - val_acc: 0.4254\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.5568 - acc: 0.4742 - val_loss: 1.4540 - val_acc: 0.5070\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.3969 - acc: 0.5453 - val_loss: 1.4334 - val_acc: 0.5188\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.3505 - acc: 0.5663 - val_loss: 1.3200 - val_acc: 0.5760\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.2855 - acc: 0.5901 - val_loss: 1.2031 - val_acc: 0.6226\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.2371 - acc: 0.6069 - val_loss: 1.2411 - val_acc: 0.6005\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.2108 - acc: 0.6166 - val_loss: 1.2598 - val_acc: 0.5979\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.2105 - acc: 0.6179 - val_loss: 1.2068 - val_acc: 0.6124\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.1587 - acc: 0.6356 - val_loss: 1.1786 - val_acc: 0.6265\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.1466 - acc: 0.6399 - val_loss: 1.0966 - val_acc: 0.6581\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.1529 - acc: 0.6390 - val_loss: 1.2340 - val_acc: 0.6092\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.1638 - acc: 0.6342 - val_loss: 1.1474 - val_acc: 0.6446\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.1361 - acc: 0.6437 - val_loss: 1.1375 - val_acc: 0.6424\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.1319 - acc: 0.6441 - val_loss: 1.1487 - val_acc: 0.6376\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.1126 - acc: 0.6519 - val_loss: 1.0731 - val_acc: 0.6636\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.1100 - acc: 0.6529 - val_loss: 1.1204 - val_acc: 0.6526\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.1103 - acc: 0.6528 - val_loss: 1.1775 - val_acc: 0.6292\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.1069 - acc: 0.6525 - val_loss: 1.0985 - val_acc: 0.6520\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0999 - acc: 0.6546 - val_loss: 1.0967 - val_acc: 0.6591\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0973 - acc: 0.6555 - val_loss: 1.0405 - val_acc: 0.6792\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.1014 - acc: 0.6541 - val_loss: 1.1677 - val_acc: 0.6265\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0893 - acc: 0.6584 - val_loss: 1.0540 - val_acc: 0.6711\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0889 - acc: 0.6568 - val_loss: 1.0725 - val_acc: 0.6622\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0825 - acc: 0.6615 - val_loss: 1.1438 - val_acc: 0.6394\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0843 - acc: 0.6596 - val_loss: 1.0277 - val_acc: 0.6816\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0669 - acc: 0.6661 - val_loss: 1.0409 - val_acc: 0.6762\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.0803 - acc: 0.6599 - val_loss: 1.0849 - val_acc: 0.6575\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0737 - acc: 0.6627 - val_loss: 1.1215 - val_acc: 0.6391\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0673 - acc: 0.6649 - val_loss: 1.0624 - val_acc: 0.6672\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0648 - acc: 0.6656 - val_loss: 1.0486 - val_acc: 0.6743\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0647 - acc: 0.6647 - val_loss: 1.0660 - val_acc: 0.6658\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0650 - acc: 0.6636 - val_loss: 1.0980 - val_acc: 0.6513\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0624 - acc: 0.6673 - val_loss: 1.0543 - val_acc: 0.6686\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0690 - acc: 0.6653 - val_loss: 1.0335 - val_acc: 0.6793\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0487 - acc: 0.6729 - val_loss: 1.0449 - val_acc: 0.6762\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0556 - acc: 0.6700 - val_loss: 1.0483 - val_acc: 0.6722\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0526 - acc: 0.6711 - val_loss: 1.0227 - val_acc: 0.6811\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0472 - acc: 0.6733 - val_loss: 1.0363 - val_acc: 0.6783\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0532 - acc: 0.6717 - val_loss: 1.0223 - val_acc: 0.6808\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0416 - acc: 0.6732 - val_loss: 1.0771 - val_acc: 0.6583\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0372 - acc: 0.6736 - val_loss: 1.0675 - val_acc: 0.6671\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0606 - acc: 0.6655 - val_loss: 1.0282 - val_acc: 0.6787\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.0661 - acc: 0.6638 - val_loss: 1.0242 - val_acc: 0.6798\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0452 - acc: 0.6718 - val_loss: 1.0708 - val_acc: 0.6636\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.0386 - acc: 0.6764 - val_loss: 1.0317 - val_acc: 0.6770\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0393 - acc: 0.6755 - val_loss: 1.0551 - val_acc: 0.6654\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0469 - acc: 0.6717 - val_loss: 1.0547 - val_acc: 0.6689\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0485 - acc: 0.6729 - val_loss: 1.0864 - val_acc: 0.6599\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.0401 - acc: 0.6743 - val_loss: 0.9906 - val_acc: 0.6897\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0368 - acc: 0.6735 - val_loss: 1.0132 - val_acc: 0.6853\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0445 - acc: 0.6722 - val_loss: 1.0171 - val_acc: 0.6813\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.0387 - acc: 0.6763 - val_loss: 1.0498 - val_acc: 0.6689\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0460 - acc: 0.6731 - val_loss: 1.0686 - val_acc: 0.6675\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0375 - acc: 0.6751 - val_loss: 1.0465 - val_acc: 0.6723\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0389 - acc: 0.6742 - val_loss: 1.0595 - val_acc: 0.6651\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0250 - acc: 0.6791 - val_loss: 1.0227 - val_acc: 0.6823\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0342 - acc: 0.6758 - val_loss: 1.0227 - val_acc: 0.6824\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0375 - acc: 0.6764 - val_loss: 1.0060 - val_acc: 0.6898\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0230 - acc: 0.6793 - val_loss: 1.0115 - val_acc: 0.6835\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0224 - acc: 0.6798 - val_loss: 1.0603 - val_acc: 0.6657\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0352 - acc: 0.6760 - val_loss: 1.0281 - val_acc: 0.6746\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0335 - acc: 0.6775 - val_loss: 0.9844 - val_acc: 0.6960\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0224 - acc: 0.6811 - val_loss: 1.0320 - val_acc: 0.6740\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.0351 - acc: 0.6750 - val_loss: 1.0805 - val_acc: 0.6631\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0223 - acc: 0.6813 - val_loss: 1.0350 - val_acc: 0.6804\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0255 - acc: 0.6781 - val_loss: 1.0166 - val_acc: 0.6827\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0279 - acc: 0.6781 - val_loss: 1.0422 - val_acc: 0.6733\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0341 - acc: 0.6777 - val_loss: 0.9790 - val_acc: 0.6986\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0214 - acc: 0.6818 - val_loss: 1.0892 - val_acc: 0.6592\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0283 - acc: 0.6802 - val_loss: 1.0154 - val_acc: 0.6855\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0244 - acc: 0.6779 - val_loss: 1.0062 - val_acc: 0.6894\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0194 - acc: 0.6811 - val_loss: 1.0128 - val_acc: 0.6851\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0110 - acc: 0.6831 - val_loss: 1.0117 - val_acc: 0.6898\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0215 - acc: 0.6807 - val_loss: 1.0087 - val_acc: 0.6883\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0231 - acc: 0.6806 - val_loss: 1.0040 - val_acc: 0.6889\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0298 - acc: 0.6776 - val_loss: 1.0346 - val_acc: 0.6800\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0202 - acc: 0.6811 - val_loss: 1.0856 - val_acc: 0.6620\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0209 - acc: 0.6805 - val_loss: 0.9843 - val_acc: 0.6952\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0093 - acc: 0.6862 - val_loss: 1.0686 - val_acc: 0.6638\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.0101 - acc: 0.6857 - val_loss: 0.9739 - val_acc: 0.6989\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.0075 - acc: 0.6861 - val_loss: 0.9899 - val_acc: 0.6946\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0080 - acc: 0.6878 - val_loss: 1.0014 - val_acc: 0.6913\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0107 - acc: 0.6852 - val_loss: 1.0051 - val_acc: 0.6876\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0133 - acc: 0.6821 - val_loss: 1.0165 - val_acc: 0.6839\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0023 - acc: 0.6889 - val_loss: 0.9863 - val_acc: 0.6931\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0083 - acc: 0.6878 - val_loss: 0.9998 - val_acc: 0.6890\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0092 - acc: 0.6862 - val_loss: 0.9811 - val_acc: 0.6973\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0127 - acc: 0.6836 - val_loss: 1.0062 - val_acc: 0.6899\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9985 - acc: 0.6901 - val_loss: 0.9626 - val_acc: 0.7035\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9983 - acc: 0.6881 - val_loss: 0.9701 - val_acc: 0.7008\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9938 - acc: 0.6915 - val_loss: 0.9868 - val_acc: 0.6932\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0051 - acc: 0.6875 - val_loss: 1.0199 - val_acc: 0.6880\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0072 - acc: 0.6864 - val_loss: 0.9687 - val_acc: 0.7041\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0078 - acc: 0.6880 - val_loss: 0.9660 - val_acc: 0.7028\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9940 - acc: 0.6921 - val_loss: 1.0037 - val_acc: 0.6911\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "print('NN model with relu activations and adam optimizer'); print('--'*40)\n",
    "# compiling the neural network classifier, adam optimizer\n",
    "adam = optimizers.Adam(lr = 0.01)\n",
    "model2.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the neural network for training\n",
    "history = model2.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "pAICaMQJKFE5",
    "outputId": "17b397c4-bf5e-44fc-ae73-4959635540eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate NN model with relu activations\n",
      "--------------------------------------------------------------------------------\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1.0037 - acc: 0.6911\n",
      "Validation accuracy: 69.11\n"
     ]
    }
   ],
   "source": [
    "print('Evaluate NN model with relu activations'); print('--'*40)\n",
    "results2 = model2.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: {}'.format(round(results2[1]*100, 2), '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT_j1efHRpGa"
   },
   "source": [
    "#### NN model, relu activations, adam optimizer, changing learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "j6CfiDwmRscX",
    "outputId": "66419ce6-9a33-4623-f0a3-e91822b6004a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 s, sys: 1e+03 ns, total: 3 s\n",
      "Wall time: 4.77 s\n",
      "NN model with relu activations and adam optimizer\n",
      "--------------------------------------------------------------------------------\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.9207 - acc: 0.7166 - val_loss: 0.9223 - val_acc: 0.7184\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9098 - acc: 0.7203 - val_loss: 0.9175 - val_acc: 0.7193\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9100 - acc: 0.7193 - val_loss: 0.9187 - val_acc: 0.7174\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9088 - acc: 0.7202 - val_loss: 0.9171 - val_acc: 0.7187\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9080 - acc: 0.7191 - val_loss: 0.9185 - val_acc: 0.7184\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9064 - acc: 0.7220 - val_loss: 0.9181 - val_acc: 0.7187\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.9074 - acc: 0.7217 - val_loss: 0.9131 - val_acc: 0.7214\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9038 - acc: 0.7233 - val_loss: 0.9160 - val_acc: 0.7208\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9038 - acc: 0.7221 - val_loss: 0.9150 - val_acc: 0.7202\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9043 - acc: 0.7222 - val_loss: 0.9147 - val_acc: 0.7218\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9017 - acc: 0.7234 - val_loss: 0.9187 - val_acc: 0.7187\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9026 - acc: 0.7225 - val_loss: 0.9187 - val_acc: 0.7187\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9057 - acc: 0.7221 - val_loss: 0.9153 - val_acc: 0.7211\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9016 - acc: 0.7229 - val_loss: 0.9116 - val_acc: 0.7207\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9031 - acc: 0.7222 - val_loss: 0.9213 - val_acc: 0.7177\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9001 - acc: 0.7229 - val_loss: 0.9053 - val_acc: 0.7233\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9013 - acc: 0.7225 - val_loss: 0.9189 - val_acc: 0.7166\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8989 - acc: 0.7245 - val_loss: 0.9059 - val_acc: 0.7229\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9003 - acc: 0.7237 - val_loss: 0.9150 - val_acc: 0.7199\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.9003 - acc: 0.7231 - val_loss: 0.9091 - val_acc: 0.7216\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8980 - acc: 0.7254 - val_loss: 0.9098 - val_acc: 0.7218\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8977 - acc: 0.7244 - val_loss: 0.9094 - val_acc: 0.7217\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8987 - acc: 0.7237 - val_loss: 0.9145 - val_acc: 0.7200\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8967 - acc: 0.7244 - val_loss: 0.9107 - val_acc: 0.7208\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8976 - acc: 0.7246 - val_loss: 0.9145 - val_acc: 0.7199\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8976 - acc: 0.7237 - val_loss: 0.9047 - val_acc: 0.7238\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8966 - acc: 0.7230 - val_loss: 0.9074 - val_acc: 0.7229\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8947 - acc: 0.7263 - val_loss: 0.9040 - val_acc: 0.7226\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8959 - acc: 0.7252 - val_loss: 0.9215 - val_acc: 0.7157\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8937 - acc: 0.7264 - val_loss: 0.9097 - val_acc: 0.7207\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8959 - acc: 0.7242 - val_loss: 0.9120 - val_acc: 0.7211\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8944 - acc: 0.7248 - val_loss: 0.9027 - val_acc: 0.7243\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8942 - acc: 0.7254 - val_loss: 0.9032 - val_acc: 0.7250\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8928 - acc: 0.7254 - val_loss: 0.9032 - val_acc: 0.7240\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8926 - acc: 0.7265 - val_loss: 0.9091 - val_acc: 0.7202\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8949 - acc: 0.7246 - val_loss: 0.9041 - val_acc: 0.7226\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.8940 - acc: 0.7237 - val_loss: 0.9028 - val_acc: 0.7241\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8925 - acc: 0.7257 - val_loss: 0.9063 - val_acc: 0.7229\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8917 - acc: 0.7259 - val_loss: 0.9024 - val_acc: 0.7245\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8943 - acc: 0.7253 - val_loss: 0.9051 - val_acc: 0.7239\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8918 - acc: 0.7263 - val_loss: 0.9123 - val_acc: 0.7199\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8918 - acc: 0.7262 - val_loss: 0.9091 - val_acc: 0.7220\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8912 - acc: 0.7266 - val_loss: 0.9088 - val_acc: 0.7209\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8900 - acc: 0.7281 - val_loss: 0.9084 - val_acc: 0.7224\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8904 - acc: 0.7269 - val_loss: 0.9066 - val_acc: 0.7211\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8903 - acc: 0.7260 - val_loss: 0.9017 - val_acc: 0.7251\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8908 - acc: 0.7267 - val_loss: 0.9037 - val_acc: 0.7225\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8892 - acc: 0.7248 - val_loss: 0.9043 - val_acc: 0.7222\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8892 - acc: 0.7263 - val_loss: 0.8993 - val_acc: 0.7247\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8902 - acc: 0.7260 - val_loss: 0.9123 - val_acc: 0.7200\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8890 - acc: 0.7261 - val_loss: 0.9017 - val_acc: 0.7247\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8873 - acc: 0.7271 - val_loss: 0.8991 - val_acc: 0.7254\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8879 - acc: 0.7272 - val_loss: 0.8996 - val_acc: 0.7247\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8880 - acc: 0.7273 - val_loss: 0.9110 - val_acc: 0.7222\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8882 - acc: 0.7275 - val_loss: 0.9008 - val_acc: 0.7245\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8879 - acc: 0.7273 - val_loss: 0.9052 - val_acc: 0.7240\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.8860 - acc: 0.7280 - val_loss: 0.9027 - val_acc: 0.7250\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8857 - acc: 0.7295 - val_loss: 0.8991 - val_acc: 0.7258\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8899 - acc: 0.7264 - val_loss: 0.9094 - val_acc: 0.7238\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.8868 - acc: 0.7277 - val_loss: 0.9053 - val_acc: 0.7228\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8864 - acc: 0.7288 - val_loss: 0.8992 - val_acc: 0.7254\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8879 - acc: 0.7276 - val_loss: 0.8937 - val_acc: 0.7282\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8860 - acc: 0.7279 - val_loss: 0.9124 - val_acc: 0.7200\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8867 - acc: 0.7286 - val_loss: 0.9027 - val_acc: 0.7235\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8852 - acc: 0.7286 - val_loss: 0.8949 - val_acc: 0.7265\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8861 - acc: 0.7287 - val_loss: 0.8954 - val_acc: 0.7266\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8840 - acc: 0.7283 - val_loss: 0.9055 - val_acc: 0.7222\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8838 - acc: 0.7285 - val_loss: 0.8979 - val_acc: 0.7258\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8849 - acc: 0.7277 - val_loss: 0.8946 - val_acc: 0.7275\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8830 - acc: 0.7291 - val_loss: 0.8960 - val_acc: 0.7247\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8848 - acc: 0.7285 - val_loss: 0.8995 - val_acc: 0.7262\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.8834 - acc: 0.7289 - val_loss: 0.9017 - val_acc: 0.7239\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8826 - acc: 0.7281 - val_loss: 0.8945 - val_acc: 0.7273\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8825 - acc: 0.7292 - val_loss: 0.8963 - val_acc: 0.7259\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8826 - acc: 0.7280 - val_loss: 0.8977 - val_acc: 0.7272\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8830 - acc: 0.7291 - val_loss: 0.8935 - val_acc: 0.7268\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8825 - acc: 0.7294 - val_loss: 0.8943 - val_acc: 0.7264\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8835 - acc: 0.7282 - val_loss: 0.8985 - val_acc: 0.7260\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8825 - acc: 0.7271 - val_loss: 0.8932 - val_acc: 0.7282\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8817 - acc: 0.7296 - val_loss: 0.8885 - val_acc: 0.7285\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8824 - acc: 0.7278 - val_loss: 0.8929 - val_acc: 0.7276\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8817 - acc: 0.7291 - val_loss: 0.8922 - val_acc: 0.7279\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8800 - acc: 0.7310 - val_loss: 0.9002 - val_acc: 0.7251\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8794 - acc: 0.7299 - val_loss: 0.8957 - val_acc: 0.7252\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8807 - acc: 0.7294 - val_loss: 0.8998 - val_acc: 0.7242\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8795 - acc: 0.7294 - val_loss: 0.8992 - val_acc: 0.7249\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8797 - acc: 0.7305 - val_loss: 0.8921 - val_acc: 0.7282\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.8812 - acc: 0.7295 - val_loss: 0.8967 - val_acc: 0.7238\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8798 - acc: 0.7304 - val_loss: 0.8901 - val_acc: 0.7291\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.8821 - acc: 0.7296 - val_loss: 0.8958 - val_acc: 0.7253\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8812 - acc: 0.7286 - val_loss: 0.8913 - val_acc: 0.7284\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8796 - acc: 0.7296 - val_loss: 0.8986 - val_acc: 0.7248\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8789 - acc: 0.7305 - val_loss: 0.8969 - val_acc: 0.7255\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8808 - acc: 0.7296 - val_loss: 0.8978 - val_acc: 0.7260\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8788 - acc: 0.7307 - val_loss: 0.8898 - val_acc: 0.7299\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8781 - acc: 0.7309 - val_loss: 0.8893 - val_acc: 0.7282\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8786 - acc: 0.7301 - val_loss: 0.8924 - val_acc: 0.7273\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8804 - acc: 0.7296 - val_loss: 0.8923 - val_acc: 0.7278\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8776 - acc: 0.7310 - val_loss: 0.8898 - val_acc: 0.7301\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8787 - acc: 0.7312 - val_loss: 0.9003 - val_acc: 0.7231\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "print('NN model with relu activations and adam optimizer'); print('--'*40)\n",
    "# compiling the neural network classifier, adam optimizer\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model2.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the neural network for training\n",
    "history = model2.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "sERp232wRvAN",
    "outputId": "4e9f4dd0-22bf-4f2a-fc71-d76816807e40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate NN model with relu activations\n",
      "--------------------------------------------------------------------------------\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.9003 - acc: 0.7231\n",
      "Validation accuracy: 72.31\n"
     ]
    }
   ],
   "source": [
    "print('Evaluate NN model with relu activations'); print('--'*40)\n",
    "results2 = model2.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: {}'.format(round(results2[1]*100, 2), '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HKt6irM6ownA"
   },
   "source": [
    "<a id='o4'></a>\n",
    "##### Observation 4 - NN model with relu activations\n",
    "* Improves the scores considerably.\n",
    "* Best accuracy achieved till now is using relu activations, SGD optimizer, changing learning rate to 0.001.\n",
    "* Next, let's try and change the number of activators and see if the score improves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "17b7kG5oR7J_"
   },
   "source": [
    "#### NN model, relu activations, changing number of activators, SGD optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "58Iskt9pKB3L",
    "outputId": "13040982-5c85-4d03-daf3-8729d8c3687a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN model with relu activations and changing number of activators\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('NN model with relu activations and changing number of activators'); print('--'*40)\n",
    "# Initialize the neural network classifier\n",
    "model3 = Sequential()\n",
    "\n",
    "# Input Layer - adding input layer and activation functions relu\n",
    "model3.add(Dense(256, input_shape = (1024, )))\n",
    "# Adding activation function\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "#Hidden Layer 1 - adding first hidden layer\n",
    "model3.add(Dense(128))\n",
    "# Adding activation function\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "#Hidden Layer 2 - Adding second hidden layer\n",
    "model3.add(Dense(64))\n",
    "# Adding activation function\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "# Output Layer - adding output layer which is of 10 nodes (digits)\n",
    "model3.add(Dense(10))\n",
    "# Adding activation function - softmax for multiclass classification\n",
    "model3.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "colab_type": "code",
    "id": "2q5A5rfawr08",
    "outputId": "a42e0e5e-d814-4ae9-b1a2-facd345a31e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 304,202\n",
      "Trainable params: 304,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WbApDf7hTG87",
    "outputId": "141ce0c1-6f66-4e22-f40a-6954dd4636f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 2.2970 - acc: 0.1352 - val_loss: 2.2856 - val_acc: 0.1681\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2796 - acc: 0.1758 - val_loss: 2.2716 - val_acc: 0.2027\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2635 - acc: 0.2046 - val_loss: 2.2535 - val_acc: 0.2214\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.2420 - acc: 0.2349 - val_loss: 2.2278 - val_acc: 0.2569\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.2120 - acc: 0.2681 - val_loss: 2.1917 - val_acc: 0.2880\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.1718 - acc: 0.2916 - val_loss: 2.1462 - val_acc: 0.3122\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.1214 - acc: 0.3206 - val_loss: 2.0898 - val_acc: 0.3460\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 2.0581 - acc: 0.3461 - val_loss: 2.0236 - val_acc: 0.3535\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.9848 - acc: 0.3783 - val_loss: 1.9432 - val_acc: 0.3811\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.9031 - acc: 0.4055 - val_loss: 1.8582 - val_acc: 0.4124\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.8185 - acc: 0.4314 - val_loss: 1.7743 - val_acc: 0.4404\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.7381 - acc: 0.4524 - val_loss: 1.6980 - val_acc: 0.4704\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.6675 - acc: 0.4743 - val_loss: 1.6228 - val_acc: 0.4852\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.5969 - acc: 0.4995 - val_loss: 1.5545 - val_acc: 0.5227\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.5448 - acc: 0.5187 - val_loss: 1.5015 - val_acc: 0.5362\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.4915 - acc: 0.5380 - val_loss: 1.4665 - val_acc: 0.5372\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.4440 - acc: 0.5557 - val_loss: 1.4270 - val_acc: 0.5549\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.3993 - acc: 0.5724 - val_loss: 1.3648 - val_acc: 0.5817\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.3595 - acc: 0.5881 - val_loss: 1.3138 - val_acc: 0.6082\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.3237 - acc: 0.5979 - val_loss: 1.2766 - val_acc: 0.6204\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.2891 - acc: 0.6102 - val_loss: 1.2549 - val_acc: 0.6227\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.2631 - acc: 0.6179 - val_loss: 1.2217 - val_acc: 0.6326\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.2333 - acc: 0.6262 - val_loss: 1.1897 - val_acc: 0.6449\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.2085 - acc: 0.6334 - val_loss: 1.2089 - val_acc: 0.6307\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.1796 - acc: 0.6431 - val_loss: 1.1399 - val_acc: 0.6573\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.1567 - acc: 0.6515 - val_loss: 1.1690 - val_acc: 0.6470\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.1386 - acc: 0.6560 - val_loss: 1.1205 - val_acc: 0.6615\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.1176 - acc: 0.6613 - val_loss: 1.1342 - val_acc: 0.6515\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0952 - acc: 0.6679 - val_loss: 1.0826 - val_acc: 0.6724\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0830 - acc: 0.6719 - val_loss: 1.0669 - val_acc: 0.6750\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.0597 - acc: 0.6795 - val_loss: 1.0353 - val_acc: 0.6884\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0421 - acc: 0.6851 - val_loss: 1.0258 - val_acc: 0.6925\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0331 - acc: 0.6867 - val_loss: 1.0104 - val_acc: 0.6980\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0165 - acc: 0.6934 - val_loss: 1.0069 - val_acc: 0.6970\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 1.0008 - acc: 0.6960 - val_loss: 0.9970 - val_acc: 0.6992\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9945 - acc: 0.6982 - val_loss: 0.9940 - val_acc: 0.6965\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9793 - acc: 0.7029 - val_loss: 0.9624 - val_acc: 0.7110\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9663 - acc: 0.7077 - val_loss: 1.0115 - val_acc: 0.6923\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.9564 - acc: 0.7122 - val_loss: 0.9731 - val_acc: 0.7039\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.9448 - acc: 0.7154 - val_loss: 0.9362 - val_acc: 0.7169\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9365 - acc: 0.7180 - val_loss: 0.9292 - val_acc: 0.7188\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9225 - acc: 0.7215 - val_loss: 0.8999 - val_acc: 0.7302\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9145 - acc: 0.7238 - val_loss: 0.9025 - val_acc: 0.7299\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9029 - acc: 0.7281 - val_loss: 1.0152 - val_acc: 0.6853\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.9000 - acc: 0.7281 - val_loss: 0.8805 - val_acc: 0.7349\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8898 - acc: 0.7289 - val_loss: 0.9236 - val_acc: 0.7178\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8760 - acc: 0.7355 - val_loss: 0.8661 - val_acc: 0.7407\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8694 - acc: 0.7385 - val_loss: 0.8628 - val_acc: 0.7422\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8612 - acc: 0.7381 - val_loss: 0.8997 - val_acc: 0.7266\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8591 - acc: 0.7398 - val_loss: 0.8416 - val_acc: 0.7478\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8462 - acc: 0.7453 - val_loss: 0.9037 - val_acc: 0.7258\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8391 - acc: 0.7459 - val_loss: 0.8628 - val_acc: 0.7382\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8393 - acc: 0.7460 - val_loss: 0.8461 - val_acc: 0.7462\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8288 - acc: 0.7493 - val_loss: 0.8156 - val_acc: 0.7549\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8158 - acc: 0.7539 - val_loss: 0.8001 - val_acc: 0.7626\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.8154 - acc: 0.7545 - val_loss: 0.8082 - val_acc: 0.7612\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.8053 - acc: 0.7569 - val_loss: 0.8299 - val_acc: 0.7492\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7994 - acc: 0.7599 - val_loss: 0.8095 - val_acc: 0.7570\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7924 - acc: 0.7619 - val_loss: 0.8090 - val_acc: 0.7562\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7901 - acc: 0.7609 - val_loss: 0.7917 - val_acc: 0.7615\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7827 - acc: 0.7656 - val_loss: 0.7713 - val_acc: 0.7694\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.7769 - acc: 0.7650 - val_loss: 0.7830 - val_acc: 0.7661\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7675 - acc: 0.7671 - val_loss: 0.7965 - val_acc: 0.7606\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7644 - acc: 0.7679 - val_loss: 0.7599 - val_acc: 0.7731\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7584 - acc: 0.7713 - val_loss: 0.7570 - val_acc: 0.7728\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7528 - acc: 0.7725 - val_loss: 0.7684 - val_acc: 0.7698\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7447 - acc: 0.7757 - val_loss: 0.7679 - val_acc: 0.7717\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7423 - acc: 0.7766 - val_loss: 0.7558 - val_acc: 0.7750\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7405 - acc: 0.7773 - val_loss: 0.7588 - val_acc: 0.7726\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7341 - acc: 0.7778 - val_loss: 0.7447 - val_acc: 0.7783\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7243 - acc: 0.7812 - val_loss: 0.7490 - val_acc: 0.7745\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.7239 - acc: 0.7818 - val_loss: 0.7168 - val_acc: 0.7861\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7154 - acc: 0.7850 - val_loss: 0.7268 - val_acc: 0.7806\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7103 - acc: 0.7860 - val_loss: 0.7208 - val_acc: 0.7813\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7072 - acc: 0.7857 - val_loss: 0.7144 - val_acc: 0.7858\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.7010 - acc: 0.7887 - val_loss: 0.7003 - val_acc: 0.7927\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7012 - acc: 0.7879 - val_loss: 0.7082 - val_acc: 0.7896\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6929 - acc: 0.7915 - val_loss: 0.6906 - val_acc: 0.7964\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6939 - acc: 0.7909 - val_loss: 0.6842 - val_acc: 0.7974\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6882 - acc: 0.7921 - val_loss: 0.7020 - val_acc: 0.7897\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6787 - acc: 0.7941 - val_loss: 0.7151 - val_acc: 0.7848\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6810 - acc: 0.7929 - val_loss: 0.6744 - val_acc: 0.7991\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6717 - acc: 0.7963 - val_loss: 0.6813 - val_acc: 0.7977\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6671 - acc: 0.7987 - val_loss: 0.7453 - val_acc: 0.7745\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6686 - acc: 0.8000 - val_loss: 0.6739 - val_acc: 0.7992\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6614 - acc: 0.8003 - val_loss: 0.6793 - val_acc: 0.7975\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6552 - acc: 0.8014 - val_loss: 0.6969 - val_acc: 0.7904\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6524 - acc: 0.8022 - val_loss: 0.6672 - val_acc: 0.8000\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6473 - acc: 0.8039 - val_loss: 0.6661 - val_acc: 0.7994\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6463 - acc: 0.8042 - val_loss: 0.6901 - val_acc: 0.7949\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6423 - acc: 0.8070 - val_loss: 0.6594 - val_acc: 0.8036\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6373 - acc: 0.8077 - val_loss: 0.7119 - val_acc: 0.7857\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6325 - acc: 0.8087 - val_loss: 0.7002 - val_acc: 0.7896\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6286 - acc: 0.8102 - val_loss: 0.6647 - val_acc: 0.8014\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6266 - acc: 0.8102 - val_loss: 0.6754 - val_acc: 0.7953\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6194 - acc: 0.8131 - val_loss: 0.6490 - val_acc: 0.8067\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6192 - acc: 0.8125 - val_loss: 0.6230 - val_acc: 0.8147\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6151 - acc: 0.8145 - val_loss: 0.6406 - val_acc: 0.8116\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6118 - acc: 0.8143 - val_loss: 0.6255 - val_acc: 0.8143\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6101 - acc: 0.8161 - val_loss: 0.6550 - val_acc: 0.8033\n"
     ]
    }
   ],
   "source": [
    "# compiling the neural network classifier, sgd optimizer\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model3.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the neural network for training\n",
    "history = model3.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "4nU-fCy5KbwM",
    "outputId": "efbd3096-803c-420b-a9cb-2403397384f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate NN model with relu activations and changing the number of activators\n",
      "--------------------------------------------------------------------------------\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.6550 - acc: 0.8033\n",
      "Validation accuracy: 80.33\n"
     ]
    }
   ],
   "source": [
    "print('Evaluate NN model with relu activations and changing the number of activators'); print('--'*40)\n",
    "results3 = model3.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: {}'.format(round(results3[1]*100, 2), '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCjOofsRTN1K"
   },
   "source": [
    "#### NN model, relu activations, changing number of activators, Adam optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DhnK4y6VTQAC",
    "outputId": "248d2cc8-22c1-482b-f193-44a2c5025f2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.9431 - acc: 0.7111 - val_loss: 0.7650 - val_acc: 0.7681\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7697 - acc: 0.7615 - val_loss: 0.8645 - val_acc: 0.7370\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7513 - acc: 0.7701 - val_loss: 0.7942 - val_acc: 0.7514\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7354 - acc: 0.7748 - val_loss: 0.7716 - val_acc: 0.7655\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7217 - acc: 0.7776 - val_loss: 0.7024 - val_acc: 0.7878\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6969 - acc: 0.7889 - val_loss: 0.7223 - val_acc: 0.7825\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6787 - acc: 0.7916 - val_loss: 0.6787 - val_acc: 0.7961\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6733 - acc: 0.7931 - val_loss: 0.6695 - val_acc: 0.7995\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6702 - acc: 0.7970 - val_loss: 0.6557 - val_acc: 0.7993\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6459 - acc: 0.8030 - val_loss: 0.6377 - val_acc: 0.8059\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6307 - acc: 0.8063 - val_loss: 0.6681 - val_acc: 0.7943\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6220 - acc: 0.8095 - val_loss: 0.6519 - val_acc: 0.7985\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6159 - acc: 0.8104 - val_loss: 0.5682 - val_acc: 0.8313\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5888 - acc: 0.8195 - val_loss: 0.6379 - val_acc: 0.8075\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5854 - acc: 0.8195 - val_loss: 0.6212 - val_acc: 0.8140\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.5868 - acc: 0.8183 - val_loss: 0.6059 - val_acc: 0.8149\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.5652 - acc: 0.8265 - val_loss: 0.6075 - val_acc: 0.8173\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5573 - acc: 0.8286 - val_loss: 0.5845 - val_acc: 0.8208\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5520 - acc: 0.8299 - val_loss: 0.6187 - val_acc: 0.8110\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.5610 - acc: 0.8274 - val_loss: 0.5504 - val_acc: 0.8365\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5195 - acc: 0.8405 - val_loss: 0.5797 - val_acc: 0.8260\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5315 - acc: 0.8363 - val_loss: 0.5837 - val_acc: 0.8220\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5184 - acc: 0.8403 - val_loss: 0.5482 - val_acc: 0.8365\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5084 - acc: 0.8423 - val_loss: 0.5310 - val_acc: 0.8398\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4920 - acc: 0.8479 - val_loss: 0.5043 - val_acc: 0.8500\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.4861 - acc: 0.8503 - val_loss: 0.5457 - val_acc: 0.8358\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4943 - acc: 0.8464 - val_loss: 0.5342 - val_acc: 0.8367\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4859 - acc: 0.8496 - val_loss: 0.4831 - val_acc: 0.8547\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4807 - acc: 0.8505 - val_loss: 0.5247 - val_acc: 0.8406\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4695 - acc: 0.8536 - val_loss: 0.5498 - val_acc: 0.8342\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4653 - acc: 0.8545 - val_loss: 0.5010 - val_acc: 0.8485\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4577 - acc: 0.8581 - val_loss: 0.4785 - val_acc: 0.8563\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4566 - acc: 0.8579 - val_loss: 0.5020 - val_acc: 0.8483\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4525 - acc: 0.8579 - val_loss: 0.5862 - val_acc: 0.8170\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4355 - acc: 0.8633 - val_loss: 0.4661 - val_acc: 0.8595\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4291 - acc: 0.8661 - val_loss: 0.5259 - val_acc: 0.8383\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4338 - acc: 0.8625 - val_loss: 0.6068 - val_acc: 0.8148\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4325 - acc: 0.8645 - val_loss: 0.4514 - val_acc: 0.8656\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4294 - acc: 0.8657 - val_loss: 0.4641 - val_acc: 0.8617\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4239 - acc: 0.8666 - val_loss: 0.5175 - val_acc: 0.8439\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4266 - acc: 0.8659 - val_loss: 0.5023 - val_acc: 0.8489\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4206 - acc: 0.8668 - val_loss: 0.4673 - val_acc: 0.8594\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.4083 - acc: 0.8699 - val_loss: 0.4995 - val_acc: 0.8479\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3917 - acc: 0.8773 - val_loss: 0.4362 - val_acc: 0.8698\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3893 - acc: 0.8769 - val_loss: 0.5263 - val_acc: 0.8397\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3958 - acc: 0.8752 - val_loss: 0.4380 - val_acc: 0.8702\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.3959 - acc: 0.8743 - val_loss: 0.4739 - val_acc: 0.8581\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3956 - acc: 0.8740 - val_loss: 0.4374 - val_acc: 0.8686\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3933 - acc: 0.8749 - val_loss: 0.4651 - val_acc: 0.8607\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3671 - acc: 0.8832 - val_loss: 0.4376 - val_acc: 0.8698\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3662 - acc: 0.8822 - val_loss: 0.4165 - val_acc: 0.8781\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3612 - acc: 0.8860 - val_loss: 0.4172 - val_acc: 0.8770\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.3767 - acc: 0.8793 - val_loss: 0.4456 - val_acc: 0.8668\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3575 - acc: 0.8863 - val_loss: 0.4409 - val_acc: 0.8695\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3584 - acc: 0.8840 - val_loss: 0.4215 - val_acc: 0.8756\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3558 - acc: 0.8864 - val_loss: 0.4387 - val_acc: 0.8690\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3602 - acc: 0.8850 - val_loss: 0.4316 - val_acc: 0.8732\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3350 - acc: 0.8931 - val_loss: 0.4214 - val_acc: 0.8757\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3381 - acc: 0.8934 - val_loss: 0.4294 - val_acc: 0.8722\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3374 - acc: 0.8938 - val_loss: 0.4462 - val_acc: 0.8694\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.3499 - acc: 0.8881 - val_loss: 0.4223 - val_acc: 0.8754\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3301 - acc: 0.8923 - val_loss: 0.4261 - val_acc: 0.8756\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3302 - acc: 0.8942 - val_loss: 0.4492 - val_acc: 0.8649\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.3206 - acc: 0.8978 - val_loss: 0.3936 - val_acc: 0.8864\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3162 - acc: 0.8980 - val_loss: 0.3932 - val_acc: 0.8864\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3092 - acc: 0.9009 - val_loss: 0.4013 - val_acc: 0.8825\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3158 - acc: 0.8982 - val_loss: 0.4132 - val_acc: 0.8783\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.3189 - acc: 0.8970 - val_loss: 0.3641 - val_acc: 0.8957\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3035 - acc: 0.9028 - val_loss: 0.4218 - val_acc: 0.8760\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3131 - acc: 0.8994 - val_loss: 0.4032 - val_acc: 0.8841\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3009 - acc: 0.9026 - val_loss: 0.4012 - val_acc: 0.8855\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2948 - acc: 0.9077 - val_loss: 0.3779 - val_acc: 0.8928\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2957 - acc: 0.9047 - val_loss: 0.4244 - val_acc: 0.8788\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2927 - acc: 0.9074 - val_loss: 0.4000 - val_acc: 0.8860\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2952 - acc: 0.9060 - val_loss: 0.4045 - val_acc: 0.8850\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.2872 - acc: 0.9078 - val_loss: 0.4378 - val_acc: 0.8738\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.3008 - acc: 0.9033 - val_loss: 0.3690 - val_acc: 0.8970\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2724 - acc: 0.9125 - val_loss: 0.3860 - val_acc: 0.8903\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.2974 - acc: 0.9023 - val_loss: 0.4051 - val_acc: 0.8840\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2782 - acc: 0.9085 - val_loss: 0.3634 - val_acc: 0.9003\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2770 - acc: 0.9094 - val_loss: 0.3970 - val_acc: 0.8867\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2813 - acc: 0.9098 - val_loss: 0.3967 - val_acc: 0.8843\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2933 - acc: 0.9037 - val_loss: 0.4170 - val_acc: 0.8803\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2803 - acc: 0.9088 - val_loss: 0.3711 - val_acc: 0.8977\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2688 - acc: 0.9134 - val_loss: 0.4142 - val_acc: 0.8851\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2594 - acc: 0.9154 - val_loss: 0.3891 - val_acc: 0.8889\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2721 - acc: 0.9106 - val_loss: 0.4202 - val_acc: 0.8810\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2624 - acc: 0.9143 - val_loss: 0.4145 - val_acc: 0.8846\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2672 - acc: 0.9133 - val_loss: 0.4157 - val_acc: 0.8844\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2453 - acc: 0.9196 - val_loss: 0.3752 - val_acc: 0.8970\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2564 - acc: 0.9160 - val_loss: 0.3450 - val_acc: 0.9084\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2401 - acc: 0.9220 - val_loss: 0.4096 - val_acc: 0.8861\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2460 - acc: 0.9199 - val_loss: 0.3834 - val_acc: 0.8932\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2424 - acc: 0.9212 - val_loss: 0.3874 - val_acc: 0.8963\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.2699 - acc: 0.9125 - val_loss: 0.3681 - val_acc: 0.9016\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2392 - acc: 0.9211 - val_loss: 0.4090 - val_acc: 0.8891\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2432 - acc: 0.9213 - val_loss: 0.3536 - val_acc: 0.9046\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.2430 - acc: 0.9205 - val_loss: 0.3895 - val_acc: 0.8961\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2386 - acc: 0.9211 - val_loss: 0.3641 - val_acc: 0.9031\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2458 - acc: 0.9195 - val_loss: 0.3539 - val_acc: 0.9066\n"
     ]
    }
   ],
   "source": [
    "# compiling the neural network classifier, adam optimizer\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model3.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the neural network for training\n",
    "history = model3.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "sHt5CH17TYgP",
    "outputId": "a1e0b820-8142-414c-c95f-4db5e98130f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate NN model with relu activations and changing the number of activators\n",
      "--------------------------------------------------------------------------------\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.3539 - acc: 0.9066\n",
      "Validation accuracy: 90.66\n"
     ]
    }
   ],
   "source": [
    "print('Evaluate NN model with relu activations and changing the number of activators'); print('--'*40)\n",
    "results3 = model3.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: {}'.format(round(results3[1]*100, 2), '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xMH4JH0Aw1Xz"
   },
   "source": [
    "<a id='o5'></a>\n",
    "##### Observation 5 - NN model with relu activations and changing activators\n",
    "* Adding relu activations and changing activators results in improvement of score.\n",
    "* Best accuracy achieved till now is using relu activations, changing number of activators and Adam optimizers with a learning rate of 0.001\n",
    "* Next, let's try adding weight initilization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kermiDSyKAPQ"
   },
   "source": [
    "<a id='Weight'></a>\n",
    "### With Weight Initializers\n",
    "Changing weight initialization scheme can significantly improve training of the model by preventing vanishing gradient problem up to some degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdMa80vmVAfU"
   },
   "source": [
    "#### NN model, relu activations, SGD optimizers with weight initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "jLn1T1HTE5ms",
    "outputId": "ffdb5aa0-c9ef-4033-8453-4f4e3ab775fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN model with weight initializers\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('NN model with weight initializers'); print('--'*40)\n",
    "# Initialize the neural network classifier\n",
    "model4 = Sequential()\n",
    "\n",
    "# Input Layer - adding input layer and activation functions relu and weight initializer\n",
    "model4.add(Dense(256, input_shape = (1024, ), kernel_initializer = 'he_normal'))\n",
    "# Adding activation function\n",
    "model4.add(Activation('relu'))\n",
    "\n",
    "#Hidden Layer 1 - adding first hidden layer\n",
    "model4.add(Dense(128, kernel_initializer = 'he_normal', bias_initializer = 'he_uniform'))\n",
    "# Adding activation function\n",
    "model4.add(Activation('relu'))\n",
    "\n",
    "#Hidden Layer 2 - adding second hidden layer\n",
    "model4.add(Dense(64, kernel_initializer = 'he_normal', bias_initializer = 'he_uniform'))\n",
    "# Adding activation function\n",
    "model4.add(Activation('relu'))\n",
    "\n",
    "#Hidden Layer 3 - adding third hidden layer\n",
    "model4.add(Dense(32, kernel_initializer = 'he_normal', bias_initializer = 'he_uniform'))\n",
    "# Adding activation function\n",
    "model4.add(Activation('relu'))\n",
    "\n",
    "# Output Layer - adding output layer which is of 10 nodes (digits)\n",
    "model4.add(Dense(10, kernel_initializer = 'he_normal', bias_initializer = 'he_uniform'))\n",
    "# Adding activation function\n",
    "model4.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "j4Ll9EKlU0Ep",
    "outputId": "918e5dc5-c837-4e54-9ad9-22ee8ec24f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 305,962\n",
      "Trainable params: 305,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "W8Np2U7LU2vN",
    "outputId": "e6bcfe8a-09e0-4d1f-e43b-3543a24cc155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.3023 - acc: 0.1175 - val_loss: 2.2772 - val_acc: 0.1445\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.2583 - acc: 0.1590 - val_loss: 2.2352 - val_acc: 0.1811\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.2025 - acc: 0.1988 - val_loss: 2.1630 - val_acc: 0.2169\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.1205 - acc: 0.2455 - val_loss: 2.0677 - val_acc: 0.2791\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 2.0151 - acc: 0.3002 - val_loss: 1.9792 - val_acc: 0.2936\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.9102 - acc: 0.3502 - val_loss: 1.8788 - val_acc: 0.3721\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 1.8119 - acc: 0.3987 - val_loss: 1.7286 - val_acc: 0.4290\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.7188 - acc: 0.4394 - val_loss: 1.6887 - val_acc: 0.4459\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.6454 - acc: 0.4664 - val_loss: 1.5630 - val_acc: 0.4977\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.5575 - acc: 0.5016 - val_loss: 1.4854 - val_acc: 0.5321\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.4950 - acc: 0.5230 - val_loss: 1.4138 - val_acc: 0.5634\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.4227 - acc: 0.5528 - val_loss: 1.3826 - val_acc: 0.5729\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.3695 - acc: 0.5711 - val_loss: 1.3418 - val_acc: 0.5759\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.3157 - acc: 0.5902 - val_loss: 1.2598 - val_acc: 0.6136\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.2658 - acc: 0.6087 - val_loss: 1.2570 - val_acc: 0.6051\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.2305 - acc: 0.6206 - val_loss: 1.1832 - val_acc: 0.6360\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.1781 - acc: 0.6407 - val_loss: 1.1872 - val_acc: 0.6325\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.1564 - acc: 0.6430 - val_loss: 1.1064 - val_acc: 0.6654\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.1314 - acc: 0.6545 - val_loss: 1.1058 - val_acc: 0.6610\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.1027 - acc: 0.6636 - val_loss: 1.0935 - val_acc: 0.6723\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.0788 - acc: 0.6717 - val_loss: 1.0264 - val_acc: 0.6935\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.0554 - acc: 0.6769 - val_loss: 1.0594 - val_acc: 0.6763\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.0394 - acc: 0.6810 - val_loss: 1.0024 - val_acc: 0.6969\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.0207 - acc: 0.6883 - val_loss: 1.0085 - val_acc: 0.6931\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 1.0036 - acc: 0.6933 - val_loss: 0.9629 - val_acc: 0.7112\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.9817 - acc: 0.7005 - val_loss: 0.9621 - val_acc: 0.7084\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.9767 - acc: 0.7021 - val_loss: 0.9664 - val_acc: 0.7089\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.9630 - acc: 0.7063 - val_loss: 0.9301 - val_acc: 0.7188\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.9437 - acc: 0.7120 - val_loss: 0.9326 - val_acc: 0.7169\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.9364 - acc: 0.7131 - val_loss: 0.9065 - val_acc: 0.7268\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.9258 - acc: 0.7177 - val_loss: 0.9086 - val_acc: 0.7228\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9093 - acc: 0.7233 - val_loss: 0.9859 - val_acc: 0.6932\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.8930 - acc: 0.7258 - val_loss: 0.8975 - val_acc: 0.7272\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.8898 - acc: 0.7287 - val_loss: 0.9300 - val_acc: 0.7106\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.8749 - acc: 0.7321 - val_loss: 0.8580 - val_acc: 0.7386\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.8671 - acc: 0.7364 - val_loss: 0.8540 - val_acc: 0.7415\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.8604 - acc: 0.7385 - val_loss: 0.8776 - val_acc: 0.7315\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.8520 - acc: 0.7388 - val_loss: 0.8911 - val_acc: 0.7285\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.8411 - acc: 0.7417 - val_loss: 0.8206 - val_acc: 0.7509\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.8298 - acc: 0.7486 - val_loss: 0.8165 - val_acc: 0.7536\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.8214 - acc: 0.7479 - val_loss: 0.8244 - val_acc: 0.7494\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.8155 - acc: 0.7504 - val_loss: 0.8274 - val_acc: 0.7457\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.8055 - acc: 0.7525 - val_loss: 0.7904 - val_acc: 0.7614\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7994 - acc: 0.7544 - val_loss: 0.8214 - val_acc: 0.7481\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.7903 - acc: 0.7585 - val_loss: 0.7907 - val_acc: 0.7623\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.7772 - acc: 0.7641 - val_loss: 0.7760 - val_acc: 0.7646\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7708 - acc: 0.7637 - val_loss: 0.7748 - val_acc: 0.7641\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7647 - acc: 0.7668 - val_loss: 0.7755 - val_acc: 0.7647\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7619 - acc: 0.7675 - val_loss: 0.8349 - val_acc: 0.7467\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7527 - acc: 0.7716 - val_loss: 0.8013 - val_acc: 0.7557\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7460 - acc: 0.7721 - val_loss: 0.8218 - val_acc: 0.7488\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7374 - acc: 0.7745 - val_loss: 0.7460 - val_acc: 0.7739\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.7298 - acc: 0.7764 - val_loss: 0.7361 - val_acc: 0.7758\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7241 - acc: 0.7789 - val_loss: 0.7359 - val_acc: 0.7771\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7231 - acc: 0.7796 - val_loss: 0.7706 - val_acc: 0.7632\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.7154 - acc: 0.7819 - val_loss: 0.6990 - val_acc: 0.7884\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.7089 - acc: 0.7844 - val_loss: 0.7225 - val_acc: 0.7826\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6965 - acc: 0.7884 - val_loss: 0.7235 - val_acc: 0.7802\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6945 - acc: 0.7878 - val_loss: 0.6968 - val_acc: 0.7902\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6934 - acc: 0.7889 - val_loss: 0.6906 - val_acc: 0.7930\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6812 - acc: 0.7935 - val_loss: 0.7031 - val_acc: 0.7886\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6734 - acc: 0.7948 - val_loss: 0.6841 - val_acc: 0.7936\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6704 - acc: 0.7957 - val_loss: 0.7160 - val_acc: 0.7796\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6639 - acc: 0.7963 - val_loss: 0.7002 - val_acc: 0.7873\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6635 - acc: 0.7970 - val_loss: 0.6885 - val_acc: 0.7896\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6577 - acc: 0.7989 - val_loss: 0.6442 - val_acc: 0.8066\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6460 - acc: 0.8025 - val_loss: 0.6553 - val_acc: 0.8033\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6456 - acc: 0.8022 - val_loss: 0.6597 - val_acc: 0.8029\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6428 - acc: 0.8029 - val_loss: 0.6701 - val_acc: 0.7975\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6438 - acc: 0.8018 - val_loss: 0.6699 - val_acc: 0.7985\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6290 - acc: 0.8080 - val_loss: 0.6421 - val_acc: 0.8052\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6306 - acc: 0.8080 - val_loss: 0.7013 - val_acc: 0.7821\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6264 - acc: 0.8086 - val_loss: 0.6395 - val_acc: 0.8061\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.6162 - acc: 0.8125 - val_loss: 0.6528 - val_acc: 0.8025\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6137 - acc: 0.8125 - val_loss: 0.6327 - val_acc: 0.8090\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6107 - acc: 0.8144 - val_loss: 0.6555 - val_acc: 0.8019\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6071 - acc: 0.8128 - val_loss: 0.6139 - val_acc: 0.8156\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6012 - acc: 0.8164 - val_loss: 0.6277 - val_acc: 0.8092\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.6028 - acc: 0.8175 - val_loss: 0.6266 - val_acc: 0.8112\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5946 - acc: 0.8199 - val_loss: 0.6035 - val_acc: 0.8183\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.5892 - acc: 0.8203 - val_loss: 0.6225 - val_acc: 0.8119\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5836 - acc: 0.8201 - val_loss: 0.6568 - val_acc: 0.8032\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5772 - acc: 0.8246 - val_loss: 0.6034 - val_acc: 0.8190\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5778 - acc: 0.8245 - val_loss: 0.6260 - val_acc: 0.8090\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5757 - acc: 0.8242 - val_loss: 0.5882 - val_acc: 0.8230\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5666 - acc: 0.8275 - val_loss: 0.6215 - val_acc: 0.8104\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5657 - acc: 0.8270 - val_loss: 0.5943 - val_acc: 0.8211\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5611 - acc: 0.8284 - val_loss: 0.5841 - val_acc: 0.8231\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5546 - acc: 0.8317 - val_loss: 0.5673 - val_acc: 0.8303\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5512 - acc: 0.8315 - val_loss: 0.5769 - val_acc: 0.8254\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5524 - acc: 0.8309 - val_loss: 0.5750 - val_acc: 0.8269\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5496 - acc: 0.8310 - val_loss: 0.5701 - val_acc: 0.8285\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5473 - acc: 0.8340 - val_loss: 0.5738 - val_acc: 0.8263\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5401 - acc: 0.8360 - val_loss: 0.5505 - val_acc: 0.8365\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5413 - acc: 0.8350 - val_loss: 0.6173 - val_acc: 0.8122\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 0.5368 - acc: 0.8359 - val_loss: 0.5707 - val_acc: 0.8304\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5295 - acc: 0.8385 - val_loss: 0.5667 - val_acc: 0.8296\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5249 - acc: 0.8381 - val_loss: 0.5843 - val_acc: 0.8244\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5273 - acc: 0.8393 - val_loss: 0.5687 - val_acc: 0.8294\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.5213 - acc: 0.8399 - val_loss: 0.5648 - val_acc: 0.8295\n"
     ]
    }
   ],
   "source": [
    "# compiling the neural network classifier, sgd optimizer\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "# Adding activation function - softmax for multiclass classification\n",
    "model4.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the neural network for training\n",
    "history = model4.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "xPbRGkQ7NKyW",
    "outputId": "c3f60776-2e5c-4e2f-ea1c-ad478024d792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN with weight initializers\n",
      "--------------------------------------------------------------------------------\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.5648 - acc: 0.8295\n",
      "Validation accuracy: 82.95\n"
     ]
    }
   ],
   "source": [
    "print('NN with weight initializers'); print('--'*40)\n",
    "results4 = model4.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: {}'.format(round(results4[1]*100, 2), '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSWZvLlSVgq5"
   },
   "source": [
    "#### NN model, relu activations, Adam optimizers with weight initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ysyBxxvgVjWk",
    "outputId": "450c0d00-c085-45d7-ed52-96360d18e32a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.8991 - acc: 0.7259 - val_loss: 0.7777 - val_acc: 0.7567\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7556 - acc: 0.7651 - val_loss: 0.7145 - val_acc: 0.7837\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7233 - acc: 0.7769 - val_loss: 0.7429 - val_acc: 0.7717\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.7134 - acc: 0.7808 - val_loss: 0.7203 - val_acc: 0.7836\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7006 - acc: 0.7834 - val_loss: 0.7579 - val_acc: 0.7643\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6854 - acc: 0.7876 - val_loss: 0.6947 - val_acc: 0.7862\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6375 - acc: 0.8048 - val_loss: 0.6920 - val_acc: 0.7847\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6482 - acc: 0.7993 - val_loss: 0.7172 - val_acc: 0.7798\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6429 - acc: 0.8015 - val_loss: 0.6664 - val_acc: 0.7970\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6220 - acc: 0.8086 - val_loss: 0.5867 - val_acc: 0.8212\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6078 - acc: 0.8123 - val_loss: 0.6032 - val_acc: 0.8152\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5877 - acc: 0.8190 - val_loss: 0.5871 - val_acc: 0.8198\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6041 - acc: 0.8137 - val_loss: 0.6405 - val_acc: 0.8071\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5615 - acc: 0.8272 - val_loss: 0.6205 - val_acc: 0.8112\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5613 - acc: 0.8273 - val_loss: 0.5388 - val_acc: 0.8364\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5540 - acc: 0.8296 - val_loss: 0.5700 - val_acc: 0.8283\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5484 - acc: 0.8299 - val_loss: 0.6048 - val_acc: 0.8130\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.5484 - acc: 0.8280 - val_loss: 0.5539 - val_acc: 0.8290\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.5517 - acc: 0.8289 - val_loss: 0.5933 - val_acc: 0.8200\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5333 - acc: 0.8333 - val_loss: 0.5172 - val_acc: 0.8419\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5145 - acc: 0.8397 - val_loss: 0.5776 - val_acc: 0.8227\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5038 - acc: 0.8428 - val_loss: 0.5885 - val_acc: 0.8203\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5021 - acc: 0.8435 - val_loss: 0.5563 - val_acc: 0.8313\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4995 - acc: 0.8436 - val_loss: 0.5187 - val_acc: 0.8443\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4902 - acc: 0.8461 - val_loss: 0.5196 - val_acc: 0.8422\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4710 - acc: 0.8533 - val_loss: 0.4911 - val_acc: 0.8530\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4936 - acc: 0.8451 - val_loss: 0.5424 - val_acc: 0.8342\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4797 - acc: 0.8485 - val_loss: 0.5177 - val_acc: 0.8429\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4690 - acc: 0.8533 - val_loss: 0.4953 - val_acc: 0.8504\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4609 - acc: 0.8557 - val_loss: 0.5042 - val_acc: 0.8469\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4545 - acc: 0.8564 - val_loss: 0.4685 - val_acc: 0.8587\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4528 - acc: 0.8584 - val_loss: 0.5315 - val_acc: 0.8411\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4509 - acc: 0.8584 - val_loss: 0.5534 - val_acc: 0.8298\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4374 - acc: 0.8635 - val_loss: 0.5036 - val_acc: 0.8473\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4344 - acc: 0.8632 - val_loss: 0.4816 - val_acc: 0.8529\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4361 - acc: 0.8620 - val_loss: 0.6043 - val_acc: 0.8112\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4331 - acc: 0.8619 - val_loss: 0.5036 - val_acc: 0.8474\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4255 - acc: 0.8643 - val_loss: 0.4520 - val_acc: 0.8638\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4218 - acc: 0.8663 - val_loss: 0.4762 - val_acc: 0.8538\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4104 - acc: 0.8693 - val_loss: 0.4917 - val_acc: 0.8511\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4133 - acc: 0.8700 - val_loss: 0.4658 - val_acc: 0.8579\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4138 - acc: 0.8682 - val_loss: 0.4311 - val_acc: 0.8703\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4022 - acc: 0.8722 - val_loss: 0.5085 - val_acc: 0.8441\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3980 - acc: 0.8724 - val_loss: 0.4468 - val_acc: 0.8643\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3898 - acc: 0.8754 - val_loss: 0.4190 - val_acc: 0.8749\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3825 - acc: 0.8784 - val_loss: 0.4479 - val_acc: 0.8654\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3758 - acc: 0.8804 - val_loss: 0.4472 - val_acc: 0.8663\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3744 - acc: 0.8803 - val_loss: 0.4578 - val_acc: 0.8621\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3732 - acc: 0.8777 - val_loss: 0.4057 - val_acc: 0.8789\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3702 - acc: 0.8817 - val_loss: 0.4784 - val_acc: 0.8530\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3802 - acc: 0.8784 - val_loss: 0.4168 - val_acc: 0.8766\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3640 - acc: 0.8855 - val_loss: 0.4354 - val_acc: 0.8693\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3655 - acc: 0.8817 - val_loss: 0.4408 - val_acc: 0.8706\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3629 - acc: 0.8839 - val_loss: 0.4955 - val_acc: 0.8507\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.3575 - acc: 0.8848 - val_loss: 0.4405 - val_acc: 0.8676\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3460 - acc: 0.8889 - val_loss: 0.4270 - val_acc: 0.8721\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3463 - acc: 0.8882 - val_loss: 0.4216 - val_acc: 0.8741\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3444 - acc: 0.8886 - val_loss: 0.4267 - val_acc: 0.8738\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3352 - acc: 0.8926 - val_loss: 0.4318 - val_acc: 0.8720\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3576 - acc: 0.8835 - val_loss: 0.4341 - val_acc: 0.8686\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3416 - acc: 0.8905 - val_loss: 0.4321 - val_acc: 0.8719\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3321 - acc: 0.8934 - val_loss: 0.4097 - val_acc: 0.8776\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3265 - acc: 0.8952 - val_loss: 0.3944 - val_acc: 0.8839\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3281 - acc: 0.8930 - val_loss: 0.4291 - val_acc: 0.8740\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3175 - acc: 0.8973 - val_loss: 0.4325 - val_acc: 0.8718\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3356 - acc: 0.8910 - val_loss: 0.3925 - val_acc: 0.8855\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3264 - acc: 0.8937 - val_loss: 0.4110 - val_acc: 0.8832\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3193 - acc: 0.8961 - val_loss: 0.4201 - val_acc: 0.8763\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3213 - acc: 0.8955 - val_loss: 0.4312 - val_acc: 0.8732\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3135 - acc: 0.8977 - val_loss: 0.4648 - val_acc: 0.8613\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3129 - acc: 0.8984 - val_loss: 0.3997 - val_acc: 0.8838\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3039 - acc: 0.9007 - val_loss: 0.4164 - val_acc: 0.8781\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3088 - acc: 0.9005 - val_loss: 0.4063 - val_acc: 0.8815\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3041 - acc: 0.9022 - val_loss: 0.3704 - val_acc: 0.8949\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2971 - acc: 0.9039 - val_loss: 0.4283 - val_acc: 0.8779\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3031 - acc: 0.9018 - val_loss: 0.4305 - val_acc: 0.8752\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2963 - acc: 0.9041 - val_loss: 0.4077 - val_acc: 0.8816\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2873 - acc: 0.9086 - val_loss: 0.4098 - val_acc: 0.8811\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2926 - acc: 0.9044 - val_loss: 0.3991 - val_acc: 0.8887\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2840 - acc: 0.9085 - val_loss: 0.3795 - val_acc: 0.8923\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.2877 - acc: 0.9056 - val_loss: 0.4328 - val_acc: 0.8731\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2810 - acc: 0.9073 - val_loss: 0.3815 - val_acc: 0.8924\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2881 - acc: 0.9066 - val_loss: 0.4516 - val_acc: 0.8707\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2902 - acc: 0.9050 - val_loss: 0.3960 - val_acc: 0.8873\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2647 - acc: 0.9148 - val_loss: 0.3972 - val_acc: 0.8877\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2760 - acc: 0.9100 - val_loss: 0.3952 - val_acc: 0.8874\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2739 - acc: 0.9095 - val_loss: 0.4250 - val_acc: 0.8813\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2745 - acc: 0.9099 - val_loss: 0.4271 - val_acc: 0.8791\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2576 - acc: 0.9163 - val_loss: 0.4173 - val_acc: 0.8834\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2657 - acc: 0.9130 - val_loss: 0.3729 - val_acc: 0.8973\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2493 - acc: 0.9177 - val_loss: 0.3755 - val_acc: 0.8954\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2611 - acc: 0.9147 - val_loss: 0.3596 - val_acc: 0.9012\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2543 - acc: 0.9182 - val_loss: 0.3893 - val_acc: 0.8908\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2478 - acc: 0.9176 - val_loss: 0.4036 - val_acc: 0.8882\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2613 - acc: 0.9129 - val_loss: 0.4178 - val_acc: 0.8851\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2535 - acc: 0.9170 - val_loss: 0.3966 - val_acc: 0.8928\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2520 - acc: 0.9163 - val_loss: 0.3765 - val_acc: 0.8971\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2548 - acc: 0.9166 - val_loss: 0.4093 - val_acc: 0.8857\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2535 - acc: 0.9170 - val_loss: 0.4349 - val_acc: 0.8797\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2450 - acc: 0.9200 - val_loss: 0.4037 - val_acc: 0.8873\n"
     ]
    }
   ],
   "source": [
    "# compiling the neural network classifier, adam optimizer\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "# Adding activation function - softmax for multiclass classification\n",
    "model4.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the neural network for training\n",
    "history = model4.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "95vBMvCvVrg0",
    "outputId": "328825e1-3e71-4e25-8e71-3e58733cef83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN with weight initializers\n",
      "--------------------------------------------------------------------------------\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.4037 - acc: 0.8873\n",
      "Validation accuracy: 88.73\n"
     ]
    }
   ],
   "source": [
    "print('NN with weight initializers'); print('--'*40)\n",
    "results4 = model4.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: {}'.format(round(results4[1]*100, 2), '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gjy8FCIQz_s4"
   },
   "source": [
    "<a id='o6'></a>\n",
    "##### Observation 6 - Weight initializers\n",
    "* Adding weight initialiers didn't result in improvement of score.\n",
    "* relu activations, changing number of activators, Adam optimizers gives the best score out of the ones tried as of now.\n",
    "* Next, let's try batch normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nlLYOhj_TNcf"
   },
   "source": [
    "<a id='Batch'></a>\n",
    "### Batch Normalization\n",
    "Batch Normalization, one of the methods to prevent the \"internal covariance shift\" problem, has proven to be highly effective. Normalize each mini-batch before nonlinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8QVHk2dWbgK"
   },
   "source": [
    "#### NN model, relu activations, SGD optimizers with weight initializers and batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "BCATllTeUghF",
    "outputId": "61ca8e1f-aac8-4a3d-f81c-5a9656f7de71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN model with batch normalization\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('NN model with batch normalization'); print('--'*40)\n",
    "# Initialize the neural network classifier\n",
    "model5 = Sequential()\n",
    "\n",
    "# Input Layer - adding input layer and activation functions relu and weight initializer\n",
    "model5.add(Dense(256, input_shape = (1024, ), kernel_initializer = 'he_normal'))\n",
    "# Adding batch normalization\n",
    "model5.add(BatchNormalization())\n",
    "# Adding activation function\n",
    "model5.add(Activation('relu'))\n",
    "\n",
    "#Hidden Layer 1 - adding first hidden layer\n",
    "model5.add(Dense(128, kernel_initializer = 'he_normal', bias_initializer = 'he_uniform'))\n",
    "# Adding batch normalization\n",
    "model5.add(BatchNormalization())\n",
    "# Adding activation function\n",
    "model5.add(Activation('relu'))\n",
    "\n",
    "#Hidden Layer 2 - adding second hidden layer\n",
    "model5.add(Dense(64, kernel_initializer = 'he_normal', bias_initializer = 'he_uniform'))\n",
    "# Adding batch normalization\n",
    "model5.add(BatchNormalization())\n",
    "# Adding activation function\n",
    "model5.add(Activation('relu'))\n",
    "\n",
    "#Hidden Layer 3 - adding third hidden layer\n",
    "model5.add(Dense(32, kernel_initializer = 'he_normal', bias_initializer = 'he_uniform'))\n",
    "# Adding batch normalization\n",
    "model5.add(BatchNormalization())\n",
    "# Adding activation function\n",
    "model5.add(Activation('relu'))\n",
    "\n",
    "# Output Layer - adding output layer which is of 10 nodes (digits)\n",
    "model5.add(Dense(10, kernel_initializer = 'he_normal', bias_initializer = 'he_uniform'))\n",
    "# Adding activation function\n",
    "model5.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "colab_type": "code",
    "id": "3Yz93UDo557M",
    "outputId": "b1f09216-291e-4c56-b0b2-466f3ab28aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 307,882\n",
      "Trainable params: 306,922\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lvXUI89PWUcr",
    "outputId": "767307aa-ba57-45b3-c51b-91583fa5592c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 2.3150 - acc: 0.1844 - val_loss: 2.2163 - val_acc: 0.1867\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 1.8823 - acc: 0.3717 - val_loss: 1.8685 - val_acc: 0.3833\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 1.6338 - acc: 0.4850 - val_loss: 1.6083 - val_acc: 0.4873\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 1.4471 - acc: 0.5612 - val_loss: 1.4532 - val_acc: 0.5435\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 1.3017 - acc: 0.6110 - val_loss: 1.2819 - val_acc: 0.6060\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 1.1888 - acc: 0.6459 - val_loss: 1.2110 - val_acc: 0.6357\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 1.0931 - acc: 0.6720 - val_loss: 1.1470 - val_acc: 0.6414\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 1.0188 - acc: 0.6929 - val_loss: 1.0641 - val_acc: 0.6710\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.9576 - acc: 0.7099 - val_loss: 1.0080 - val_acc: 0.6921\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.9052 - acc: 0.7238 - val_loss: 0.9584 - val_acc: 0.7056\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.8609 - acc: 0.7344 - val_loss: 0.9839 - val_acc: 0.6924\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.8205 - acc: 0.7494 - val_loss: 0.9355 - val_acc: 0.7078\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.7844 - acc: 0.7591 - val_loss: 0.8979 - val_acc: 0.7123\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.7555 - acc: 0.7667 - val_loss: 0.9690 - val_acc: 0.6953\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.7297 - acc: 0.7736 - val_loss: 0.8284 - val_acc: 0.7423\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.7034 - acc: 0.7813 - val_loss: 0.9007 - val_acc: 0.7136\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.6805 - acc: 0.7895 - val_loss: 0.9803 - val_acc: 0.6925\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.6578 - acc: 0.7969 - val_loss: 0.7991 - val_acc: 0.7457\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.6425 - acc: 0.8005 - val_loss: 0.8517 - val_acc: 0.7338\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.6255 - acc: 0.8049 - val_loss: 0.8117 - val_acc: 0.7400\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.6085 - acc: 0.8114 - val_loss: 0.8065 - val_acc: 0.7500\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.5910 - acc: 0.8164 - val_loss: 0.7252 - val_acc: 0.7730\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.5801 - acc: 0.8195 - val_loss: 0.8067 - val_acc: 0.7415\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.5632 - acc: 0.8253 - val_loss: 0.8137 - val_acc: 0.7422\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.5505 - acc: 0.8272 - val_loss: 0.6932 - val_acc: 0.7826\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.5378 - acc: 0.8322 - val_loss: 0.9460 - val_acc: 0.7073\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.5254 - acc: 0.8360 - val_loss: 0.6978 - val_acc: 0.7786\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.5168 - acc: 0.8379 - val_loss: 0.8921 - val_acc: 0.7368\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.5062 - acc: 0.8424 - val_loss: 0.7901 - val_acc: 0.7526\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.4920 - acc: 0.8462 - val_loss: 0.6657 - val_acc: 0.7909\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.4873 - acc: 0.8475 - val_loss: 0.9750 - val_acc: 0.7089\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.4793 - acc: 0.8509 - val_loss: 0.7757 - val_acc: 0.7625\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.4699 - acc: 0.8526 - val_loss: 0.7678 - val_acc: 0.7598\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.4629 - acc: 0.8545 - val_loss: 0.7930 - val_acc: 0.7597\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.4515 - acc: 0.8596 - val_loss: 0.6978 - val_acc: 0.7844\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.4392 - acc: 0.8636 - val_loss: 0.6710 - val_acc: 0.7926\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.4332 - acc: 0.8650 - val_loss: 0.7249 - val_acc: 0.7742\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.4249 - acc: 0.8675 - val_loss: 0.6876 - val_acc: 0.7842\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.4179 - acc: 0.8695 - val_loss: 0.6177 - val_acc: 0.8071\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.4102 - acc: 0.8732 - val_loss: 1.1939 - val_acc: 0.6915\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.4061 - acc: 0.8729 - val_loss: 0.7878 - val_acc: 0.7606\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.4005 - acc: 0.8746 - val_loss: 0.6239 - val_acc: 0.8039\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.3936 - acc: 0.8773 - val_loss: 0.6273 - val_acc: 0.8059\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.3872 - acc: 0.8802 - val_loss: 0.5841 - val_acc: 0.8211\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.3789 - acc: 0.8835 - val_loss: 0.5863 - val_acc: 0.8203\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.3709 - acc: 0.8839 - val_loss: 0.6137 - val_acc: 0.8091\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.3669 - acc: 0.8873 - val_loss: 0.6152 - val_acc: 0.8077\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.3640 - acc: 0.8870 - val_loss: 0.6704 - val_acc: 0.7876\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.3575 - acc: 0.8888 - val_loss: 0.6125 - val_acc: 0.8124\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.3488 - acc: 0.8913 - val_loss: 0.7482 - val_acc: 0.7721\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.3417 - acc: 0.8925 - val_loss: 0.6436 - val_acc: 0.8008\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.3388 - acc: 0.8943 - val_loss: 0.6630 - val_acc: 0.8002\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.3363 - acc: 0.8953 - val_loss: 1.0303 - val_acc: 0.7077\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.3302 - acc: 0.8977 - val_loss: 0.6981 - val_acc: 0.7801\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.3246 - acc: 0.8993 - val_loss: 0.7736 - val_acc: 0.7778\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.3225 - acc: 0.9000 - val_loss: 0.9034 - val_acc: 0.7348\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.3214 - acc: 0.9002 - val_loss: 0.9498 - val_acc: 0.7229\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.3085 - acc: 0.9051 - val_loss: 0.5623 - val_acc: 0.8292\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.3056 - acc: 0.9064 - val_loss: 0.9083 - val_acc: 0.7462\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.3017 - acc: 0.9069 - val_loss: 0.6753 - val_acc: 0.7982\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.2960 - acc: 0.9097 - val_loss: 0.8200 - val_acc: 0.7688\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.2921 - acc: 0.9085 - val_loss: 0.7007 - val_acc: 0.7875\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.2870 - acc: 0.9111 - val_loss: 0.5730 - val_acc: 0.8280\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.2868 - acc: 0.9124 - val_loss: 0.6654 - val_acc: 0.8033\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.2802 - acc: 0.9140 - val_loss: 0.9222 - val_acc: 0.7542\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.2723 - acc: 0.9172 - val_loss: 0.7212 - val_acc: 0.7878\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.2724 - acc: 0.9156 - val_loss: 0.5668 - val_acc: 0.8287\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.2662 - acc: 0.9178 - val_loss: 0.6644 - val_acc: 0.8062\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.2692 - acc: 0.9163 - val_loss: 0.5836 - val_acc: 0.8216\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.2586 - acc: 0.9201 - val_loss: 0.6806 - val_acc: 0.7996\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.2588 - acc: 0.9211 - val_loss: 0.6559 - val_acc: 0.8069\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.2556 - acc: 0.9227 - val_loss: 0.6227 - val_acc: 0.8114\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.2572 - acc: 0.9206 - val_loss: 0.5525 - val_acc: 0.8367\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.2480 - acc: 0.9237 - val_loss: 1.9892 - val_acc: 0.6235\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.2453 - acc: 0.9242 - val_loss: 0.9709 - val_acc: 0.7505\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.2417 - acc: 0.9260 - val_loss: 0.5700 - val_acc: 0.8296\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.2377 - acc: 0.9266 - val_loss: 0.5419 - val_acc: 0.8381\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.2350 - acc: 0.9288 - val_loss: 0.7219 - val_acc: 0.7956\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.2356 - acc: 0.9276 - val_loss: 0.6147 - val_acc: 0.8211\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.2337 - acc: 0.9287 - val_loss: 0.6259 - val_acc: 0.8096\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.2274 - acc: 0.9311 - val_loss: 0.5695 - val_acc: 0.8381\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.2224 - acc: 0.9329 - val_loss: 0.5421 - val_acc: 0.8424\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.2269 - acc: 0.9294 - val_loss: 0.8632 - val_acc: 0.7679\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.2149 - acc: 0.9343 - val_loss: 0.6775 - val_acc: 0.8163\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.2183 - acc: 0.9321 - val_loss: 0.6102 - val_acc: 0.8263\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.2136 - acc: 0.9340 - val_loss: 0.6119 - val_acc: 0.8273\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.2130 - acc: 0.9346 - val_loss: 0.9060 - val_acc: 0.7550\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.2108 - acc: 0.9350 - val_loss: 0.7187 - val_acc: 0.8004\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.2061 - acc: 0.9364 - val_loss: 0.6345 - val_acc: 0.8180\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.2057 - acc: 0.9381 - val_loss: 0.4849 - val_acc: 0.8626\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.1968 - acc: 0.9413 - val_loss: 0.6472 - val_acc: 0.8304\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.1917 - acc: 0.9424 - val_loss: 0.6683 - val_acc: 0.8133\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.1934 - acc: 0.9407 - val_loss: 0.7798 - val_acc: 0.7920\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.1913 - acc: 0.9417 - val_loss: 0.7867 - val_acc: 0.7778\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.1907 - acc: 0.9420 - val_loss: 0.6375 - val_acc: 0.8199\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.1893 - acc: 0.9419 - val_loss: 0.6015 - val_acc: 0.8279\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.1853 - acc: 0.9440 - val_loss: 0.5841 - val_acc: 0.8378\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.1819 - acc: 0.9442 - val_loss: 0.7618 - val_acc: 0.8002\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 2s 46us/sample - loss: 0.1804 - acc: 0.9435 - val_loss: 0.7315 - val_acc: 0.8016\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.1793 - acc: 0.9457 - val_loss: 0.7381 - val_acc: 0.8078\n"
     ]
    }
   ],
   "source": [
    "# compiling the neural network classifier, sgd optimizer\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "# Adding activation function - softmax for multiclass classification\n",
    "model5.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the neural network for training\n",
    "history = model5.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "8jMKdIGlU0eG",
    "outputId": "6680e992-5559-4379-de7c-2b80fa37a638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN with batch normalization\n",
      "--------------------------------------------------------------------------------\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.7381 - acc: 0.8078\n",
      "Validation accuracy: 80.78\n"
     ]
    }
   ],
   "source": [
    "print('NN with batch normalization'); print('--'*40)\n",
    "results5 = model5.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: {}'.format(round(results5[1]*100, 2), '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvExZp5EXHFf"
   },
   "source": [
    "#### NN model, relu activations, Adam optimizers with weight initializers and batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rws18ePgW5HZ",
    "outputId": "1761ca54-9f96-43db-9705-dd67994d8d5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.7504 - acc: 0.7711 - val_loss: 3.2994 - val_acc: 0.3926\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.5840 - acc: 0.8120 - val_loss: 1.2989 - val_acc: 0.5782\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.5254 - acc: 0.8286 - val_loss: 1.5073 - val_acc: 0.5588\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.4785 - acc: 0.8432 - val_loss: 1.4805 - val_acc: 0.5900\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.4628 - acc: 0.8490 - val_loss: 1.5200 - val_acc: 0.5520\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.4416 - acc: 0.8556 - val_loss: 1.1569 - val_acc: 0.6578\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.4216 - acc: 0.8632 - val_loss: 1.1616 - val_acc: 0.6521\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.3979 - acc: 0.8718 - val_loss: 1.0359 - val_acc: 0.6737\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.3967 - acc: 0.8716 - val_loss: 1.4157 - val_acc: 0.6081\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.3868 - acc: 0.8749 - val_loss: 1.1907 - val_acc: 0.6233\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.3657 - acc: 0.8803 - val_loss: 1.0921 - val_acc: 0.6475\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.3518 - acc: 0.8872 - val_loss: 1.0731 - val_acc: 0.6741\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.3442 - acc: 0.8874 - val_loss: 1.1014 - val_acc: 0.6781\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.3349 - acc: 0.8899 - val_loss: 1.2347 - val_acc: 0.6433\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.3198 - acc: 0.8963 - val_loss: 1.0597 - val_acc: 0.6864\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.3151 - acc: 0.8965 - val_loss: 1.3385 - val_acc: 0.6374\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.3006 - acc: 0.9024 - val_loss: 1.2399 - val_acc: 0.6477\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.2937 - acc: 0.9026 - val_loss: 1.7937 - val_acc: 0.6011\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.2807 - acc: 0.9075 - val_loss: 0.8963 - val_acc: 0.7358\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.2783 - acc: 0.9098 - val_loss: 0.9110 - val_acc: 0.7418\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.2730 - acc: 0.9120 - val_loss: 0.9502 - val_acc: 0.7330\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.2706 - acc: 0.9109 - val_loss: 0.9985 - val_acc: 0.7336\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.2596 - acc: 0.9153 - val_loss: 1.4751 - val_acc: 0.6206\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.2459 - acc: 0.9192 - val_loss: 1.0131 - val_acc: 0.7315\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.2410 - acc: 0.9215 - val_loss: 1.3443 - val_acc: 0.6587\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.2471 - acc: 0.9187 - val_loss: 1.0037 - val_acc: 0.7185\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.2468 - acc: 0.9188 - val_loss: 0.8069 - val_acc: 0.7687\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.2256 - acc: 0.9253 - val_loss: 0.7956 - val_acc: 0.7738\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.2232 - acc: 0.9268 - val_loss: 0.9224 - val_acc: 0.7399\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.2189 - acc: 0.9274 - val_loss: 0.8176 - val_acc: 0.7669\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 2s 53us/sample - loss: 0.2169 - acc: 0.9281 - val_loss: 0.8483 - val_acc: 0.7552\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.2185 - acc: 0.9276 - val_loss: 0.9837 - val_acc: 0.7370\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.2079 - acc: 0.9323 - val_loss: 0.8542 - val_acc: 0.7669\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.2026 - acc: 0.9330 - val_loss: 0.9887 - val_acc: 0.7467\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.1968 - acc: 0.9350 - val_loss: 1.0074 - val_acc: 0.7355\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.1947 - acc: 0.9348 - val_loss: 0.8603 - val_acc: 0.7645\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.1904 - acc: 0.9379 - val_loss: 0.7189 - val_acc: 0.7949\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.1789 - acc: 0.9404 - val_loss: 0.9522 - val_acc: 0.7534\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.1776 - acc: 0.9414 - val_loss: 0.7963 - val_acc: 0.8006\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.1767 - acc: 0.9409 - val_loss: 0.9288 - val_acc: 0.7571\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.1766 - acc: 0.9411 - val_loss: 1.1659 - val_acc: 0.7217\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.1626 - acc: 0.9458 - val_loss: 0.9868 - val_acc: 0.7480\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.1718 - acc: 0.9429 - val_loss: 0.7413 - val_acc: 0.7992\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.1626 - acc: 0.9460 - val_loss: 1.3095 - val_acc: 0.6971\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.1561 - acc: 0.9485 - val_loss: 0.8414 - val_acc: 0.7886\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.1580 - acc: 0.9470 - val_loss: 0.7729 - val_acc: 0.8021\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.1604 - acc: 0.9472 - val_loss: 1.3858 - val_acc: 0.7020\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.1538 - acc: 0.9488 - val_loss: 1.4758 - val_acc: 0.6984\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.1425 - acc: 0.9529 - val_loss: 1.3721 - val_acc: 0.7090\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.1504 - acc: 0.9494 - val_loss: 1.0456 - val_acc: 0.7430\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.1506 - acc: 0.9496 - val_loss: 1.0405 - val_acc: 0.7593\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.1414 - acc: 0.9524 - val_loss: 0.8466 - val_acc: 0.7840\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.1373 - acc: 0.9538 - val_loss: 0.9790 - val_acc: 0.7692\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.1469 - acc: 0.9508 - val_loss: 0.6021 - val_acc: 0.8406\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.1327 - acc: 0.9560 - val_loss: 1.0881 - val_acc: 0.7641\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.1317 - acc: 0.9556 - val_loss: 1.0091 - val_acc: 0.7638\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.1291 - acc: 0.9558 - val_loss: 1.0545 - val_acc: 0.7565\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.1291 - acc: 0.9569 - val_loss: 0.6812 - val_acc: 0.8264\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.1252 - acc: 0.9581 - val_loss: 0.8298 - val_acc: 0.8017\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.1217 - acc: 0.9590 - val_loss: 1.1110 - val_acc: 0.7636\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.1219 - acc: 0.9591 - val_loss: 0.8744 - val_acc: 0.7934\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.1249 - acc: 0.9574 - val_loss: 1.2907 - val_acc: 0.7352\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 0.1188 - acc: 0.9600 - val_loss: 0.9428 - val_acc: 0.7811\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.1189 - acc: 0.9592 - val_loss: 1.0607 - val_acc: 0.7717\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.1173 - acc: 0.9614 - val_loss: 0.8250 - val_acc: 0.8036\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.1102 - acc: 0.9630 - val_loss: 0.8915 - val_acc: 0.7794\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.1150 - acc: 0.9620 - val_loss: 0.8700 - val_acc: 0.7963\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.1051 - acc: 0.9645 - val_loss: 0.8872 - val_acc: 0.7971\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.1120 - acc: 0.9622 - val_loss: 1.2268 - val_acc: 0.7523\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.1117 - acc: 0.9622 - val_loss: 0.8054 - val_acc: 0.8112\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 2s 53us/sample - loss: 0.1154 - acc: 0.9614 - val_loss: 0.8851 - val_acc: 0.7975\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.1071 - acc: 0.9640 - val_loss: 1.2763 - val_acc: 0.7354\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 2s 53us/sample - loss: 0.1113 - acc: 0.9617 - val_loss: 1.0526 - val_acc: 0.7878\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.0973 - acc: 0.9672 - val_loss: 0.9450 - val_acc: 0.7733\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.1012 - acc: 0.9657 - val_loss: 1.3132 - val_acc: 0.7354\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.1073 - acc: 0.9642 - val_loss: 1.2652 - val_acc: 0.7547\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.0974 - acc: 0.9671 - val_loss: 0.6400 - val_acc: 0.8382\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.0929 - acc: 0.9692 - val_loss: 1.3082 - val_acc: 0.7578\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.0951 - acc: 0.9686 - val_loss: 0.6770 - val_acc: 0.8472\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.0961 - acc: 0.9680 - val_loss: 0.8655 - val_acc: 0.8092\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.0991 - acc: 0.9665 - val_loss: 0.8122 - val_acc: 0.8212\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.0931 - acc: 0.9688 - val_loss: 0.7419 - val_acc: 0.8227\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.0910 - acc: 0.9695 - val_loss: 1.1053 - val_acc: 0.7612\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.1015 - acc: 0.9658 - val_loss: 0.8460 - val_acc: 0.8165\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.0871 - acc: 0.9707 - val_loss: 0.8258 - val_acc: 0.8185\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.0931 - acc: 0.9679 - val_loss: 0.7424 - val_acc: 0.8282\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.0896 - acc: 0.9692 - val_loss: 1.8734 - val_acc: 0.7012\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 2s 48us/sample - loss: 0.0949 - acc: 0.9678 - val_loss: 0.9185 - val_acc: 0.7866\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.0945 - acc: 0.9676 - val_loss: 1.1041 - val_acc: 0.7891\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.0850 - acc: 0.9713 - val_loss: 1.0702 - val_acc: 0.7694\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.0888 - acc: 0.9695 - val_loss: 0.8052 - val_acc: 0.8224\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.0860 - acc: 0.9713 - val_loss: 0.7990 - val_acc: 0.8161\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.0729 - acc: 0.9757 - val_loss: 1.1168 - val_acc: 0.7737\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.0783 - acc: 0.9731 - val_loss: 0.7263 - val_acc: 0.8390\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.0854 - acc: 0.9707 - val_loss: 0.6956 - val_acc: 0.8449\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.0763 - acc: 0.9735 - val_loss: 1.0002 - val_acc: 0.8003\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 2s 50us/sample - loss: 0.0863 - acc: 0.9700 - val_loss: 0.9083 - val_acc: 0.8045\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 2s 51us/sample - loss: 0.0833 - acc: 0.9722 - val_loss: 1.1478 - val_acc: 0.7791\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 2s 49us/sample - loss: 0.0819 - acc: 0.9722 - val_loss: 0.9367 - val_acc: 0.8083\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 2s 52us/sample - loss: 0.0795 - acc: 0.9729 - val_loss: 1.1002 - val_acc: 0.7901\n"
     ]
    }
   ],
   "source": [
    "# compiling the neural network classifier, adam optimizer\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "# Adding activation function - softmax for multiclass classification\n",
    "model5.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the neural network for training\n",
    "history = model5.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "x612tS1vXAfv",
    "outputId": "f11fc93f-16ff-47dd-865b-972c3e338684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN with batch normalization\n",
      "--------------------------------------------------------------------------------\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 1.1002 - acc: 0.7901\n",
      "Validation accuracy: 79.01\n"
     ]
    }
   ],
   "source": [
    "print('NN with batch normalization'); print('--'*40)\n",
    "results5 = model5.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: {}'.format(round(results5[1]*100, 2), '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zlIflBua6Hie"
   },
   "source": [
    "<a id='o7'></a>\n",
    "##### Observation 7 - Batch Normalization\n",
    "* Batch normalization didn't result in improvement of score.\n",
    "* Relu activations, changing number of activators, Adam optimizers achieved the best score.\n",
    "* Next, let's try batch normalization with dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04uo_AzWTq5X"
   },
   "source": [
    "<a id='Dropout'></a>\n",
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "smSh8h6RZthm"
   },
   "source": [
    "#### NN model, relu activations, SGD optimizers with weight initializers,  batch normalization and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "xq5p41MtNvui",
    "outputId": "8c1d1307-fc95-40ba-cfdd-e4733b432c15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN model with dropout - sgd optimizer\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('NN model with dropout - sgd optimizer'); print('--'*40)\n",
    "# Initialize the neural network classifier\n",
    "model6 = Sequential()\n",
    "# Input Layer - adding input layer and activation functions relu and weight initializer\n",
    "model6.add(Dense(512, input_shape = (1024, ), kernel_initializer = 'he_normal'))\n",
    "# Adding batch normalization\n",
    "model6.add(BatchNormalization()) \n",
    "# Adding activation function\n",
    "model6.add(Activation('relu'))\n",
    "# Adding dropout layer\n",
    "model6.add(Dropout(0.2))\n",
    "\n",
    "#Hidden Layer 1 - adding first hidden layer\n",
    "model6.add(Dense(256, kernel_initializer = 'he_normal', bias_initializer = 'he_uniform'))\n",
    "# Adding batch normalization\n",
    "model6.add(BatchNormalization())\n",
    "# Adding activation function\n",
    "model6.add(Activation('relu'))\n",
    "# Adding dropout layer\n",
    "model6.add(Dropout(0.2))\n",
    "\n",
    "#Hidden Layer 2 - adding second hidden layer\n",
    "model6.add(Dense(128, kernel_initializer = 'he_normal', bias_initializer = 'he_uniform'))\n",
    "# Adding batch normalization\n",
    "model6.add(BatchNormalization())\n",
    "# Adding activation function\n",
    "model6.add(Activation('relu'))\n",
    "# Adding dropout layer\n",
    "model6.add(Dropout(0.2))\n",
    "\n",
    "#Hidden Layer 3 - adding third hidden layer\n",
    "model6.add(Dense(64, kernel_initializer = 'he_normal', bias_initializer = 'he_uniform'))\n",
    "# Adding batch normalization\n",
    "model6.add(BatchNormalization())\n",
    "# Adding activation function\n",
    "model6.add(Activation('relu'))\n",
    "# Adding dropout layer\n",
    "model6.add(Dropout(0.2))\n",
    "\n",
    "#Hidden Layer 4 - adding fourth hidden layer\n",
    "model6.add(Dense(32, kernel_initializer = 'he_normal', bias_initializer = 'he_uniform'))\n",
    "# Adding batch normalization\n",
    "model6.add(BatchNormalization())\n",
    "# Adding activation function\n",
    "model6.add(Activation('relu'))\n",
    "# Adding dropout layer\n",
    "model6.add(Dropout(0.2))\n",
    "\n",
    "# Output Layer - adding output layer which is of 10 nodes (digits)\n",
    "model6.add(Dense(10, kernel_initializer = 'he_normal',bias_initializer = 'he_uniform'))\n",
    "# Adding activation function\n",
    "model6.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 941
    },
    "colab_type": "code",
    "id": "IV_EP0rf6n6A",
    "outputId": "3fdbd698-c572-4d46-ee16-acf3ae768c77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 703,658\n",
      "Trainable params: 701,674\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "E9TPI3fIZGTI",
    "outputId": "2d73d0c6-232d-405f-cbe8-11ea5d49550d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 3s 71us/sample - loss: 2.6054 - acc: 0.1100 - val_loss: 2.3237 - val_acc: 0.1209\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 2.4142 - acc: 0.1332 - val_loss: 2.2139 - val_acc: 0.2095\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 2.3151 - acc: 0.1548 - val_loss: 2.1209 - val_acc: 0.2677\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 2.2315 - acc: 0.1876 - val_loss: 2.0331 - val_acc: 0.3157\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 2.1531 - acc: 0.2181 - val_loss: 1.9579 - val_acc: 0.3408\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 2.0815 - acc: 0.2495 - val_loss: 1.8626 - val_acc: 0.3965\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 2.0079 - acc: 0.2789 - val_loss: 1.7922 - val_acc: 0.4313\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 1.9351 - acc: 0.3115 - val_loss: 1.7376 - val_acc: 0.4426\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 1.8709 - acc: 0.3382 - val_loss: 1.6199 - val_acc: 0.4975\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 1.8116 - acc: 0.3619 - val_loss: 1.5512 - val_acc: 0.5238\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 1.7518 - acc: 0.3841 - val_loss: 1.4736 - val_acc: 0.5408\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 1.7028 - acc: 0.4066 - val_loss: 1.3984 - val_acc: 0.5655\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 1.6439 - acc: 0.4270 - val_loss: 1.3576 - val_acc: 0.5828\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 1.5967 - acc: 0.4430 - val_loss: 1.3111 - val_acc: 0.5965\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 1.5617 - acc: 0.4607 - val_loss: 1.2542 - val_acc: 0.6111\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 1.5186 - acc: 0.4753 - val_loss: 1.2091 - val_acc: 0.6265\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 1.4842 - acc: 0.4868 - val_loss: 1.1793 - val_acc: 0.6374\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 1.4473 - acc: 0.5011 - val_loss: 1.1519 - val_acc: 0.6433\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 1.4101 - acc: 0.5162 - val_loss: 1.1057 - val_acc: 0.6606\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 1.3852 - acc: 0.5309 - val_loss: 1.0990 - val_acc: 0.6641\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 1.3534 - acc: 0.5418 - val_loss: 1.0614 - val_acc: 0.6762\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 1.3285 - acc: 0.5496 - val_loss: 1.0304 - val_acc: 0.6890\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 1.2992 - acc: 0.5609 - val_loss: 1.0085 - val_acc: 0.6887\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 1.2786 - acc: 0.5706 - val_loss: 0.9750 - val_acc: 0.7053\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 1.2606 - acc: 0.5766 - val_loss: 0.9636 - val_acc: 0.7069\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 1.2394 - acc: 0.5840 - val_loss: 0.9422 - val_acc: 0.7091\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 1.2132 - acc: 0.5979 - val_loss: 0.9353 - val_acc: 0.7169\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 1.1932 - acc: 0.6047 - val_loss: 0.9152 - val_acc: 0.7215\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 1.1793 - acc: 0.6109 - val_loss: 0.8742 - val_acc: 0.7368\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 1.1572 - acc: 0.6158 - val_loss: 0.9592 - val_acc: 0.7013\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 1.1357 - acc: 0.6254 - val_loss: 0.8361 - val_acc: 0.7450\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 1.1246 - acc: 0.6317 - val_loss: 0.8718 - val_acc: 0.7318\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 1.1089 - acc: 0.6334 - val_loss: 0.8291 - val_acc: 0.7463\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 1.0959 - acc: 0.6414 - val_loss: 0.8557 - val_acc: 0.7293\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 1.0835 - acc: 0.6456 - val_loss: 0.8170 - val_acc: 0.7472\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 1.0635 - acc: 0.6545 - val_loss: 0.8103 - val_acc: 0.7564\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 1.0554 - acc: 0.6572 - val_loss: 0.7692 - val_acc: 0.7686\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 1.0389 - acc: 0.6655 - val_loss: 0.7873 - val_acc: 0.7632\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 1.0189 - acc: 0.6723 - val_loss: 0.7743 - val_acc: 0.7618\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 1.0079 - acc: 0.6775 - val_loss: 0.7309 - val_acc: 0.7797\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 1.0044 - acc: 0.6761 - val_loss: 0.7411 - val_acc: 0.7771\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.9949 - acc: 0.6807 - val_loss: 0.7256 - val_acc: 0.7826\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.9799 - acc: 0.6888 - val_loss: 0.7309 - val_acc: 0.7801\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.9662 - acc: 0.6906 - val_loss: 0.7218 - val_acc: 0.7818\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.9578 - acc: 0.6942 - val_loss: 0.6908 - val_acc: 0.7904\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.9417 - acc: 0.7012 - val_loss: 0.7344 - val_acc: 0.7721\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.9413 - acc: 0.6993 - val_loss: 0.7060 - val_acc: 0.7821\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.9270 - acc: 0.7054 - val_loss: 0.7181 - val_acc: 0.7824\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.9109 - acc: 0.7130 - val_loss: 0.6612 - val_acc: 0.7988\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.9078 - acc: 0.7140 - val_loss: 0.6873 - val_acc: 0.7903\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.8992 - acc: 0.7155 - val_loss: 0.6665 - val_acc: 0.8009\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.8844 - acc: 0.7209 - val_loss: 0.6310 - val_acc: 0.8111\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.8843 - acc: 0.7214 - val_loss: 0.6561 - val_acc: 0.7992\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.8734 - acc: 0.7273 - val_loss: 0.6311 - val_acc: 0.8083\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.8673 - acc: 0.7281 - val_loss: 0.6193 - val_acc: 0.8108\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.8486 - acc: 0.7355 - val_loss: 0.6420 - val_acc: 0.8012\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.8503 - acc: 0.7352 - val_loss: 0.6994 - val_acc: 0.7861\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.8442 - acc: 0.7357 - val_loss: 0.5837 - val_acc: 0.8247\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.8391 - acc: 0.7389 - val_loss: 0.6363 - val_acc: 0.8028\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.8335 - acc: 0.7413 - val_loss: 0.5961 - val_acc: 0.8199\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.8294 - acc: 0.7413 - val_loss: 0.5941 - val_acc: 0.8199\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.8155 - acc: 0.7469 - val_loss: 0.6761 - val_acc: 0.7928\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.8109 - acc: 0.7496 - val_loss: 0.6227 - val_acc: 0.8094\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.8007 - acc: 0.7499 - val_loss: 0.6400 - val_acc: 0.8033\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.8021 - acc: 0.7507 - val_loss: 0.5850 - val_acc: 0.8219\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.7899 - acc: 0.7548 - val_loss: 0.5739 - val_acc: 0.8261\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.7775 - acc: 0.7590 - val_loss: 0.6175 - val_acc: 0.8099\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.7847 - acc: 0.7580 - val_loss: 0.5935 - val_acc: 0.8196\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.7709 - acc: 0.7607 - val_loss: 0.7921 - val_acc: 0.7597\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.7697 - acc: 0.7607 - val_loss: 0.5952 - val_acc: 0.8155\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.7648 - acc: 0.7630 - val_loss: 0.5414 - val_acc: 0.8394\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.7613 - acc: 0.7660 - val_loss: 0.5473 - val_acc: 0.8335\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.7515 - acc: 0.7674 - val_loss: 0.5540 - val_acc: 0.8316\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.7506 - acc: 0.7693 - val_loss: 0.5334 - val_acc: 0.8379\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.7394 - acc: 0.7717 - val_loss: 0.5623 - val_acc: 0.8301\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.7449 - acc: 0.7692 - val_loss: 0.5112 - val_acc: 0.8475\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.7367 - acc: 0.7758 - val_loss: 0.5499 - val_acc: 0.8302\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.7347 - acc: 0.7757 - val_loss: 0.5693 - val_acc: 0.8232\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.7263 - acc: 0.7772 - val_loss: 0.6090 - val_acc: 0.8162\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.7270 - acc: 0.7768 - val_loss: 0.6102 - val_acc: 0.8118\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.7203 - acc: 0.7798 - val_loss: 0.5505 - val_acc: 0.8335\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.7166 - acc: 0.7812 - val_loss: 0.5441 - val_acc: 0.8350\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.7112 - acc: 0.7829 - val_loss: 0.5885 - val_acc: 0.8156\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.7027 - acc: 0.7845 - val_loss: 0.5343 - val_acc: 0.8360\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.6959 - acc: 0.7876 - val_loss: 0.5293 - val_acc: 0.8361\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.6922 - acc: 0.7890 - val_loss: 0.5124 - val_acc: 0.8444\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 2s 53us/sample - loss: 0.6874 - acc: 0.7903 - val_loss: 0.5271 - val_acc: 0.8380\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 2s 53us/sample - loss: 0.6906 - acc: 0.7891 - val_loss: 0.5241 - val_acc: 0.8409\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.6743 - acc: 0.7943 - val_loss: 0.5262 - val_acc: 0.8401\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.6803 - acc: 0.7909 - val_loss: 0.5525 - val_acc: 0.8313\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.6779 - acc: 0.7928 - val_loss: 0.5164 - val_acc: 0.8436\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.6767 - acc: 0.7927 - val_loss: 0.4986 - val_acc: 0.8492\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.6632 - acc: 0.7985 - val_loss: 0.5105 - val_acc: 0.8431\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.6640 - acc: 0.7991 - val_loss: 0.4897 - val_acc: 0.8518\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.6698 - acc: 0.7959 - val_loss: 0.5073 - val_acc: 0.8418\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 2s 54us/sample - loss: 0.6591 - acc: 0.8000 - val_loss: 0.6676 - val_acc: 0.7981\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 2s 55us/sample - loss: 0.6608 - acc: 0.7998 - val_loss: 0.6813 - val_acc: 0.7984\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.6470 - acc: 0.8018 - val_loss: 0.4924 - val_acc: 0.8505\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.6573 - acc: 0.8001 - val_loss: 0.5130 - val_acc: 0.8419\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.6478 - acc: 0.8029 - val_loss: 0.4758 - val_acc: 0.8560\n"
     ]
    }
   ],
   "source": [
    "# compiling the neural network classifier, sgd optimizer\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model6.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Adding activation function - softmax for multiclass classification\n",
    "history = model6.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "JpuSGV5WUUJX",
    "outputId": "880b9b5c-f1da-48a1-c91a-471fd15c30e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN model with dropout - sgd optimizer\n",
      "--------------------------------------------------------------------------------\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.4758 - acc: 0.8560\n",
      "Validation accuracy: 85.6\n"
     ]
    }
   ],
   "source": [
    "print('NN model with dropout - sgd optimizer'); print('--'*40)\n",
    "results6 = model6.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: {}'.format(round(results6[1]*100, 2), '%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "658feR9fZ353",
    "outputId": "fd0788fc-79ef-4743-f378-54e217eb1095"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 3s 75us/sample - loss: 1.0483 - acc: 0.6722 - val_loss: 1.5585 - val_acc: 0.4775\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.9086 - acc: 0.7194 - val_loss: 1.3776 - val_acc: 0.5337\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.8480 - acc: 0.7403 - val_loss: 1.0837 - val_acc: 0.6561\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.7984 - acc: 0.7575 - val_loss: 1.1266 - val_acc: 0.6141\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.7714 - acc: 0.7648 - val_loss: 1.2182 - val_acc: 0.5853\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.7336 - acc: 0.7772 - val_loss: 1.0197 - val_acc: 0.6763\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.7149 - acc: 0.7826 - val_loss: 1.1113 - val_acc: 0.6252\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.6941 - acc: 0.7898 - val_loss: 0.9268 - val_acc: 0.7488\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.6799 - acc: 0.7955 - val_loss: 1.3377 - val_acc: 0.5425\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.6518 - acc: 0.8032 - val_loss: 0.8574 - val_acc: 0.7210\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.6379 - acc: 0.8080 - val_loss: 1.2970 - val_acc: 0.5655\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.6319 - acc: 0.8079 - val_loss: 0.9649 - val_acc: 0.7167\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.6119 - acc: 0.8154 - val_loss: 1.2310 - val_acc: 0.5864\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.6004 - acc: 0.8187 - val_loss: 0.8527 - val_acc: 0.7557\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.5864 - acc: 0.8228 - val_loss: 1.2250 - val_acc: 0.5955\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.5891 - acc: 0.8222 - val_loss: 0.9921 - val_acc: 0.6742\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.5695 - acc: 0.8276 - val_loss: 1.0117 - val_acc: 0.6686\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.5593 - acc: 0.8319 - val_loss: 0.8131 - val_acc: 0.7855\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.5542 - acc: 0.8344 - val_loss: 1.1605 - val_acc: 0.6218\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.5464 - acc: 0.8354 - val_loss: 0.9370 - val_acc: 0.6977\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.5382 - acc: 0.8398 - val_loss: 0.7988 - val_acc: 0.7521\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 3s 61us/sample - loss: 0.5289 - acc: 0.8412 - val_loss: 0.9359 - val_acc: 0.6881\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.5178 - acc: 0.8447 - val_loss: 0.8229 - val_acc: 0.7292\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.5133 - acc: 0.8455 - val_loss: 1.0570 - val_acc: 0.6738\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.5046 - acc: 0.8481 - val_loss: 0.7736 - val_acc: 0.7540\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.5038 - acc: 0.8490 - val_loss: 0.8040 - val_acc: 0.7357\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.4964 - acc: 0.8505 - val_loss: 1.0628 - val_acc: 0.6397\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 3s 64us/sample - loss: 0.4956 - acc: 0.8516 - val_loss: 1.0051 - val_acc: 0.6658\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.4762 - acc: 0.8577 - val_loss: 0.9671 - val_acc: 0.6847\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.4803 - acc: 0.8545 - val_loss: 0.9152 - val_acc: 0.7100\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.4699 - acc: 0.8582 - val_loss: 0.7210 - val_acc: 0.7599\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 3s 61us/sample - loss: 0.4675 - acc: 0.8602 - val_loss: 0.7587 - val_acc: 0.7574\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.4615 - acc: 0.8604 - val_loss: 0.7750 - val_acc: 0.7526\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.4583 - acc: 0.8603 - val_loss: 0.8713 - val_acc: 0.7247\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.4579 - acc: 0.8632 - val_loss: 0.7976 - val_acc: 0.7362\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.4483 - acc: 0.8645 - val_loss: 0.7683 - val_acc: 0.7563\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.4392 - acc: 0.8675 - val_loss: 0.7715 - val_acc: 0.7536\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.4412 - acc: 0.8669 - val_loss: 0.8139 - val_acc: 0.7285\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.4326 - acc: 0.8701 - val_loss: 0.6890 - val_acc: 0.7885\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.4206 - acc: 0.8730 - val_loss: 0.8502 - val_acc: 0.7258\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.4262 - acc: 0.8727 - val_loss: 0.6450 - val_acc: 0.7916\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.4188 - acc: 0.8747 - val_loss: 0.5895 - val_acc: 0.8100\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.4113 - acc: 0.8745 - val_loss: 0.7252 - val_acc: 0.7735\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.4156 - acc: 0.8732 - val_loss: 1.1334 - val_acc: 0.6520\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.4083 - acc: 0.8765 - val_loss: 0.6479 - val_acc: 0.7949\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 3s 61us/sample - loss: 0.4091 - acc: 0.8773 - val_loss: 0.7718 - val_acc: 0.7485\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.4042 - acc: 0.8782 - val_loss: 0.7290 - val_acc: 0.7611\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.3953 - acc: 0.8811 - val_loss: 0.6882 - val_acc: 0.7742\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.3882 - acc: 0.8829 - val_loss: 0.8469 - val_acc: 0.7211\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.3840 - acc: 0.8865 - val_loss: 0.6448 - val_acc: 0.7923\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.3824 - acc: 0.8846 - val_loss: 0.7429 - val_acc: 0.7559\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.3770 - acc: 0.8862 - val_loss: 0.6541 - val_acc: 0.7947\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.3806 - acc: 0.8847 - val_loss: 0.7222 - val_acc: 0.7739\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.3762 - acc: 0.8865 - val_loss: 0.6802 - val_acc: 0.7789\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.3678 - acc: 0.8901 - val_loss: 0.5836 - val_acc: 0.8153\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.3635 - acc: 0.8897 - val_loss: 0.7012 - val_acc: 0.7723\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.3637 - acc: 0.8902 - val_loss: 0.5000 - val_acc: 0.8412\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.3613 - acc: 0.8913 - val_loss: 0.7912 - val_acc: 0.7452\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.3617 - acc: 0.8900 - val_loss: 0.7234 - val_acc: 0.7732\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.3663 - acc: 0.8914 - val_loss: 0.7428 - val_acc: 0.7548\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.3541 - acc: 0.8931 - val_loss: 0.4835 - val_acc: 0.8514\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.3497 - acc: 0.8946 - val_loss: 0.9309 - val_acc: 0.7019\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.3509 - acc: 0.8935 - val_loss: 0.6272 - val_acc: 0.8097\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.3499 - acc: 0.8937 - val_loss: 0.6166 - val_acc: 0.8006\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.3408 - acc: 0.8973 - val_loss: 0.5850 - val_acc: 0.8120\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.3443 - acc: 0.8963 - val_loss: 0.5576 - val_acc: 0.8225\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 3s 61us/sample - loss: 0.3357 - acc: 0.8967 - val_loss: 0.5877 - val_acc: 0.8114\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.3436 - acc: 0.8964 - val_loss: 0.8347 - val_acc: 0.7368\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.3296 - acc: 0.8996 - val_loss: 0.5776 - val_acc: 0.8166\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.3298 - acc: 0.9002 - val_loss: 0.7237 - val_acc: 0.7641\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.3314 - acc: 0.8998 - val_loss: 0.7168 - val_acc: 0.7644\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.3229 - acc: 0.9024 - val_loss: 0.6814 - val_acc: 0.7736\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.3281 - acc: 0.8997 - val_loss: 0.5008 - val_acc: 0.8452\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.3208 - acc: 0.9037 - val_loss: 0.5365 - val_acc: 0.8301\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 3s 61us/sample - loss: 0.3230 - acc: 0.9022 - val_loss: 0.6199 - val_acc: 0.8008\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 3s 65us/sample - loss: 0.3145 - acc: 0.9044 - val_loss: 0.5949 - val_acc: 0.8097\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 3s 61us/sample - loss: 0.3178 - acc: 0.9046 - val_loss: 0.6488 - val_acc: 0.7916\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.3136 - acc: 0.9048 - val_loss: 0.5016 - val_acc: 0.8428\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.3124 - acc: 0.9065 - val_loss: 0.6061 - val_acc: 0.8069\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.3083 - acc: 0.9069 - val_loss: 0.5600 - val_acc: 0.8191\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.3097 - acc: 0.9063 - val_loss: 0.5729 - val_acc: 0.8153\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.3036 - acc: 0.9097 - val_loss: 0.4584 - val_acc: 0.8562\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 3s 62us/sample - loss: 0.3066 - acc: 0.9073 - val_loss: 0.5082 - val_acc: 0.8383\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.2970 - acc: 0.9109 - val_loss: 0.7692 - val_acc: 0.7568\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.3044 - acc: 0.9073 - val_loss: 0.6092 - val_acc: 0.8047\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.2958 - acc: 0.9103 - val_loss: 0.4906 - val_acc: 0.8454\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.2953 - acc: 0.9108 - val_loss: 0.4721 - val_acc: 0.8436\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.2943 - acc: 0.9105 - val_loss: 0.6549 - val_acc: 0.7836\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.2943 - acc: 0.9100 - val_loss: 0.6813 - val_acc: 0.7893\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 2s 56us/sample - loss: 0.2928 - acc: 0.9110 - val_loss: 0.7207 - val_acc: 0.7628\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.2925 - acc: 0.9115 - val_loss: 0.8072 - val_acc: 0.7591\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 2s 58us/sample - loss: 0.2900 - acc: 0.9117 - val_loss: 0.8668 - val_acc: 0.7243\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 3s 63us/sample - loss: 0.2853 - acc: 0.9132 - val_loss: 0.5118 - val_acc: 0.8381\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.2833 - acc: 0.9132 - val_loss: 0.6805 - val_acc: 0.7838\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.2863 - acc: 0.9134 - val_loss: 0.5222 - val_acc: 0.8342\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 2s 59us/sample - loss: 0.2776 - acc: 0.9172 - val_loss: 0.6173 - val_acc: 0.7970\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 2s 57us/sample - loss: 0.2856 - acc: 0.9139 - val_loss: 0.4914 - val_acc: 0.8441\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.2740 - acc: 0.9163 - val_loss: 0.4306 - val_acc: 0.8653\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.2711 - acc: 0.9185 - val_loss: 0.6014 - val_acc: 0.8122\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 3s 60us/sample - loss: 0.2757 - acc: 0.9154 - val_loss: 0.5253 - val_acc: 0.8297\n"
     ]
    }
   ],
   "source": [
    "# compiling the neural network classifier, adam optimizer\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model6.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Adding activation function - softmax for multiclass classification\n",
    "history = model6.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "f-n63MmSN9DQ",
    "outputId": "70ff10de-e9d7-4482-b8c5-905e6d835e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN model with dropout - adam optimizer\n",
      "--------------------------------------------------------------------------------\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.5253 - acc: 0.8297\n",
      "Validation accuracy: 82.97\n"
     ]
    }
   ],
   "source": [
    "print('NN model with dropout - adam optimizer'); print('--'*40)\n",
    "results6 = model6.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: {}'.format(round(results6[1]*100, 2), '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YEbd6Ynm6wmp"
   },
   "source": [
    "<a id='o8'></a>\n",
    "##### Observation 8 - Batch Normalization and Dropout\n",
    "* Didn't result in any improvement of score.\n",
    "* NN model, relu activations, SGD optimizers with weight initializers and batch normalization is still the best model.\n",
    "* Next, let's try batch normalization and dropout with adam optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-x-REsa00x7"
   },
   "source": [
    "<a id='Prediction'></a>\n",
    "### Prediction on test dataset using Model 3 - relu activations, Adam optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "E3V_MkU-018D",
    "outputId": "3ccf507a-70e3-4d2c-d4b9-d55d887ef826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN model with relu activations and changing number of activators\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('NN model with relu activations and changing number of activators'); print('--'*40)\n",
    "# Initialize the neural network classifier\n",
    "model3 = Sequential()\n",
    "\n",
    "# Input Layer - adding input layer and activation functions relu\n",
    "model3.add(Dense(256, input_shape = (1024, )))\n",
    "# Adding activation function\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "#Hidden Layer 1 - adding first hidden layer\n",
    "model3.add(Dense(128))\n",
    "# Adding activation function\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "#Hidden Layer 2 - Adding second hidden layer\n",
    "model3.add(Dense(64))\n",
    "# Adding activation function\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "# Output Layer - adding output layer which is of 10 nodes (digits)\n",
    "model3.add(Dense(10))\n",
    "# Adding activation function - softmax for multiclass classification\n",
    "model3.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dFUqzgvDL0Gf",
    "outputId": "67f86db0-42f7-4cef-c552-fcc3b20b3287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 39us/sample - loss: 2.2450 - acc: 0.1494 - val_loss: 1.9481 - val_acc: 0.3398\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.5502 - acc: 0.4844 - val_loss: 1.3632 - val_acc: 0.5493\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.2826 - acc: 0.5840 - val_loss: 1.1971 - val_acc: 0.6190\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.1456 - acc: 0.6382 - val_loss: 1.0864 - val_acc: 0.6639\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.0588 - acc: 0.6704 - val_loss: 1.0618 - val_acc: 0.6653\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 1.0035 - acc: 0.6882 - val_loss: 0.9490 - val_acc: 0.7054\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.9524 - acc: 0.7060 - val_loss: 0.9711 - val_acc: 0.7005\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9115 - acc: 0.7183 - val_loss: 0.8688 - val_acc: 0.7336\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8822 - acc: 0.7289 - val_loss: 0.8723 - val_acc: 0.7294\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.8557 - acc: 0.7358 - val_loss: 0.8526 - val_acc: 0.7390\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.8294 - acc: 0.7449 - val_loss: 0.8516 - val_acc: 0.7340\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.8123 - acc: 0.7475 - val_loss: 0.7854 - val_acc: 0.7562\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7956 - acc: 0.7556 - val_loss: 0.8098 - val_acc: 0.7527\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7827 - acc: 0.7574 - val_loss: 0.7563 - val_acc: 0.7686\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7541 - acc: 0.7695 - val_loss: 0.7475 - val_acc: 0.7719\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7410 - acc: 0.7709 - val_loss: 0.7352 - val_acc: 0.7752\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7287 - acc: 0.7764 - val_loss: 0.7410 - val_acc: 0.7713\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7150 - acc: 0.7795 - val_loss: 0.7157 - val_acc: 0.7821\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.7025 - acc: 0.7840 - val_loss: 0.7085 - val_acc: 0.7825\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6890 - acc: 0.7884 - val_loss: 0.7198 - val_acc: 0.7801\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6722 - acc: 0.7940 - val_loss: 0.7024 - val_acc: 0.7853\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6632 - acc: 0.7958 - val_loss: 0.7599 - val_acc: 0.7661\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6577 - acc: 0.7969 - val_loss: 0.6656 - val_acc: 0.7979\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6323 - acc: 0.8049 - val_loss: 0.6612 - val_acc: 0.7972\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6246 - acc: 0.8080 - val_loss: 0.6253 - val_acc: 0.8116\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6241 - acc: 0.8078 - val_loss: 0.6045 - val_acc: 0.8176\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.6085 - acc: 0.8138 - val_loss: 0.6033 - val_acc: 0.8179\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5945 - acc: 0.8184 - val_loss: 0.5880 - val_acc: 0.8226\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.5854 - acc: 0.8206 - val_loss: 0.5891 - val_acc: 0.8232\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5819 - acc: 0.8211 - val_loss: 0.5972 - val_acc: 0.8191\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5704 - acc: 0.8244 - val_loss: 0.5885 - val_acc: 0.8224\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.5728 - acc: 0.8236 - val_loss: 0.5906 - val_acc: 0.8203\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5547 - acc: 0.8282 - val_loss: 0.5743 - val_acc: 0.8260\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5482 - acc: 0.8301 - val_loss: 0.5979 - val_acc: 0.8173\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5397 - acc: 0.8349 - val_loss: 0.5557 - val_acc: 0.8319\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5328 - acc: 0.8364 - val_loss: 0.5550 - val_acc: 0.8320\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5315 - acc: 0.8366 - val_loss: 0.5342 - val_acc: 0.8388\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5190 - acc: 0.8395 - val_loss: 0.5484 - val_acc: 0.8354\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5133 - acc: 0.8424 - val_loss: 0.5546 - val_acc: 0.8307\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5245 - acc: 0.8354 - val_loss: 0.5637 - val_acc: 0.8249\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.5054 - acc: 0.8429 - val_loss: 0.5232 - val_acc: 0.8415\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5053 - acc: 0.8436 - val_loss: 0.5410 - val_acc: 0.8354\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.5047 - acc: 0.8423 - val_loss: 0.5490 - val_acc: 0.8328\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4911 - acc: 0.8472 - val_loss: 0.5196 - val_acc: 0.8423\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4943 - acc: 0.8452 - val_loss: 0.5047 - val_acc: 0.8465\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4728 - acc: 0.8534 - val_loss: 0.5193 - val_acc: 0.8446\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4728 - acc: 0.8541 - val_loss: 0.5411 - val_acc: 0.8332\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4783 - acc: 0.8500 - val_loss: 0.5254 - val_acc: 0.8409\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4661 - acc: 0.8535 - val_loss: 0.4862 - val_acc: 0.8540\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4548 - acc: 0.8591 - val_loss: 0.4810 - val_acc: 0.8564\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4544 - acc: 0.8582 - val_loss: 0.5049 - val_acc: 0.8487\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4551 - acc: 0.8577 - val_loss: 0.4743 - val_acc: 0.8570\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4540 - acc: 0.8572 - val_loss: 0.4703 - val_acc: 0.8590\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4449 - acc: 0.8603 - val_loss: 0.5001 - val_acc: 0.8488\n",
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4390 - acc: 0.8627 - val_loss: 0.4796 - val_acc: 0.8548\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4353 - acc: 0.8651 - val_loss: 0.4902 - val_acc: 0.8526\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4404 - acc: 0.8614 - val_loss: 0.5234 - val_acc: 0.8398\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.4391 - acc: 0.8615 - val_loss: 0.4935 - val_acc: 0.8507\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4318 - acc: 0.8632 - val_loss: 0.4953 - val_acc: 0.8497\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4265 - acc: 0.8662 - val_loss: 0.5158 - val_acc: 0.8422\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4205 - acc: 0.8655 - val_loss: 0.5047 - val_acc: 0.8468\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4207 - acc: 0.8683 - val_loss: 0.4942 - val_acc: 0.8505\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4136 - acc: 0.8702 - val_loss: 0.4649 - val_acc: 0.8625\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4127 - acc: 0.8694 - val_loss: 0.4480 - val_acc: 0.8663\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4169 - acc: 0.8680 - val_loss: 0.4424 - val_acc: 0.8684\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4004 - acc: 0.8735 - val_loss: 0.4501 - val_acc: 0.8655\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4046 - acc: 0.8707 - val_loss: 0.4404 - val_acc: 0.8692\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4078 - acc: 0.8700 - val_loss: 0.4328 - val_acc: 0.8717\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.4011 - acc: 0.8722 - val_loss: 0.4715 - val_acc: 0.8596\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3974 - acc: 0.8742 - val_loss: 0.4439 - val_acc: 0.8680\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3904 - acc: 0.8752 - val_loss: 0.4707 - val_acc: 0.8602\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3903 - acc: 0.8760 - val_loss: 0.4233 - val_acc: 0.8751\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3848 - acc: 0.8788 - val_loss: 0.4433 - val_acc: 0.8659\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3820 - acc: 0.8785 - val_loss: 0.4359 - val_acc: 0.8703\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3744 - acc: 0.8806 - val_loss: 0.4497 - val_acc: 0.8642\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3889 - acc: 0.8754 - val_loss: 0.4522 - val_acc: 0.8640\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3780 - acc: 0.8807 - val_loss: 0.5019 - val_acc: 0.8474\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3741 - acc: 0.8813 - val_loss: 0.4329 - val_acc: 0.8713\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3686 - acc: 0.8828 - val_loss: 0.4347 - val_acc: 0.8714\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3624 - acc: 0.8852 - val_loss: 0.4339 - val_acc: 0.8716\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3730 - acc: 0.8813 - val_loss: 0.4617 - val_acc: 0.8615\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3621 - acc: 0.8837 - val_loss: 0.4089 - val_acc: 0.8799\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3633 - acc: 0.8843 - val_loss: 0.4048 - val_acc: 0.8813\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3598 - acc: 0.8852 - val_loss: 0.4693 - val_acc: 0.8583\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3580 - acc: 0.8858 - val_loss: 0.4362 - val_acc: 0.8702\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3572 - acc: 0.8849 - val_loss: 0.4603 - val_acc: 0.8621\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3524 - acc: 0.8885 - val_loss: 0.4158 - val_acc: 0.8780\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3495 - acc: 0.8895 - val_loss: 0.4046 - val_acc: 0.8816\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3430 - acc: 0.8909 - val_loss: 0.4195 - val_acc: 0.8769\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3433 - acc: 0.8904 - val_loss: 0.4739 - val_acc: 0.8565\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3410 - acc: 0.8909 - val_loss: 0.4222 - val_acc: 0.8758\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3433 - acc: 0.8912 - val_loss: 0.4033 - val_acc: 0.8818\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3392 - acc: 0.8909 - val_loss: 0.4610 - val_acc: 0.8605\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.3302 - acc: 0.8946 - val_loss: 0.3992 - val_acc: 0.8845\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3377 - acc: 0.8926 - val_loss: 0.4248 - val_acc: 0.8755\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3321 - acc: 0.8932 - val_loss: 0.4212 - val_acc: 0.8764\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3279 - acc: 0.8958 - val_loss: 0.4042 - val_acc: 0.8802\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3348 - acc: 0.8917 - val_loss: 0.3966 - val_acc: 0.8849\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.3188 - acc: 0.8980 - val_loss: 0.4341 - val_acc: 0.8735\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3311 - acc: 0.8932 - val_loss: 0.3852 - val_acc: 0.8892\n"
     ]
    }
   ],
   "source": [
    "# compiling the neural network classifier, adam optimizer\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model3.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the neural network for training\n",
    "history = model3.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 200, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "2ao6j_Dl1I9j",
    "outputId": "2197768b-98ca-41a3-f096-158282390297"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN with batch normalization\n",
      "--------------------------------------------------------------------------------\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3852 - acc: 0.8892\n",
      "Validation accuracy: 88.92\n"
     ]
    }
   ],
   "source": [
    "print('NN with batch normalization'); print('--'*40)\n",
    "results3 = model3.evaluate(X_val, y_val)\n",
    "print('Validation accuracy: {}'.format(round(results3[1]*100, 2), '%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "2VfnxZqX1Mnm",
    "outputId": "f0a94d2e-950b-45ee-d164-5e7d93fc45a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model on test dataset\n",
      "18000/18000 [==============================] - 1s 52us/sample - loss: 0.6316 - acc: 0.8357\n",
      "Test loss : 0.6316036958562004\n",
      "Test accuracy : 0.8357222\n"
     ]
    }
   ],
   "source": [
    "print('Testing the model on test dataset')\n",
    "predictions = model3.predict_classes(X_test)\n",
    "score = model3.evaluate(X_test, y_test)\n",
    "print('Test loss :', score[0])\n",
    "print('Test accuracy :', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "Zg8aVLVu1rkI",
    "outputId": "04585158-57c9-4abb-d75f-3e1a0bcbd051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      1814\n",
      "           1       0.85      0.86      0.86      1828\n",
      "           2       0.86      0.85      0.86      1803\n",
      "           3       0.79      0.79      0.79      1719\n",
      "           4       0.86      0.88      0.87      1812\n",
      "           5       0.76      0.83      0.80      1768\n",
      "           6       0.83      0.81      0.82      1832\n",
      "           7       0.91      0.85      0.88      1808\n",
      "           8       0.80      0.79      0.80      1812\n",
      "           9       0.84      0.82      0.83      1804\n",
      "\n",
      "    accuracy                           0.84     18000\n",
      "   macro avg       0.84      0.84      0.84     18000\n",
      "weighted avg       0.84      0.84      0.84     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report'); print('--'*40)\n",
    "print(classification_report(y_test_o, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "colab_type": "code",
    "id": "rTLDrm8u3KR0",
    "outputId": "feec8cdb-8b61-4280-f286-c5cfd29f4b68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing the confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7fa60fd0b8>"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAGjCAYAAABdU+ZeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 1080x518.4 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Visualizing the confusion matrix')\n",
    "plt.figure(figsize = (15, 7.2))\n",
    "sns.heatmap(confusion_matrix(y_test_o, predictions), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "id": "91DnbyzFQCVg",
    "outputId": "82c28e5f-8009-4655-a542-d567a4c0d2d7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAEXCAYAAAD82wBdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbEAAAEXCAYAAAAjlXpCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns/4FUnlyVsAU2xwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model3 Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc = 'upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model3 Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rX4gZs4YB3Kc",
    "outputId": "43ddc14c-8b2e-4de5-e0e0-e44017d97147"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.predict_classes(X_test)[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "8YADP-ZLB7HA",
    "outputId": "72b128ca-23b2-47cd-ed8b-c96c1967fc36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7f9f3c72b0>"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD1CAYAAAB9TzjVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Showing the image\n",
    "plt.imshow(X_test[20].reshape(32, 32), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZnPW2DeGCBf8",
    "outputId": "750a7e76-cbe8-4c4a-b03d-b64ae030cc8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.predict_classes(X_test)[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "SNYI3rhrCEVv",
    "outputId": "9a7b29ec-738a-4dcf-bc8a-8cab43f49509"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7f9f2fd198>"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD1CAYAAAB9TzjVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJyRiqOCERAwVnJCI+X8SLdBus2/nIgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[10].reshape(32, 32), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "liZmu-GVCPoV",
    "outputId": "795f01e0-a6a2-4cec-8a9f-b4e0d55b3f49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.predict_classes(X_test)[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-nx-k4eMKAl"
   },
   "source": [
    "<a id='Conclusion'></a>\n",
    "### Conclusion\n",
    "Evaluated the accuracy using two methods i.e. baby sitting the NN and NN through API. Followed all the required steps starting with loading the datasets to performing hyperparameter optimization and running a finer search by using a finer range. Explored different options in optimizers, number of activators, learning rate and activation methods in NN through API. Found that baby sitting process achieved the best accuracy of 21% using hyper parameter optimization. It might have been further improved but that's the trade off vs time taken to run the script. NN through API method achieved best accuracy of 90% on validation set. Also printed the classification report, visualized the confusion matrix and summarized history for accuracy and loss."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NN 1 - Project - Part I.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
